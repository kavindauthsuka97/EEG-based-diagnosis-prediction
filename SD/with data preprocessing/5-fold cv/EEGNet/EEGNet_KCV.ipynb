{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cell 0 — Install packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (run once)\n",
        "%pip install -q mne PyWavelets scikit-learn seaborn\n",
        "%pip install -q imbalanced-learn\n",
        "%pip install -q azureml-core azure-ai-ml azure-identity\n",
        "\n",
        "print(\"✅ Packages installed (if no errors above).\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Note: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n✅ Packages installed (if no errors above).\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1767930100194
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1 — Load libraries + set seeds"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # file/folder ops\n",
        "import random  # python RNG\n",
        "import numpy as np  # arrays/math\n",
        "\n",
        "import mne  # EEG reading/processing\n",
        "import pywt  # wavelets\n",
        "from sklearn.decomposition import FastICA  # ICA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score  # metrics\n",
        "from sklearn.model_selection import StratifiedKFold  # 10-fold CV\n",
        "\n",
        "from collections import defaultdict  # grouping\n",
        "from typing import Optional, Union, Sequence, Dict, Tuple, List  # typing helpers\n",
        "\n",
        "import matplotlib.pyplot as plt  # plotting\n",
        "import seaborn as sns  # heatmaps\n",
        "\n",
        "import tensorflow as tf  # tensorflow\n",
        "from tensorflow.keras.models import Model  # keras model\n",
        "from tensorflow.keras.layers import (  # layers\n",
        "    Conv2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization,\n",
        "    Input, DepthwiseConv2D, SeparableConv2D, Activation\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam  # optimizer\n",
        "from tensorflow.keras.losses import BinaryCrossentropy  # loss\n",
        "from tensorflow.keras.metrics import BinaryAccuracy  # metric\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger  # callbacks\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler  # SMOTE + fallback oversampler\n",
        "\n",
        "# Try enabling interactive logging (optional)\n",
        "try:\n",
        "    tf.keras.utils.enable_interactive_logging()  # better logs if supported\n",
        "except Exception:\n",
        "    pass  # ignore if unsupported\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "random.seed(42)  # python seed\n",
        "np.random.seed(42)  # numpy seed\n",
        "tf.random.set_seed(42)  # TF seed\n",
        "\n",
        "print(\"✅ Imports done + seeds set.\")  # progress print\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2026-01-09 03:41:48.949799: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2026-01-09 03:41:49.248646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767930109.354296    3126 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767930109.382802    3126 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767930109.622506    3126 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767930109.622544    3126 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767930109.622546    3126 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767930109.622548    3126 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2026-01-09 03:41:49.645847: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Imports done + seeds set.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1767930107518
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2 — Helper: load EEG (.set) with labels"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_eeg_data_with_target(  # loader function\n",
        "    folder_path: str,  # folder containing .set\n",
        "    session_name: str,  # ses-1 or ses-2\n",
        "    max_samples: int = 118000,  # max keep from start\n",
        "    discard_samples: int = 10000  # discard beginning\n",
        "):\n",
        "    \"\"\"Load EEG data from .set files and assign labels based on session_name.\"\"\"  # docstring\n",
        "\n",
        "    eeg_files = [f for f in os.listdir(folder_path) if f.endswith('.set')]  # list .set files\n",
        "    data_list = []  # store arrays\n",
        "    targets = []  # store labels\n",
        "    sfreq_list = []  # store sampling rates\n",
        "\n",
        "    for eeg_file in eeg_files:  # loop files\n",
        "        file_path = os.path.join(folder_path, eeg_file)  # full path\n",
        "\n",
        "        raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose=False)  # read file\n",
        "        data = raw.get_data().astype(np.float32)  # (C,T)\n",
        "        sfreq = float(raw.info[\"sfreq\"])  # sampling rate\n",
        "\n",
        "        if data.shape[1] > max_samples:  # trim if too long\n",
        "            data = data[:, :max_samples]  # keep first max\n",
        "\n",
        "        if data.shape[1] > discard_samples:  # ensure can discard\n",
        "            data = data[:, discard_samples:]  # discard start\n",
        "        else:\n",
        "            print(f\"⚠️ Not enough samples to discard in {eeg_file}, skipping.\")  # warn\n",
        "            continue  # skip\n",
        "\n",
        "        data_list.append(data)  # save data\n",
        "        sfreq_list.append(sfreq)  # save fs\n",
        "\n",
        "        if session_name == 'ses-1':  # session 1 label\n",
        "            targets.append(0)  # class 0\n",
        "        elif session_name == 'ses-2':  # session 2 label\n",
        "            targets.append(1)  # class 1\n",
        "        else:\n",
        "            print(f\"⚠️ Unknown session name: {session_name}\")  # warn\n",
        "\n",
        "    return data_list, targets, sfreq_list  # return\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1767930107836
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3 — Leakage-safe preprocessing classes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _names_from_index_mapping(  # helper\n",
        "    n_channels: int,  # number of channels\n",
        "    index_to_name: Optional[Dict[int, str]]  # optional mapping\n",
        ") -> List[str]:\n",
        "    \"\"\"Map numeric channel indices to names or auto-name.\"\"\"  # docstring\n",
        "\n",
        "    if index_to_name is None:  # if no mapping\n",
        "        return [f\"EEG{i+1}\" for i in range(n_channels)]  # auto names\n",
        "\n",
        "    keys = list(index_to_name.keys())  # mapping keys\n",
        "    is_zero_based = (0 in keys) and (1 not in keys)  # detect 0-based mapping\n",
        "\n",
        "    names = []  # output names\n",
        "    for i in range(n_channels):  # for each channel\n",
        "        key = i if is_zero_based else (i + 1)  # choose key style\n",
        "        names.append(index_to_name.get(key, f\"EEG{i+1}\"))  # mapped or fallback\n",
        "    return names  # return names\n",
        "\n",
        "\n",
        "def _make_raw(  # helper\n",
        "    eeg: np.ndarray,  # eeg array\n",
        "    sfreq: float,  # sampling frequency\n",
        "    ch_names: List[str],  # channel names\n",
        "    use_standard_1020: bool = True  # montage flag\n",
        ") -> Tuple[mne.io.Raw, bool]:\n",
        "    \"\"\"Create MNE Raw and optionally apply 10-20 montage.\"\"\"  # docstring\n",
        "\n",
        "    ch_types = ['eog' if str(n).upper().startswith(\"EOG\") else 'eeg' for n in ch_names]  # guess types\n",
        "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)  # info\n",
        "    raw = mne.io.RawArray(eeg.astype(np.float32, copy=False), info, verbose=False)  # raw object\n",
        "\n",
        "    montage_applied = False  # flag\n",
        "\n",
        "    if use_standard_1020:  # if apply montage\n",
        "        try:\n",
        "            mont = mne.channels.make_standard_montage(\"standard_1020\")  # load montage\n",
        "            raw.set_montage(mont, match_case=False, on_missing=\"ignore\")  # apply montage\n",
        "            montage_applied = True  # mark ok\n",
        "        except Exception:\n",
        "            montage_applied = False  # mark fail\n",
        "\n",
        "    return raw, montage_applied  # return raw + flag\n",
        "\n",
        "\n",
        "class WaveletICA:\n",
        "    \"\"\"Wavelet-enhanced ICA (wICA).\"\"\"  # docstring\n",
        "    def __init__(self, wavelet=\"db4\", level=3, n_components=10, random_state=42):  # init\n",
        "        self.wavelet = wavelet  # wavelet\n",
        "        self.level = level  # level\n",
        "        self.n_components = n_components  # ICA comps\n",
        "        self.random_state = random_state  # seed\n",
        "        self.ica_: Optional[FastICA] = None  # fitted ICA\n",
        "        self._n_ch: Optional[int] = None  # channel count\n",
        "\n",
        "    def fit(self, X: np.ndarray):  # fit\n",
        "        C = X.shape[0]  # channels\n",
        "        self._n_ch = C  # store channels\n",
        "\n",
        "        coeffs = pywt.wavedec(X, wavelet=self.wavelet, level=self.level, axis=1)  # DWT\n",
        "        A = coeffs[0]  # approximation\n",
        "\n",
        "        k = int(min(self.n_components, C))  # clip comps\n",
        "        self.ica_ = FastICA(n_components=k, random_state=self.random_state)  # ICA model\n",
        "\n",
        "        S = self.ica_.fit_transform(A.T)  # fit ICA\n",
        "        A_denoised = self.ica_.inverse_transform(S).T  # inverse ICA\n",
        "\n",
        "        coeffs[0] = A_denoised  # replace approx\n",
        "        _ = pywt.waverec(coeffs, wavelet=self.wavelet, axis=1)  # sanity reconstruction\n",
        "\n",
        "        return self  # return self\n",
        "\n",
        "    def transform(self, X: np.ndarray) -> np.ndarray:  # transform\n",
        "        assert self.ica_ is not None, \"WaveletICA not fitted yet.\"  # ensure fit\n",
        "\n",
        "        coeffs = pywt.wavedec(X, wavelet=self.wavelet, level=self.level, axis=1)  # DWT\n",
        "        A = coeffs[0]  # approximation\n",
        "\n",
        "        S = self.ica_.transform(A.T)  # project\n",
        "        A_denoised = self.ica_.inverse_transform(S).T  # reconstruct\n",
        "\n",
        "        coeffs[0] = A_denoised  # replace\n",
        "        Y = pywt.waverec(coeffs, wavelet=self.wavelet, axis=1)  # full recon\n",
        "\n",
        "        if Y.shape[1] < X.shape[1]:  # pad if short\n",
        "            pad_width = X.shape[1] - Y.shape[1]  # pad amount\n",
        "            Y = np.pad(Y, ((0, 0), (0, pad_width)), mode=\"constant\")  # pad\n",
        "        elif Y.shape[1] > X.shape[1]:  # trim if long\n",
        "            Y = Y[:, :X.shape[1]]  # trim\n",
        "\n",
        "        return Y.astype(np.float32, copy=False)  # return float32\n",
        "\n",
        "\n",
        "class EEGPreprocessor:\n",
        "    \"\"\"Leakage-safe preprocessing class (as you provided).\"\"\"  # docstring\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        index_to_name: Optional[Dict[int, str]] = None,\n",
        "        use_standard_1020: bool = True,\n",
        "        resample_to: Optional[float] = None,\n",
        "        notch_freqs: Union[None, float, Sequence[float]] = 50.0,\n",
        "        highpass: Optional[float] = 0.05,\n",
        "        bad_point_z: float = 6.0,\n",
        "        bad_channel_z: float = 5.0,\n",
        "        interpolate_bad_channels: bool = False,\n",
        "        car: bool = True,\n",
        "        use_wica: bool = True,\n",
        "        wica_components: int = 10,\n",
        "        wica_wavelet: str = \"db4\",\n",
        "        wica_level: int = 3,\n",
        "        wica_random_state: int = 42\n",
        "    ):\n",
        "        self.index_to_name = index_to_name\n",
        "        self.use_standard_1020 = use_standard_1020\n",
        "        self.resample_to = resample_to\n",
        "        self.notch_freqs = notch_freqs\n",
        "        self.highpass = highpass\n",
        "        self.bad_point_z = bad_point_z\n",
        "        self.bad_channel_z = bad_channel_z\n",
        "        self.interpolate_bad_channels = interpolate_bad_channels\n",
        "        self.car = car\n",
        "        self.use_wica = use_wica\n",
        "\n",
        "        self._sfreq_out: Optional[float] = None\n",
        "        self._train_mu: Optional[np.ndarray] = None\n",
        "        self._train_sd: Optional[np.ndarray] = None\n",
        "        self._robust_med: Optional[float] = None\n",
        "        self._robust_mad: Optional[float] = None\n",
        "        self._train_eeg_names: Optional[List[str]] = None\n",
        "\n",
        "        self._wica = WaveletICA(\n",
        "            wavelet=wica_wavelet,\n",
        "            level=wica_level,\n",
        "            n_components=wica_components,\n",
        "            random_state=wica_random_state\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def sfreq_out(self) -> float:\n",
        "        assert self._sfreq_out is not None, \"Preprocessor not run yet.\"\n",
        "        return float(self._sfreq_out)\n",
        "\n",
        "    def _filter_and_reference(self, raw: mne.io.Raw):\n",
        "        if self.resample_to is not None and float(self.resample_to) != float(raw.info[\"sfreq\"]):\n",
        "            raw.resample(self.resample_to, npad=\"auto\")\n",
        "\n",
        "        self._sfreq_out = float(raw.info[\"sfreq\"])\n",
        "\n",
        "        if self.notch_freqs is not None:\n",
        "            raw.notch_filter(freqs=self.notch_freqs, verbose=False)\n",
        "\n",
        "        if self.highpass is not None:\n",
        "            raw.filter(l_freq=self.highpass, h_freq=None, verbose=False)\n",
        "\n",
        "        if self.car:\n",
        "            raw.set_eeg_reference(\"average\", projection=True)\n",
        "            raw.apply_proj()\n",
        "\n",
        "    def _repair_transients_with_train_stats(self, raw: mne.io.Raw):\n",
        "        X = raw.get_data()\n",
        "        mu = self._train_mu\n",
        "        sd = self._train_sd\n",
        "        assert mu is not None and sd is not None, \"Training stats not set.\"\n",
        "\n",
        "        hi = mu + self.bad_point_z * sd\n",
        "        lo = mu - self.bad_point_z * sd\n",
        "        mask = (X > hi) | (X < lo)\n",
        "\n",
        "        if np.any(mask):\n",
        "            X_fixed = X.copy()\n",
        "            t = np.arange(X.shape[1], dtype=float)\n",
        "            for ch in range(X.shape[0]):\n",
        "                m = mask[ch]\n",
        "                if m.any():\n",
        "                    good = ~m\n",
        "                    if good.sum() >= 2:\n",
        "                        X_fixed[ch, m] = np.interp(t[m], t[good], X_fixed[ch, good])\n",
        "            raw._data = X_fixed\n",
        "\n",
        "    def _interpolate_bad_channels_with_train_calibration(self, raw: mne.io.Raw):\n",
        "        if not self.interpolate_bad_channels:\n",
        "            return\n",
        "\n",
        "        picks = mne.pick_types(raw.info, eeg=True)\n",
        "        if len(picks) == 0:\n",
        "            return\n",
        "\n",
        "        X = raw.get_data(picks=picks)\n",
        "        ch_std = X.std(axis=1)\n",
        "\n",
        "        med = self._robust_med\n",
        "        mad = self._robust_mad\n",
        "        if med is None or mad is None or mad == 0:\n",
        "            return\n",
        "\n",
        "        z = 0.6745 * (ch_std - med) / mad\n",
        "        eeg_names = mne.pick_info(raw.info, picks).ch_names\n",
        "        bads = [eeg_names[i] for i in np.where(np.abs(z) > self.bad_channel_z)[0]]\n",
        "\n",
        "        raw.info[\"bads\"] = bads\n",
        "        if bads:\n",
        "            raw.interpolate_bads(reset_bads=True, verbose=False)\n",
        "\n",
        "    def fit(self, X_train: np.ndarray, sfreq: float):\n",
        "        C = X_train.shape[0]\n",
        "        ch_names = _names_from_index_mapping(C, self.index_to_name)\n",
        "\n",
        "        raw_train, montage_applied = _make_raw(X_train, sfreq, ch_names, self.use_standard_1020)\n",
        "        self._filter_and_reference(raw_train)\n",
        "\n",
        "        Xt = raw_train.get_data()\n",
        "        self._train_mu = Xt.mean(axis=1, keepdims=True)\n",
        "        self._train_sd = Xt.std(axis=1, keepdims=True) + 1e-12\n",
        "\n",
        "        if montage_applied:\n",
        "            picks_eeg = mne.pick_types(raw_train.info, eeg=True)\n",
        "            if len(picks_eeg):\n",
        "                X_eeg = Xt[picks_eeg]\n",
        "                ch_std = X_eeg.std(axis=1)\n",
        "                med = np.median(ch_std)\n",
        "                mad = np.median(np.abs(ch_std - med)) + 1e-12\n",
        "                self._robust_med = float(med)\n",
        "                self._robust_mad = float(mad)\n",
        "                self._train_eeg_names = mne.pick_info(raw_train.info, picks_eeg).ch_names\n",
        "            else:\n",
        "                self._robust_med = None\n",
        "                self._robust_mad = None\n",
        "        else:\n",
        "            self._robust_med = None\n",
        "            self._robust_mad = None\n",
        "\n",
        "        self._repair_transients_with_train_stats(raw_train)\n",
        "        Xt = raw_train.get_data()\n",
        "\n",
        "        if montage_applied and self.interpolate_bad_channels:\n",
        "            self._interpolate_bad_channels_with_train_calibration(raw_train)\n",
        "            Xt = raw_train.get_data()\n",
        "\n",
        "        if self.use_wica:\n",
        "            self._wica.fit(Xt)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: np.ndarray, sfreq: float) -> Tuple[np.ndarray, float]:\n",
        "        C = X.shape[0]\n",
        "        ch_names = _names_from_index_mapping(C, self.index_to_name)\n",
        "\n",
        "        raw, montage_applied = _make_raw(X, sfreq, ch_names, self.use_standard_1020)\n",
        "        self._filter_and_reference(raw)\n",
        "        self._repair_transients_with_train_stats(raw)\n",
        "\n",
        "        if montage_applied and self.interpolate_bad_channels:\n",
        "            self._interpolate_bad_channels_with_train_calibration(raw)\n",
        "\n",
        "        Xf = raw.get_data()\n",
        "        if self.use_wica:\n",
        "            Xf = self._wica.transform(Xf)\n",
        "\n",
        "        return Xf.astype(np.float32, copy=False), self.sfreq_out\n",
        "\n",
        "    def fit_transform(self, X_train: np.ndarray, sfreq: float) -> Tuple[np.ndarray, float]:\n",
        "        self.fit(X_train, sfreq)\n",
        "        X_clean, fs_out = self.transform(X_train, sfreq)\n",
        "        return X_clean, fs_out\n",
        "\n",
        "print(\"✅ Preprocessing classes loaded.\")  # progress print\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Preprocessing classes loaded.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1767930108218
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4 — NEW dataset selection rule + Azure download + load raw EEG"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore  # azure workspace + datastore\n",
        "\n",
        "print(\"[STEP 4] Connecting to Azure ML workspace...\")  # progress print\n",
        "\n",
        "# Workspace info (your values)\n",
        "subscription_id = \"eccc04ba-d8b0-4f70-864a-b4a6753bfc72\"  # subscription\n",
        "resource_group  = \"somnasnest\"  # RG\n",
        "workspace_name  = \"SomnasNest\"  # workspace\n",
        "\n",
        "ws = Workspace(  # connect\n",
        "    subscription_id=subscription_id,  # sub id\n",
        "    resource_group=resource_group,  # rg\n",
        "    workspace_name=workspace_name  # ws name\n",
        ")\n",
        "\n",
        "print(\"[STEP 4] Getting datastore 'workspaceblobstore'...\")  # progress print\n",
        "datastore = Datastore.get(ws, \"workspaceblobstore\")  # blobstore\n",
        "\n",
        "remote_prefix = \"UI/2025-12-11_033542_UTC/New Dataset\"  # remote folder inside datastore\n",
        "local_root = \"./azureml_eeg_data\"  # local download root\n",
        "os.makedirs(local_root, exist_ok=True)  # ensure folder exists\n",
        "\n",
        "print(f\"[STEP 4] Downloading datastore prefix: {remote_prefix}\")  # progress print\n",
        "n_files = datastore.download(  # download\n",
        "    target_path=local_root,  # local target\n",
        "    prefix=remote_prefix,  # remote prefix\n",
        "    overwrite=False,  # don't overwrite\n",
        "    show_progress=True,  # show progress\n",
        ")\n",
        "print(f\"[STEP 4] Downloaded {n_files} file(s).\")  # progress print\n",
        "\n",
        "base_path = os.path.join(local_root, *remote_prefix.split(\"/\"))  # local base path\n",
        "print(f\"[STEP 4] base_path = {base_path}\")  # debug print\n",
        "\n",
        "if not os.path.isdir(base_path):  # sanity check\n",
        "    raise RuntimeError(f\"[STEP 4] base_path does not exist: {base_path}\")  # error\n",
        "\n",
        "print(\"[STEP 4] Listing base_path contents:\")  # progress print\n",
        "print(os.listdir(base_path)[:10], \"...\")  # small preview\n",
        "\n",
        "# ---------------- NEW SUBJECT/SESSION SELECTION RULE ----------------\n",
        "# Rule:\n",
        "#  - sub-01..sub-59 -> only ses-1 (class 0)\n",
        "#  - sub-60..sub-71 -> only ses-2 (class 1)\n",
        "\n",
        "sub_ses1 = [f\"sub-{i:02d}\" for i in range(1, 60)]  # sub-01..sub-59\n",
        "sub_ses2 = [f\"sub-{i:02d}\" for i in range(60, 72)]  # sub-60..sub-71\n",
        "subjects_used = sub_ses1 + sub_ses2  # full list\n",
        "\n",
        "print(\"\\n[STEP 4] Dataset rule summary:\")  # progress print\n",
        "print(f\"  ses-1 subjects count: {len(sub_ses1)} (sub-01..sub-59)\")  # summary\n",
        "print(f\"  ses-2 subjects count: {len(sub_ses2)} (sub-60..sub-71)\")  # summary\n",
        "print(f\"  total subjects used : {len(subjects_used)}\")  # summary\n",
        "\n",
        "# Storage for raw trials\n",
        "raw_list = []  # EEG trials\n",
        "targets = []  # labels\n",
        "sfreqs = []  # sampling rates\n",
        "subject_ids = []  # subject id per trial\n",
        "\n",
        "print(\"\\n[STEP 4] Loading raw EEG data according to rule...\")  # progress print\n",
        "\n",
        "# Load ses-1 for sub-01..sub-59\n",
        "for sub in sub_ses1:  # loop subjects\n",
        "    session = \"ses-1\"  # only ses-1\n",
        "    path = os.path.join(base_path, sub, session)  # folder path\n",
        "    if not os.path.isdir(path):  # missing folder guard\n",
        "        print(f\"⚠️ Missing folder: {path}, skipping.\")  # warn\n",
        "        continue  # skip\n",
        "    data_list, t_list, sf_list = load_eeg_data_with_target(path, session)  # load\n",
        "    print(f\"  Loaded {len(data_list)} trial(s) from {sub}/{session}\")  # progress\n",
        "    for data, t, sf in zip(data_list, t_list, sf_list):  # append\n",
        "        raw_list.append(data.astype(np.float32, copy=False))  # store eeg\n",
        "        targets.append(int(t))  # store label\n",
        "        sfreqs.append(float(sf))  # store sf\n",
        "        subject_ids.append(sub)  # store subject\n",
        "\n",
        "# Load ses-2 for sub-60..sub-71\n",
        "for sub in sub_ses2:  # loop subjects\n",
        "    session = \"ses-2\"  # only ses-2\n",
        "    path = os.path.join(base_path, sub, session)  # folder path\n",
        "    if not os.path.isdir(path):  # missing folder guard\n",
        "        print(f\"⚠️ Missing folder: {path}, skipping.\")  # warn\n",
        "        continue  # skip\n",
        "    data_list, t_list, sf_list = load_eeg_data_with_target(path, session)  # load\n",
        "    print(f\"  Loaded {len(data_list)} trial(s) from {sub}/{session}\")  # progress\n",
        "    for data, t, sf in zip(data_list, t_list, sf_list):  # append\n",
        "        raw_list.append(data.astype(np.float32, copy=False))  # store eeg\n",
        "        targets.append(int(t))  # store label\n",
        "        sfreqs.append(float(sf))  # store sf\n",
        "        subject_ids.append(sub)  # store subject\n",
        "\n",
        "targets = np.array(targets, dtype=np.int32)  # labels to array\n",
        "subject_ids = np.array(subject_ids)  # subject ids to array\n",
        "\n",
        "print(\"\\n[STEP 4] Finished loading raw trials.\")  # progress print\n",
        "print(\"  Total trials loaded:\", len(raw_list))  # count\n",
        "print(\"  Targets shape:\", targets.shape)  # shape\n",
        "print(\"  Unique labels + counts:\", np.unique(targets, return_counts=True))  # label counts\n",
        "\n",
        "# Sampling rate checks\n",
        "sfreqs = np.array(sfreqs, dtype=np.float32)  # sf list to array\n",
        "if len(sfreqs) == 0:  # guard\n",
        "    raise RuntimeError(\"No EEG data found. Check paths / dataset.\")  # error\n",
        "\n",
        "fs = float(sfreqs[0])  # take first fs\n",
        "if not np.allclose(sfreqs, fs):  # check consistency\n",
        "    print(\"⚠️ Warning: Not all sampling frequencies are identical!\")  # warn\n",
        "print(f\"[STEP 4] Using fs={fs} Hz\")  # log\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 4] Connecting to Azure ML workspace...\n[STEP 4] Getting datastore 'workspaceblobstore'...\n[STEP 4] Downloaded 0 file(s).\n[STEP 4] base_path = ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset\n[STEP 4] Listing base_path contents:\n['CHANGES', 'code', 'dataset_description.json', 'participants.json', 'participants.tsv', 'README', 'session_1_eeg_data.csv', 'session_2_eeg_data.csv', 'sub-01', 'sub-01_eeg_data.pkl'] ...\n\n[STEP 4] Dataset rule summary:\n  ses-1 subjects count: 59 (sub-01..sub-59)\n  ses-2 subjects count: 12 (sub-60..sub-71)\n  total subjects used : 71\n\n[STEP 4] Loading raw EEG data according to rule...\n  Loaded 1 trial(s) from sub-01/ses-1\n  Loaded 1 trial(s) from sub-02/ses-1\n  Loaded 1 trial(s) from sub-03/ses-1\n  Loaded 1 trial(s) from sub-04/ses-1\n  Loaded 1 trial(s) from sub-05/ses-1\n  Loaded 1 trial(s) from sub-06/ses-1\n  Loaded 1 trial(s) from sub-07/ses-1\n  Loaded 1 trial(s) from sub-08/ses-1\n  Loaded 1 trial(s) from sub-09/ses-1\n  Loaded 1 trial(s) from sub-10/ses-1\n  Loaded 1 trial(s) from sub-11/ses-1\n  Loaded 1 trial(s) from sub-12/ses-1\n  Loaded 1 trial(s) from sub-13/ses-1\n  Loaded 1 trial(s) from sub-14/ses-1\n  Loaded 1 trial(s) from sub-15/ses-1\n  Loaded 1 trial(s) from sub-16/ses-1\n  Loaded 1 trial(s) from sub-17/ses-1\n  Loaded 1 trial(s) from sub-18/ses-1\n  Loaded 1 trial(s) from sub-19/ses-1\n  Loaded 1 trial(s) from sub-20/ses-1\n  Loaded 1 trial(s) from sub-21/ses-1\n  Loaded 1 trial(s) from sub-22/ses-1\n  Loaded 1 trial(s) from sub-23/ses-1\n  Loaded 1 trial(s) from sub-24/ses-1\n  Loaded 1 trial(s) from sub-25/ses-1\n  Loaded 1 trial(s) from sub-26/ses-1\n  Loaded 1 trial(s) from sub-27/ses-1\n  Loaded 1 trial(s) from sub-28/ses-1\n  Loaded 1 trial(s) from sub-29/ses-1\n  Loaded 1 trial(s) from sub-30/ses-1\n  Loaded 1 trial(s) from sub-31/ses-1\n  Loaded 1 trial(s) from sub-32/ses-1\n  Loaded 1 trial(s) from sub-33/ses-1\n  Loaded 1 trial(s) from sub-34/ses-1\n  Loaded 1 trial(s) from sub-35/ses-1\n  Loaded 1 trial(s) from sub-36/ses-1\n  Loaded 1 trial(s) from sub-37/ses-1\n  Loaded 1 trial(s) from sub-38/ses-1\n  Loaded 1 trial(s) from sub-39/ses-1\n  Loaded 1 trial(s) from sub-40/ses-1\n  Loaded 1 trial(s) from sub-41/ses-1\n  Loaded 1 trial(s) from sub-42/ses-1\n  Loaded 1 trial(s) from sub-44/ses-1\n  Loaded 1 trial(s) from sub-45/ses-1\n  Loaded 1 trial(s) from sub-46/ses-1\n  Loaded 1 trial(s) from sub-47/ses-1\n  Loaded 1 trial(s) from sub-48/ses-1\n  Loaded 1 trial(s) from sub-49/ses-1\n  Loaded 1 trial(s) from sub-50/ses-1\n  Loaded 1 trial(s) from sub-51/ses-1\n  Loaded 1 trial(s) from sub-52/ses-1\n  Loaded 1 trial(s) from sub-53/ses-1\n  Loaded 1 trial(s) from sub-54/ses-1\n  Loaded 1 trial(s) from sub-55/ses-1\n  Loaded 1 trial(s) from sub-56/ses-1\n  Loaded 1 trial(s) from sub-57/ses-1\n  Loaded 1 trial(s) from sub-58/ses-1\n  Loaded 1 trial(s) from sub-59/ses-1\n  Loaded 1 trial(s) from sub-60/ses-2\n  Loaded 1 trial(s) from sub-61/ses-2\n  Loaded 1 trial(s) from sub-62/ses-2\n  Loaded 1 trial(s) from sub-63/ses-2\n  Loaded 1 trial(s) from sub-64/ses-2\n  Loaded 1 trial(s) from sub-65/ses-2\n  Loaded 1 trial(s) from sub-66/ses-2\n  Loaded 1 trial(s) from sub-67/ses-2\n  Loaded 1 trial(s) from sub-68/ses-2\n  Loaded 1 trial(s) from sub-69/ses-2\n  Loaded 1 trial(s) from sub-70/ses-2\n  Loaded 1 trial(s) from sub-71/ses-2\n\n[STEP 4] Finished loading raw trials.\n  Total trials loaded: 71\n  Targets shape: (71,)\n  Unique labels + counts: (array([0, 1], dtype=int32), array([59, 12]))\n[STEP 4] Using fs=500.0 Hz\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Path already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/session_1_eeg_data.csv\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/session_2_eeg_data.csv\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-1/sub-01_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-1/sub-01_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-2/sub-01_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-2/sub-01_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01_eeg_data.pkl\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-1/sub-02_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-1/sub-02_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-2/sub-02_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-2/sub-02_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-1/sub-03_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-1/sub-03_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-2/sub-03_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-2/sub-03_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-1/sub-04_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-1/sub-04_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-2/sub-04_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-2/sub-04_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-1/sub-05_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-1/sub-05_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-2/sub-05_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-2/sub-05_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-1/sub-06_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-1/sub-06_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-2/sub-06_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-2/sub-06_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-1/sub-07_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-1/sub-07_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-2/sub-07_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-2/sub-07_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-1/sub-08_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-1/sub-08_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-2/sub-08_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-2/sub-08_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-1/sub-09_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-1/sub-09_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-2/sub-09_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-2/sub-09_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-1/sub-10_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-1/sub-10_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-2/sub-10_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-2/sub-10_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-1/sub-11_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-1/sub-11_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-2/sub-11_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-2/sub-11_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-1/sub-12_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-1/sub-12_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-2/sub-12_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-2/sub-12_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-1/sub-13_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-1/sub-13_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-2/sub-13_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-2/sub-13_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-1/sub-14_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-1/sub-14_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-2/sub-14_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-2/sub-14_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-1/sub-15_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-1/sub-15_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-2/sub-15_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-2/sub-15_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-1/sub-16_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-1/sub-16_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-2/sub-16_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-2/sub-16_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-1/sub-17_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-1/sub-17_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-2/sub-17_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-2/sub-17_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-1/sub-18_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-1/sub-18_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-2/sub-18_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-2/sub-18_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-1/sub-19_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-1/sub-19_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-2/sub-19_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-2/sub-19_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-1/sub-20_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-1/sub-20_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-2/sub-20_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-2/sub-20_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-1/sub-21_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-1/sub-21_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-2/sub-21_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-2/sub-21_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-1/sub-22_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-1/sub-22_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-2/sub-22_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-2/sub-22_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-1/sub-23_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-1/sub-23_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-2/sub-23_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-2/sub-23_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-1/sub-24_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-1/sub-24_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-2/sub-24_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-2/sub-24_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-1/sub-25_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-1/sub-25_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-2/sub-25_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-2/sub-25_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-1/sub-26_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-1/sub-26_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-2/sub-26_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-2/sub-26_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-1/sub-27_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-1/sub-27_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-2/sub-27_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-2/sub-27_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-1/sub-28_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-1/sub-28_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-2/sub-28_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-2/sub-28_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-1/sub-29_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-1/sub-29_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-2/sub-29_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-2/sub-29_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-1/sub-30_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-1/sub-30_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-2/sub-30_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-2/sub-30_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-1/sub-31_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-1/sub-31_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-2/sub-31_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-2/sub-31_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-1/sub-32_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-1/sub-32_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-2/sub-32_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-2/sub-32_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-1/sub-33_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-1/sub-33_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-2/sub-33_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-2/sub-33_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-1/sub-34_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-1/sub-34_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-2/sub-34_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-2/sub-34_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-1/sub-35_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-1/sub-35_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-2/sub-35_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-2/sub-35_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-1/sub-36_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-1/sub-36_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-2/sub-36_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-2/sub-36_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-1/sub-37_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-1/sub-37_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-2/sub-37_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-2/sub-37_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-1/sub-38_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-1/sub-38_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-2/sub-38_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-2/sub-38_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-1/sub-39_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-1/sub-39_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-2/sub-39_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-2/sub-39_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-1/sub-40_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-1/sub-40_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-2/sub-40_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-2/sub-40_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-1/sub-41_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-1/sub-41_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-2/sub-41_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-2/sub-41_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-1/sub-42_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-1/sub-42_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-2/sub-42_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-2/sub-42_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-1/sub-43_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-1/sub-43_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-2/sub-43_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-2/sub-43_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-1/sub-44_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-1/sub-44_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-2/sub-44_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-2/sub-44_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-1/sub-45_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-1/sub-45_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-2/sub-45_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-2/sub-45_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-1/sub-46_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-1/sub-46_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-2/sub-46_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-2/sub-46_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-1/sub-47_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-1/sub-47_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-2/sub-47_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-2/sub-47_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-1/sub-48_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-1/sub-48_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-2/sub-48_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-2/sub-48_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-1/sub-49_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-1/sub-49_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-2/sub-49_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-2/sub-49_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-1/sub-50_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-1/sub-50_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-2/sub-50_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-2/sub-50_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-1/sub-51_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-1/sub-51_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-2/sub-51_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-2/sub-51_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-1/sub-52_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-1/sub-52_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-2/sub-52_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-2/sub-52_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-1/sub-53_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-1/sub-53_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-2/sub-53_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-2/sub-53_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-1/sub-54_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-1/sub-54_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-2/sub-54_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-2/sub-54_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-1/sub-55_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-1/sub-55_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-2/sub-55_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-2/sub-55_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-1/sub-56_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-1/sub-56_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-2/sub-56_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-2/sub-56_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-1/sub-57_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-1/sub-57_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-2/sub-57_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-2/sub-57_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-1/sub-58_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-1/sub-58_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-2/sub-58_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-2/sub-58_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-1/sub-59_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-1/sub-59_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-2/sub-59_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-2/sub-59_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-1/sub-60_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-1/sub-60_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-2/sub-60_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-2/sub-60_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-1/sub-61_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-1/sub-61_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-2/sub-61_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-2/sub-61_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-1/sub-62_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-1/sub-62_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-2/sub-62_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-2/sub-62_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-1/sub-63_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-1/sub-63_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-2/sub-63_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-2/sub-63_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-1/sub-64_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-1/sub-64_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-2/sub-64_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-2/sub-64_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-1/sub-65_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-1/sub-65_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-2/sub-65_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-2/sub-65_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-1/sub-66_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-1/sub-66_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-2/sub-66_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-2/sub-66_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-1/sub-67_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-1/sub-67_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-2/sub-67_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-2/sub-67_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-68/ses-1/sub-68_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-68/ses-1/sub-68_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-68/ses-2/sub-68_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-68/ses-2/sub-68_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-69/ses-1/sub-69_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-69/ses-1/sub-69_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-69/ses-2/sub-69_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-69/ses-2/sub-69_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-70/ses-1/sub-70_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-70/ses-1/sub-70_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-70/ses-2/sub-70_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-70/ses-2/sub-70_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-71/ses-1/sub-71_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-71/ses-1/sub-71_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-71/ses-2/sub-71_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-71/ses-2/sub-71_ses-2_task-eyesopen_eeg.set\n/tmp/ipykernel_3126/2943896634.py:17: RuntimeWarning: Data file name in EEG.data (sub-41_ses-1_task-eyesopen_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-42_ses-1_task-eyesopen_eeg.fdt).\n  raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose=False)  # read file\n/tmp/ipykernel_3126/2943896634.py:17: RuntimeWarning: Data file name in EEG.data (sub-43_ses-1_task-eyesopen_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-44_ses-1_task-eyesopen_eeg.fdt).\n  raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose=False)  # read file\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1767930176533
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5 — Preprocess all trials"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHANNEL_MAP = None  # keep as before\n",
        "\n",
        "pre = EEGPreprocessor(  # create preprocessor\n",
        "    index_to_name=CHANNEL_MAP,  # channel map\n",
        "    use_standard_1020=True,  # montage\n",
        "    resample_to=None,  # no resample\n",
        "    notch_freqs=[50.0, 100.0, 150.0],  # notch\n",
        "    highpass=0.05,  # highpass\n",
        "    bad_point_z=6.0,  # transient repair threshold\n",
        "    bad_channel_z=5.0,  # bad channel threshold\n",
        "    interpolate_bad_channels=False,  # disabled\n",
        "    car=True,  # CAR\n",
        "    use_wica=True,  # wICA on\n",
        "    wica_components=10,  # comps\n",
        "    wica_wavelet=\"db4\",  # wavelet\n",
        "    wica_level=3,  # level\n",
        "    wica_random_state=42,  # seed\n",
        ")\n",
        "\n",
        "print(\"[STEP 5] Fitting EEGPreprocessor on a subset of loaded trials...\")  # progress print\n",
        "\n",
        "max_calib_trials = min(10, len(raw_list))  # same logic\n",
        "if max_calib_trials == 0:  # guard\n",
        "    raise RuntimeError(\"No data to fit EEGPreprocessor.\")  # error\n",
        "\n",
        "calib_trials = raw_list[:max_calib_trials]  # subset\n",
        "X_calib = np.concatenate(calib_trials, axis=1).astype(np.float32, copy=False)  # concat time-wise\n",
        "\n",
        "X_calib_clean, fs_out = pre.fit_transform(X_calib, fs)  # fit + transform\n",
        "print(f\"[STEP 5] Preprocessor fitted. Output fs: {fs_out} Hz\")  # log\n",
        "\n",
        "data_clean = []  # store cleaned trials\n",
        "for i, segment in enumerate(raw_list):  # loop trials\n",
        "    X_clean, _ = pre.transform(segment, fs)  # transform trial\n",
        "    data_clean.append(X_clean.astype(np.float32, copy=False))  # store\n",
        "    if (i + 1) % 20 == 0:  # periodic log\n",
        "        print(f\"[STEP 5] Preprocessed {i+1}/{len(raw_list)} trials\")  # progress\n",
        "\n",
        "data_clean = np.array(data_clean, dtype=np.float32)  # to array\n",
        "\n",
        "print(\"[STEP 5] Done preprocessing all trials.\")  # log\n",
        "print(\"  data_clean shape:\", data_clean.shape)  # shape\n",
        "print(\"  targets shape   :\", targets.shape)  # shape\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 5] Fitting EEGPreprocessor on a subset of loaded trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessor fitted. Output fs: 500.0 Hz\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessed 20/71 trials\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessed 40/71 trials\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessed 60/71 trials\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Done preprocessing all trials.\n  data_clean shape: (71, 61, 108000)\n  targets shape   : (71,)\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1767930275448
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6 — Augmentation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(data: np.ndarray, target: int, segment_size: int = 100):  # function\n",
        "    \"\"\"Split (C,T) trial into segments (C,segment_size) with same label.\"\"\"  # docstring\n",
        "    augmented_data = []  # segments\n",
        "    augmented_targets = []  # labels\n",
        "\n",
        "    if data.ndim == 3:  # if extra dim\n",
        "        data = data[0]  # drop it\n",
        "\n",
        "    n_segments = data.shape[1] // segment_size  # segment count\n",
        "\n",
        "    for i in range(n_segments):  # loop segments\n",
        "        seg = data[:, i * segment_size:(i + 1) * segment_size]  # slice\n",
        "        augmented_data.append(seg.astype(np.float32, copy=False))  # save\n",
        "        augmented_targets.append(int(target))  # save label\n",
        "\n",
        "    return augmented_data, augmented_targets  # return\n",
        "\n",
        "print(\"[STEP 6] Augmenting all trials...\")  # log\n",
        "\n",
        "augmented = []  # all segments\n",
        "aug_targets = []  # segment labels\n",
        "aug_subject_ids = []  # subject per segment\n",
        "\n",
        "for trial, y, subj in zip(data_clean, targets, subject_ids):  # loop trials\n",
        "    segs, ys = augment_data(trial, int(y), segment_size=100)  # segment\n",
        "    augmented.extend(segs)  # add segments\n",
        "    aug_targets.extend(ys)  # add labels\n",
        "    aug_subject_ids.extend([subj] * len(segs))  # repeat subject id\n",
        "\n",
        "augmented = np.array(augmented, dtype=np.float32)  # (N,C,Tseg)\n",
        "aug_targets = np.array(aug_targets, dtype=np.int32)  # (N,)\n",
        "aug_subject_ids = np.array(aug_subject_ids)  # (N,)\n",
        "\n",
        "print(\"[STEP 6] Augmentation done.\")  # log\n",
        "print(\"  augmented shape:\", augmented.shape)  # shape\n",
        "print(\"  aug_targets shape:\", aug_targets.shape)  # shape\n",
        "print(\"  Class counts (augmented):\", np.unique(aug_targets, return_counts=True))  # counts\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 6] Augmenting all trials...\n[STEP 6] Augmentation done.\n  augmented shape: (76680, 61, 100)\n  aug_targets shape: (76680,)\n  Class counts (augmented): (array([0, 1], dtype=int32), array([63720, 12960]))\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1767930276380
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7 — “Fair selection” step"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 7] Grouping segments by subject and class...\")  # log\n",
        "\n",
        "subject_data = defaultdict(lambda: {0: [], 1: []})  # subject -> {0:[...],1:[...]}\n",
        "\n",
        "for x, y, subj in zip(augmented, aug_targets, aug_subject_ids):  # loop samples\n",
        "    subject_data[subj][int(y)].append(x)  # store\n",
        "\n",
        "max_per_class_per_subject = 200  # same parameter\n",
        "\n",
        "selected_data = []  # selected samples\n",
        "selected_targets = []  # selected labels\n",
        "\n",
        "print(\"[STEP 7] Selecting up to 200 segments per (subject, class)...\")  # log\n",
        "\n",
        "for subj in subjects_used:  # loop all subjects in dataset\n",
        "    for class_label in [0, 1]:  # loop both classes\n",
        "        samples = subject_data.get(subj, {0: [], 1: []})[class_label]  # fetch\n",
        "        picked = samples[:max_per_class_per_subject]  # take up to 200\n",
        "        selected_data.extend(picked)  # add\n",
        "        selected_targets.extend([class_label] * len(picked))  # add labels\n",
        "\n",
        "selected_data = np.array(selected_data, dtype=np.float32)  # to array\n",
        "selected_targets = np.array(selected_targets, dtype=np.int32)  # to array\n",
        "\n",
        "print(\"[STEP 7] Selection done.\")  # log\n",
        "print(\"  selected_data shape:\", selected_data.shape)  # shape\n",
        "print(\"  selected_targets shape:\", selected_targets.shape)  # shape\n",
        "print(\"  Class counts (selected):\", np.unique(selected_targets, return_counts=True))  # counts\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 7] Grouping segments by subject and class...\n[STEP 7] Selecting up to 200 segments per (subject, class)...\n[STEP 7] Selection done.\n  selected_data shape: (14200, 61, 100)\n  selected_targets shape: (14200,)\n  Class counts (selected): (array([0, 1], dtype=int32), array([11800,  2400]))\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1767930276656
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8 — Reshape for CNN"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 8] Reshaping for CNN...\")  # log\n",
        "\n",
        "# (N,C,T) -> (N,C,T,1)\n",
        "X_all = selected_data[..., np.newaxis].astype(np.float32, copy=False)  # CNN input\n",
        "y_all = selected_targets.astype(np.int32, copy=False)  # labels\n",
        "\n",
        "print(\"[STEP 8] Done.\")  # log\n",
        "print(\"  X_all shape:\", X_all.shape)  # shape\n",
        "print(\"  y_all shape:\", y_all.shape)  # shape\n",
        "print(\"  Class counts:\", np.unique(y_all, return_counts=True))  # counts\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 8] Reshaping for CNN...\n[STEP 8] Done.\n  X_all shape: (14200, 61, 100, 1)\n  y_all shape: (14200,)\n  Class counts: (array([0, 1], dtype=int32), array([11800,  2400]))\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1767930276981
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9 — EEGNet model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(opt):  # helper\n",
        "    \"\"\"Safely read optimizer LR.\"\"\"  # docstring\n",
        "    try:\n",
        "        return float(tf.keras.backend.get_value(opt.learning_rate))  # standard\n",
        "    except Exception:\n",
        "        try:\n",
        "            return float(opt.learning_rate.numpy())  # alt\n",
        "        except Exception:\n",
        "            try:\n",
        "                return float(opt.lr.numpy())  # legacy\n",
        "            except Exception:\n",
        "                return float(getattr(opt, \"lr\", 0.0))  # fallback\n",
        "\n",
        "def create_eegnet(input_shape, dropout_rate=0.5, num_classes=1):  # EEGNet-ish\n",
        "    \"\"\"EEGNet (adapted to your pipeline).\"\"\"  # docstring\n",
        "    n_electrodes = input_shape[0]  # channels\n",
        "    inputs = Input(shape=input_shape)  # input\n",
        "\n",
        "    x = Conv2D(16, (1, 64), padding='same', use_bias=False)(inputs)  # temporal conv\n",
        "    x = BatchNormalization()(x)  # BN\n",
        "\n",
        "    x = DepthwiseConv2D((n_electrodes, 1), depth_multiplier=2, padding='valid', use_bias=False)(x)  # spatial depthwise\n",
        "    x = BatchNormalization()(x)  # BN\n",
        "    x = Activation('elu')(x)  # ELU\n",
        "    x = AveragePooling2D((1, 4))(x)  # pool\n",
        "    x = Dropout(dropout_rate)(x)  # dropout\n",
        "\n",
        "    x = SeparableConv2D(16, (1, 16), padding='same', use_bias=False)(x)  # separable conv\n",
        "    x = BatchNormalization()(x)  # BN\n",
        "    x = Activation('elu')(x)  # ELU\n",
        "    x = AveragePooling2D((1, 8))(x)  # pool\n",
        "    x = Dropout(dropout_rate)(x)  # dropout\n",
        "\n",
        "    x = Flatten()(x)  # flatten\n",
        "    x = Dense(64, activation='relu')(x)  # dense\n",
        "    outputs = Dense(num_classes, activation='sigmoid')(x)  # sigmoid output\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs, name=\"EEGNet_simple\")  # model\n",
        "\n",
        "print(\"✅ Model function defined.\")  # log\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Model function defined.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1767930277497
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10 — NEW: 10-Fold CV + per-fold normalization + SMOTE + metrics + average"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Step 10 - 10-fold (or 5-fold) CV + per-fold normalization + SMOTE + per-fold metrics + averages\n",
        "\n",
        "print(\"[STEP 10] Starting cross-validation...\")  # log\n",
        "\n",
        "n_splits = 5  # number of folds (change to 10 if you want)\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)  # stratified CV splitter\n",
        "\n",
        "# Containers for fold results\n",
        "fold_metrics = []  # store metrics dict per fold\n",
        "fold_conf_mats = []  # store confusion matrix per fold\n",
        "\n",
        "# Convenience variables\n",
        "n_electrodes = X_all.shape[1]  # number of electrodes\n",
        "segment_size = X_all.shape[2]  # segment length\n",
        "input_shape = (n_electrodes, segment_size, 1)  # model input shape\n",
        "\n",
        "print(\"[STEP 10] Input shape:\", input_shape)  # log\n",
        "print(\"[STEP 10] Global class count (before CV):\", np.unique(y_all, return_counts=True))  # log\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_all, y_all), start=1):  # loop folds\n",
        "    print(\"\\n\" + \"=\" * 70)  # separator\n",
        "    print(f\"[FOLD {fold}/{n_splits}] Building fold data...\")  # header\n",
        "\n",
        "    # ---------------- Split data ----------------\n",
        "    X_train_raw = X_all[train_idx].astype(np.float32, copy=False)  # training samples\n",
        "    y_train_raw = y_all[train_idx].astype(np.int32, copy=False)  # training labels\n",
        "    X_val_raw = X_all[val_idx].astype(np.float32, copy=False)  # validation samples\n",
        "    y_val_raw = y_all[val_idx].astype(np.int32, copy=False)  # validation labels\n",
        "\n",
        "    print(f\"[FOLD {fold}] Train size: {X_train_raw.shape[0]} | Val size: {X_val_raw.shape[0]}\")  # sizes\n",
        "    print(f\"[FOLD {fold}] Train class count (pre-balance): {np.unique(y_train_raw, return_counts=True)}\")  # counts\n",
        "    print(f\"[FOLD {fold}] Val   class count:              {np.unique(y_val_raw, return_counts=True)}\")  # counts\n",
        "\n",
        "    # ---------------- Normalization (TRAIN stats only) ----------------\n",
        "    print(f\"[FOLD {fold}] Computing normalization stats from TRAIN only...\")  # log\n",
        "\n",
        "    epsilon = 1e-6  # avoid division by zero\n",
        "    train_mean = np.mean(X_train_raw, axis=(0, 2, 3), keepdims=True).astype(np.float32)  # mean per electrode\n",
        "    train_std = np.std(X_train_raw, axis=(0, 2, 3), keepdims=True).astype(np.float32)  # std per electrode\n",
        "    train_std = np.maximum(train_std, epsilon).astype(np.float32)  # clamp std\n",
        "\n",
        "    X_train_norm = ((X_train_raw - train_mean) / train_std).astype(np.float32)  # normalized train\n",
        "    X_val_norm = ((X_val_raw - train_mean) / train_std).astype(np.float32)  # normalized val\n",
        "\n",
        "    print(f\"[FOLD {fold}] ✅ Normalization done.\")  # log\n",
        "\n",
        "    # ---------------- SMOTE balancing (TRAIN ONLY) ----------------\n",
        "    print(f\"[FOLD {fold}] Preparing data for SMOTE (flatten to 2D)...\")  # log\n",
        "\n",
        "    X_train_2d = X_train_norm.reshape(X_train_norm.shape[0], -1)  # flatten (N, features)\n",
        "\n",
        "    # Print class count BEFORE SMOTE\n",
        "    unique_before, counts_before = np.unique(y_train_raw, return_counts=True)  # counts\n",
        "    print(f\"[FOLD {fold}] ✅ Class count BEFORE SMOTE: {dict(zip(unique_before.tolist(), counts_before.tolist()))}\")  # log\n",
        "\n",
        "    # Decide if SMOTE can run safely\n",
        "    minority_n = int(np.min(counts_before))  # smallest class size\n",
        "\n",
        "    if minority_n >= 2:  # SMOTE requires at least 2 minority samples\n",
        "        k_neighbors = max(1, min(5, minority_n - 1))  # safe k_neighbors\n",
        "        smote = SMOTE(random_state=42, k_neighbors=k_neighbors)  # SMOTE object\n",
        "        X_train_bal_2d, y_train_bal_int = smote.fit_resample(X_train_2d, y_train_raw)  # apply SMOTE\n",
        "        print(f\"[FOLD {fold}] ✅ SMOTE applied (k_neighbors={k_neighbors}).\")  # log\n",
        "    else:\n",
        "        ros = RandomOverSampler(random_state=42)  # fallback oversampler\n",
        "        X_train_bal_2d, y_train_bal_int = ros.fit_resample(X_train_2d, y_train_raw)  # apply fallback\n",
        "        print(f\"[FOLD {fold}] ⚠️ SMOTE not possible (minority_n={minority_n}); used RandomOverSampler.\")  # log\n",
        "\n",
        "    # Print class count AFTER balancing (2D stage)\n",
        "    unique_after, counts_after = np.unique(y_train_bal_int, return_counts=True)  # counts\n",
        "    print(f\"[FOLD {fold}] ✅ Class count AFTER balancing (2D): {dict(zip(unique_after.tolist(), counts_after.tolist()))}\")  # log\n",
        "\n",
        "    # Reshape back to CNN format\n",
        "    print(f\"[FOLD {fold}] Reshaping back to CNN format...\")  # log\n",
        "    X_train_bal = X_train_bal_2d.reshape(-1, n_electrodes, segment_size, 1).astype(np.float32)  # reshape\n",
        "    y_train_bal = y_train_bal_int.astype(np.float32)  # keras labels float32\n",
        "\n",
        "    # Print class count AFTER balancing (final stage)\n",
        "    unique_after2, counts_after2 = np.unique(y_train_bal, return_counts=True)  # counts\n",
        "    print(f\"[FOLD {fold}] ✅ Class count AFTER balancing (final): {dict(zip(unique_after2.tolist(), counts_after2.tolist()))}\")  # log\n",
        "    print(f\"[FOLD {fold}] X_train_bal shape: {X_train_bal.shape}\")  # shape log\n",
        "\n",
        "    # Prepare val labels for keras\n",
        "    y_val_float = y_val_raw.astype(np.float32, copy=False)  # float labels\n",
        "\n",
        "    # ---------------- Build model ----------------\n",
        "    print(f\"[FOLD {fold}] Building model...\")  # log\n",
        "    model = create_eegnet(input_shape=input_shape, dropout_rate=0.5, num_classes=1)  # EEGNet\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-3),  # optimizer\n",
        "        loss=BinaryCrossentropy(from_logits=False),  # loss\n",
        "        metrics=[BinaryAccuracy(name='accuracy', threshold=0.5)]  # metric\n",
        "    )\n",
        "\n",
        "    print(f\"[FOLD {fold}] Model compiled. Initial LR={get_lr(model.optimizer)}\")  # log\n",
        "    print(model.summary())  # print summary\n",
        "\n",
        "    # ---------------- Callbacks ----------------\n",
        "    lr_scheduler = ReduceLROnPlateau(monitor=\"loss\", factor=0.5, patience=5, min_lr=1e-6, verbose=1)  # LR schedule\n",
        "    early_stop = EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True, verbose=1)  # early stop\n",
        "    ckpt = ModelCheckpoint(\n",
        "        filepath=f\"fold_{fold:02d}_best_model.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    )  # checkpoint\n",
        "    csv_logger = CSVLogger(f\"fold_{fold:02d}_training_log.csv\", append=False)  # csv log\n",
        "\n",
        "    callbacks = [lr_scheduler, early_stop, ckpt, csv_logger]  # callback list\n",
        "\n",
        "    # ---------------- Train ----------------\n",
        "    EPOCHS = 300  # epochs\n",
        "    BATCH_SIZE = 200  # batch\n",
        "\n",
        "    print(f\"[FOLD {fold}] Training started...\")  # log\n",
        "    history = model.fit(\n",
        "        X_train_bal, y_train_bal,\n",
        "        validation_data=(X_val_norm, y_val_float),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    print(f\"[FOLD {fold}] ✅ Training finished.\")  # log\n",
        "    print(f\"[FOLD {fold}] Best val_loss={float(np.min(history.history['val_loss'])):.6f}\")  # log\n",
        "\n",
        "    # ---------------- Evaluate ----------------\n",
        "    print(f\"[FOLD {fold}] Evaluating on validation fold...\")  # log\n",
        "    val_loss, val_acc = model.evaluate(X_val_norm, y_val_float, batch_size=BATCH_SIZE, verbose=1)  # evaluate\n",
        "    print(f\"[FOLD {fold}] val_loss={val_loss:.4f} | val_acc={val_acc:.4f}\")  # log\n",
        "\n",
        "    # Predict probabilities\n",
        "    print(f\"[FOLD {fold}] Predicting probabilities on validation fold...\")  # log\n",
        "    y_prob = model.predict(X_val_norm, batch_size=BATCH_SIZE, verbose=1).reshape(-1)  # probs\n",
        "    y_pred = (y_prob > 0.5).astype(int)  # binary preds\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_val_raw, y_pred)  # compute CM\n",
        "    fold_conf_mats.append(cm)  # store CM\n",
        "    print(f\"[FOLD {fold}] Confusion matrix:\\n{cm}\")  # print CM\n",
        "\n",
        "    # Extract TN, FP, FN, TP safely\n",
        "    if cm.shape == (2, 2):\n",
        "        TN, FP = int(cm[0, 0]), int(cm[0, 1])\n",
        "        FN, TP = int(cm[1, 0]), int(cm[1, 1])\n",
        "    else:\n",
        "        TN = FP = FN = TP = 0  # fallback\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = (TP + TN) / max((TP + TN + FP + FN), 1)\n",
        "    precision = TP / max((TP + FP), 1)\n",
        "    recall = TP / max((TP + FN), 1)\n",
        "    specificity = TN / max((TN + FP), 1)\n",
        "    f1 = (2 * precision * recall) / max((precision + recall), 1e-12)\n",
        "\n",
        "    # AUC (guard)\n",
        "    try:\n",
        "        auc_val = float(roc_auc_score(y_val_raw, y_prob))\n",
        "    except Exception:\n",
        "        auc_val = float(\"nan\")\n",
        "        print(f\"[FOLD {fold}] ⚠️ AUC could not be computed (likely single-class y_val).\")\n",
        "\n",
        "    # Store fold metrics\n",
        "    fold_metrics.append({\n",
        "        \"fold\": fold,\n",
        "        \"val_loss\": float(val_loss),\n",
        "        \"val_acc\": float(val_acc),\n",
        "        \"accuracy\": float(accuracy),\n",
        "        \"precision\": float(precision),\n",
        "        \"recall\": float(recall),\n",
        "        \"specificity\": float(specificity),\n",
        "        \"f1\": float(f1),\n",
        "        \"auc\": float(auc_val),\n",
        "        \"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP\n",
        "    })\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"Fold {fold} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Fold summary\n",
        "    print(f\"[FOLD {fold}] Metrics: acc={accuracy:.4f}, prec={precision:.4f}, rec={recall:.4f}, \"\n",
        "          f\"spec={specificity:.4f}, f1={f1:.4f}, auc={auc_val:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[STEP 10] Cross-validation finished.\")\n",
        "\n",
        "# ---------------- Averages ----------------\n",
        "def safe_mean(values):  # mean ignoring NaNs\n",
        "    return float(np.nanmean(np.array(values, dtype=float)))\n",
        "\n",
        "def safe_std(values):  # std ignoring NaNs\n",
        "    return float(np.nanstd(np.array(values, dtype=float)))\n",
        "\n",
        "avg_results = {\n",
        "    \"val_loss\": safe_mean([m[\"val_loss\"] for m in fold_metrics]),\n",
        "    \"val_acc\": safe_mean([m[\"val_acc\"] for m in fold_metrics]),\n",
        "    \"accuracy\": safe_mean([m[\"accuracy\"] for m in fold_metrics]),\n",
        "    \"precision\": safe_mean([m[\"precision\"] for m in fold_metrics]),\n",
        "    \"recall\": safe_mean([m[\"recall\"] for m in fold_metrics]),\n",
        "    \"specificity\": safe_mean([m[\"specificity\"] for m in fold_metrics]),\n",
        "    \"f1\": safe_mean([m[\"f1\"] for m in fold_metrics]),\n",
        "    \"auc\": safe_mean([m[\"auc\"] for m in fold_metrics]),\n",
        "}\n",
        "\n",
        "std_results = {\n",
        "    \"val_loss\": safe_std([m[\"val_loss\"] for m in fold_metrics]),\n",
        "    \"val_acc\": safe_std([m[\"val_acc\"] for m in fold_metrics]),\n",
        "    \"accuracy\": safe_std([m[\"accuracy\"] for m in fold_metrics]),\n",
        "    \"precision\": safe_std([m[\"precision\"] for m in fold_metrics]),\n",
        "    \"recall\": safe_std([m[\"recall\"] for m in fold_metrics]),\n",
        "    \"specificity\": safe_std([m[\"specificity\"] for m in fold_metrics]),\n",
        "    \"f1\": safe_std([m[\"f1\"] for m in fold_metrics]),\n",
        "    \"auc\": safe_std([m[\"auc\"] for m in fold_metrics]),\n",
        "}\n",
        "\n",
        "print(\"\\n[FINAL] Average CV metrics (mean ± std):\")\n",
        "for k in avg_results.keys():\n",
        "    print(f\"  {k:12s}: {avg_results[k]:.4f} ± {std_results[k]:.4f}\")\n",
        "\n",
        "# Summed confusion matrix across folds\n",
        "cm_sum = np.sum(np.stack(fold_conf_mats, axis=0), axis=0)\n",
        "print(\"\\n[FINAL] Sum of confusion matrices across folds:\")\n",
        "print(cm_sum)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm_sum, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Summed Confusion Matrix (All Folds)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2026-01-09 03:44:44.294308: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"EEGNet_simple\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EEGNet_simple\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m1,952\u001b[0m │\n│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,136\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,952</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,457\u001b[0m (29.13 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,457</span> (29.13 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,329\u001b[0m (28.63 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,329</span> (28.63 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "None\n[FOLD 1] Training started...\nEpoch 1/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.5848 - loss: 0.6747\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 1: val_loss improved from inf to 0.65745, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 253ms/step - accuracy: 0.5853 - loss: 0.6743 - val_accuracy: 0.7063 - val_loss: 0.6575 - learning_rate: 0.0010\nEpoch 2/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.7490 - loss: 0.5149\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2: val_loss improved from 0.65745 to 0.59919, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.7492 - loss: 0.5145 - val_accuracy: 0.7303 - val_loss: 0.5992 - learning_rate: 0.0010\nEpoch 3/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8294 - loss: 0.3903\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3: val_loss improved from 0.59919 to 0.48001, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.8295 - loss: 0.3902 - val_accuracy: 0.8081 - val_loss: 0.4800 - learning_rate: 0.0010\nEpoch 4/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8675 - loss: 0.3195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4: val_loss improved from 0.48001 to 0.35661, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.8675 - loss: 0.3195 - val_accuracy: 0.8711 - val_loss: 0.3566 - learning_rate: 0.0010\nEpoch 5/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.8769 - loss: 0.2993\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5: val_loss improved from 0.35661 to 0.31526, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.8770 - loss: 0.2992 - val_accuracy: 0.8665 - val_loss: 0.3153 - learning_rate: 0.0010\nEpoch 6/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8887 - loss: 0.2697\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6: val_loss improved from 0.31526 to 0.27105, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.8887 - loss: 0.2696 - val_accuracy: 0.8912 - val_loss: 0.2711 - learning_rate: 0.0010\nEpoch 7/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9006 - loss: 0.2485\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7: val_loss improved from 0.27105 to 0.17766, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9007 - loss: 0.2484 - val_accuracy: 0.9377 - val_loss: 0.1777 - learning_rate: 0.0010\nEpoch 8/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9144 - loss: 0.2146\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8: val_loss improved from 0.17766 to 0.17251, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9144 - loss: 0.2147 - val_accuracy: 0.9408 - val_loss: 0.1725 - learning_rate: 0.0010\nEpoch 9/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9237 - loss: 0.1973\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9: val_loss improved from 0.17251 to 0.16482, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9237 - loss: 0.1974 - val_accuracy: 0.9486 - val_loss: 0.1648 - learning_rate: 0.0010\nEpoch 10/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9245 - loss: 0.1953\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10: val_loss improved from 0.16482 to 0.11246, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9245 - loss: 0.1954 - val_accuracy: 0.9683 - val_loss: 0.1125 - learning_rate: 0.0010\nEpoch 11/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9295 - loss: 0.1849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11: val_loss did not improve from 0.11246\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.9295 - loss: 0.1849 - val_accuracy: 0.9359 - val_loss: 0.1712 - learning_rate: 0.0010\nEpoch 12/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9298 - loss: 0.1865\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12: val_loss did not improve from 0.11246\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 247ms/step - accuracy: 0.9298 - loss: 0.1866 - val_accuracy: 0.9444 - val_loss: 0.1497 - learning_rate: 0.0010\nEpoch 13/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9365 - loss: 0.1637\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13: val_loss did not improve from 0.11246\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9365 - loss: 0.1638 - val_accuracy: 0.9592 - val_loss: 0.1320 - learning_rate: 0.0010\nEpoch 14/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9366 - loss: 0.1625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14: val_loss did not improve from 0.11246\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9366 - loss: 0.1626 - val_accuracy: 0.9606 - val_loss: 0.1274 - learning_rate: 0.0010\nEpoch 15/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9402 - loss: 0.1535\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15: val_loss did not improve from 0.11246\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9402 - loss: 0.1536 - val_accuracy: 0.9581 - val_loss: 0.1270 - learning_rate: 0.0010\nEpoch 16/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9384 - loss: 0.1620\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16: val_loss did not improve from 0.11246\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9384 - loss: 0.1619 - val_accuracy: 0.9581 - val_loss: 0.1209 - learning_rate: 0.0010\nEpoch 17/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9452 - loss: 0.1464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17: val_loss improved from 0.11246 to 0.09742, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9452 - loss: 0.1465 - val_accuracy: 0.9683 - val_loss: 0.0974 - learning_rate: 0.0010\nEpoch 18/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9450 - loss: 0.1414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18: val_loss improved from 0.09742 to 0.09297, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9450 - loss: 0.1414 - val_accuracy: 0.9732 - val_loss: 0.0930 - learning_rate: 0.0010\nEpoch 19/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9492 - loss: 0.1338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19: val_loss improved from 0.09297 to 0.08141, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9492 - loss: 0.1338 - val_accuracy: 0.9764 - val_loss: 0.0814 - learning_rate: 0.0010\nEpoch 20/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9504 - loss: 0.1322\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20: val_loss did not improve from 0.08141\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9504 - loss: 0.1322 - val_accuracy: 0.9708 - val_loss: 0.0893 - learning_rate: 0.0010\nEpoch 21/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9499 - loss: 0.1289\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21: val_loss did not improve from 0.08141\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.9499 - loss: 0.1290 - val_accuracy: 0.9687 - val_loss: 0.0912 - learning_rate: 0.0010\nEpoch 22/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9489 - loss: 0.1331\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22: val_loss did not improve from 0.08141\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9489 - loss: 0.1332 - val_accuracy: 0.9701 - val_loss: 0.0903 - learning_rate: 0.0010\nEpoch 23/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9551 - loss: 0.1238\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23: val_loss did not improve from 0.08141\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9551 - loss: 0.1238 - val_accuracy: 0.9673 - val_loss: 0.0838 - learning_rate: 0.0010\nEpoch 24/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9542 - loss: 0.1191\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24: val_loss improved from 0.08141 to 0.07688, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9542 - loss: 0.1191 - val_accuracy: 0.9778 - val_loss: 0.0769 - learning_rate: 0.0010\nEpoch 25/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9540 - loss: 0.1188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25: val_loss did not improve from 0.07688\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9540 - loss: 0.1188 - val_accuracy: 0.9606 - val_loss: 0.1167 - learning_rate: 0.0010\nEpoch 26/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9486 - loss: 0.1327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26: val_loss did not improve from 0.07688\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9487 - loss: 0.1326 - val_accuracy: 0.9718 - val_loss: 0.0803 - learning_rate: 0.0010\nEpoch 27/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9563 - loss: 0.1127\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27: val_loss improved from 0.07688 to 0.06786, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 250ms/step - accuracy: 0.9563 - loss: 0.1127 - val_accuracy: 0.9796 - val_loss: 0.0679 - learning_rate: 0.0010\nEpoch 28/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9594 - loss: 0.1076\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28: val_loss improved from 0.06786 to 0.06743, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9593 - loss: 0.1077 - val_accuracy: 0.9792 - val_loss: 0.0674 - learning_rate: 0.0010\nEpoch 29/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9609 - loss: 0.1056\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29: val_loss improved from 0.06743 to 0.06093, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9608 - loss: 0.1056 - val_accuracy: 0.9806 - val_loss: 0.0609 - learning_rate: 0.0010\nEpoch 30/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9585 - loss: 0.1053\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30: val_loss did not improve from 0.06093\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9585 - loss: 0.1053 - val_accuracy: 0.9778 - val_loss: 0.0683 - learning_rate: 0.0010\nEpoch 31/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9605 - loss: 0.0976\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31: val_loss did not improve from 0.06093\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9605 - loss: 0.0977 - val_accuracy: 0.9792 - val_loss: 0.0678 - learning_rate: 0.0010\nEpoch 32/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9629 - loss: 0.0950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32: val_loss did not improve from 0.06093\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9629 - loss: 0.0950 - val_accuracy: 0.9746 - val_loss: 0.0709 - learning_rate: 0.0010\nEpoch 33/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9655 - loss: 0.0935\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33: val_loss did not improve from 0.06093\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9655 - loss: 0.0935 - val_accuracy: 0.9729 - val_loss: 0.0777 - learning_rate: 0.0010\nEpoch 34/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9614 - loss: 0.1015\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34: val_loss improved from 0.06093 to 0.05656, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9614 - loss: 0.1014 - val_accuracy: 0.9817 - val_loss: 0.0566 - learning_rate: 0.0010\nEpoch 35/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9668 - loss: 0.0881\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35: val_loss did not improve from 0.05656\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9668 - loss: 0.0882 - val_accuracy: 0.9743 - val_loss: 0.0697 - learning_rate: 0.0010\nEpoch 36/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9644 - loss: 0.0945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36: val_loss did not improve from 0.05656\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9644 - loss: 0.0946 - val_accuracy: 0.9778 - val_loss: 0.0681 - learning_rate: 0.0010\nEpoch 37/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9698 - loss: 0.0856\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37: val_loss did not improve from 0.05656\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9697 - loss: 0.0856 - val_accuracy: 0.9796 - val_loss: 0.0628 - learning_rate: 0.0010\nEpoch 38/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9667 - loss: 0.0880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38: val_loss improved from 0.05656 to 0.05419, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9667 - loss: 0.0881 - val_accuracy: 0.9849 - val_loss: 0.0542 - learning_rate: 0.0010\nEpoch 39/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9713 - loss: 0.0831\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39: val_loss did not improve from 0.05419\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9712 - loss: 0.0831 - val_accuracy: 0.9813 - val_loss: 0.0631 - learning_rate: 0.0010\nEpoch 40/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9715 - loss: 0.0800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40: val_loss did not improve from 0.05419\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9714 - loss: 0.0800 - val_accuracy: 0.9750 - val_loss: 0.0762 - learning_rate: 0.0010\nEpoch 41/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9703 - loss: 0.0833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41: val_loss did not improve from 0.05419\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9703 - loss: 0.0833 - val_accuracy: 0.9810 - val_loss: 0.0610 - learning_rate: 0.0010\nEpoch 42/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9677 - loss: 0.0892\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42: val_loss did not improve from 0.05419\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9677 - loss: 0.0892 - val_accuracy: 0.9771 - val_loss: 0.0634 - learning_rate: 0.0010\nEpoch 43/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9704 - loss: 0.0797\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43: val_loss did not improve from 0.05419\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9704 - loss: 0.0797 - val_accuracy: 0.9842 - val_loss: 0.0562 - learning_rate: 0.0010\nEpoch 44/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9710 - loss: 0.0769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44: val_loss did not improve from 0.05419\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9710 - loss: 0.0769 - val_accuracy: 0.9838 - val_loss: 0.0552 - learning_rate: 0.0010\nEpoch 45/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9711 - loss: 0.0823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45: val_loss did not improve from 0.05419\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 274ms/step - accuracy: 0.9711 - loss: 0.0823 - val_accuracy: 0.9842 - val_loss: 0.0566 - learning_rate: 0.0010\nEpoch 46/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9696 - loss: 0.0874\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46: val_loss improved from 0.05419 to 0.05383, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 281ms/step - accuracy: 0.9696 - loss: 0.0875 - val_accuracy: 0.9866 - val_loss: 0.0538 - learning_rate: 0.0010\nEpoch 47/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9753 - loss: 0.0663\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47: val_loss improved from 0.05383 to 0.04833, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 270ms/step - accuracy: 0.9753 - loss: 0.0664 - val_accuracy: 0.9866 - val_loss: 0.0483 - learning_rate: 0.0010\nEpoch 48/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9739 - loss: 0.0775\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48: val_loss did not improve from 0.04833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9739 - loss: 0.0775 - val_accuracy: 0.9852 - val_loss: 0.0523 - learning_rate: 0.0010\nEpoch 49/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9768 - loss: 0.0662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49: val_loss did not improve from 0.04833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 270ms/step - accuracy: 0.9768 - loss: 0.0663 - val_accuracy: 0.9799 - val_loss: 0.0610 - learning_rate: 0.0010\nEpoch 50/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9753 - loss: 0.0730\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50: val_loss did not improve from 0.04833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 276ms/step - accuracy: 0.9752 - loss: 0.0731 - val_accuracy: 0.9827 - val_loss: 0.0574 - learning_rate: 0.0010\nEpoch 51/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9750 - loss: 0.0716\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51: val_loss did not improve from 0.04833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9750 - loss: 0.0716 - val_accuracy: 0.9817 - val_loss: 0.0564 - learning_rate: 0.0010\nEpoch 52/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9736 - loss: 0.0694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 52: val_loss did not improve from 0.04833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 268ms/step - accuracy: 0.9736 - loss: 0.0695 - val_accuracy: 0.9838 - val_loss: 0.0563 - learning_rate: 0.0010\nEpoch 53/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9773 - loss: 0.0638\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53: val_loss did not improve from 0.04833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9773 - loss: 0.0638 - val_accuracy: 0.9845 - val_loss: 0.0488 - learning_rate: 0.0010\nEpoch 54/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9762 - loss: 0.0687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54: val_loss improved from 0.04833 to 0.03788, saving model to fold_01_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 277ms/step - accuracy: 0.9762 - loss: 0.0688 - val_accuracy: 0.9891 - val_loss: 0.0379 - learning_rate: 0.0010\nEpoch 55/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9769 - loss: 0.0700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9769 - loss: 0.0700 - val_accuracy: 0.9856 - val_loss: 0.0482 - learning_rate: 0.0010\nEpoch 56/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9784 - loss: 0.0649\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 56: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9784 - loss: 0.0649 - val_accuracy: 0.9725 - val_loss: 0.0829 - learning_rate: 0.0010\nEpoch 57/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9718 - loss: 0.0681\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 57: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.9718 - loss: 0.0681 - val_accuracy: 0.9880 - val_loss: 0.0424 - learning_rate: 0.0010\nEpoch 58/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 0.9741 - loss: 0.0732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 58: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 274ms/step - accuracy: 0.9740 - loss: 0.0733 - val_accuracy: 0.9852 - val_loss: 0.0455 - learning_rate: 0.0010\nEpoch 59/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9777 - loss: 0.0628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 59: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 293ms/step - accuracy: 0.9777 - loss: 0.0628 - val_accuracy: 0.9877 - val_loss: 0.0427 - learning_rate: 0.0010\nEpoch 60/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9773 - loss: 0.0623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 60: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 275ms/step - accuracy: 0.9773 - loss: 0.0623 - val_accuracy: 0.9838 - val_loss: 0.0495 - learning_rate: 0.0010\nEpoch 61/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9792 - loss: 0.0588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 61: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9792 - loss: 0.0588 - val_accuracy: 0.9827 - val_loss: 0.0480 - learning_rate: 0.0010\nEpoch 62/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9811 - loss: 0.0563\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 62: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9810 - loss: 0.0563 - val_accuracy: 0.9799 - val_loss: 0.0616 - learning_rate: 0.0010\nEpoch 63/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9711 - loss: 0.0772\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 63: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9711 - loss: 0.0771 - val_accuracy: 0.9856 - val_loss: 0.0420 - learning_rate: 0.0010\nEpoch 64/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9781 - loss: 0.0611\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 64: val_loss did not improve from 0.03788\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9781 - loss: 0.0611 - val_accuracy: 0.9887 - val_loss: 0.0411 - learning_rate: 0.0010\nEpoch 64: early stopping\nRestoring model weights from the end of the best epoch: 54.\n[FOLD 1] ✅ Training finished.\n[FOLD 1] Best val_loss=0.037877\n[FOLD 1] Evaluating on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9917 - loss: 0.0311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 1] val_loss=0.0379 | val_acc=0.9891\n[FOLD 1] Predicting probabilities on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 1] Confusion matrix:\n[[2342   18]\n [  13  467]]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 500x400 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[FOLD 1] Metrics: acc=0.9891, prec=0.9629, rec=0.9729, spec=0.9924, f1=0.9679, auc=0.9963\n\n======================================================================\n[FOLD 2/5] Building fold data...\n[FOLD 2] Train size: 11360 | Val size: 2840\n[FOLD 2] Train class count (pre-balance): (array([0, 1], dtype=int32), array([9440, 1920]))\n[FOLD 2] Val   class count:              (array([0, 1], dtype=int32), array([2360,  480]))\n[FOLD 2] Computing normalization stats from TRAIN only...\n[FOLD 2] ✅ Normalization done.\n[FOLD 2] Preparing data for SMOTE (flatten to 2D)...\n[FOLD 2] ✅ Class count BEFORE SMOTE: {0: 9440, 1: 1920}\n[FOLD 2] ✅ SMOTE applied (k_neighbors=5).\n[FOLD 2] ✅ Class count AFTER balancing (2D): {0: 9440, 1: 9440}\n[FOLD 2] Reshaping back to CNN format...\n[FOLD 2] ✅ Class count AFTER balancing (final): {0.0: 9440, 1.0: 9440}\n[FOLD 2] X_train_bal shape: (18880, 61, 100, 1)\n[FOLD 2] Building model...\n[FOLD 2] Model compiled. Initial LR=0.0010000000474974513\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"EEGNet_simple\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EEGNet_simple\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m1,952\u001b[0m │\n│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,136\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,952</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,457\u001b[0m (29.13 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,457</span> (29.13 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,329\u001b[0m (28.63 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,329</span> (28.63 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "None\n[FOLD 2] Training started...\nEpoch 1/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.5849 - loss: 0.6658\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 1: val_loss improved from inf to 0.81447, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 268ms/step - accuracy: 0.5855 - loss: 0.6654 - val_accuracy: 0.1926 - val_loss: 0.8145 - learning_rate: 0.0010\nEpoch 2/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.7296 - loss: 0.5411\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2: val_loss did not improve from 0.81447\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.7298 - loss: 0.5409 - val_accuracy: 0.3063 - val_loss: 0.9172 - learning_rate: 0.0010\nEpoch 3/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.8104 - loss: 0.4204\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3: val_loss improved from 0.81447 to 0.66694, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.8105 - loss: 0.4202 - val_accuracy: 0.6373 - val_loss: 0.6669 - learning_rate: 0.0010\nEpoch 4/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.8437 - loss: 0.3576\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4: val_loss improved from 0.66694 to 0.48470, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.8438 - loss: 0.3575 - val_accuracy: 0.7634 - val_loss: 0.4847 - learning_rate: 0.0010\nEpoch 5/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.8689 - loss: 0.3032\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5: val_loss improved from 0.48470 to 0.36452, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.8690 - loss: 0.3031 - val_accuracy: 0.8320 - val_loss: 0.3645 - learning_rate: 0.0010\nEpoch 6/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.8893 - loss: 0.2707\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6: val_loss improved from 0.36452 to 0.27677, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.8893 - loss: 0.2707 - val_accuracy: 0.8845 - val_loss: 0.2768 - learning_rate: 0.0010\nEpoch 7/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9063 - loss: 0.2372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7: val_loss improved from 0.27677 to 0.27070, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9063 - loss: 0.2372 - val_accuracy: 0.8884 - val_loss: 0.2707 - learning_rate: 0.0010\nEpoch 8/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9098 - loss: 0.2237\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8: val_loss improved from 0.27070 to 0.20513, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 284ms/step - accuracy: 0.9098 - loss: 0.2236 - val_accuracy: 0.9250 - val_loss: 0.2051 - learning_rate: 0.0010\nEpoch 9/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9175 - loss: 0.2103\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9: val_loss improved from 0.20513 to 0.16310, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 288ms/step - accuracy: 0.9174 - loss: 0.2104 - val_accuracy: 0.9401 - val_loss: 0.1631 - learning_rate: 0.0010\nEpoch 10/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 0.9218 - loss: 0.1972\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10: val_loss improved from 0.16310 to 0.16176, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 271ms/step - accuracy: 0.9218 - loss: 0.1973 - val_accuracy: 0.9412 - val_loss: 0.1618 - learning_rate: 0.0010\nEpoch 11/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9219 - loss: 0.1991\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11: val_loss did not improve from 0.16176\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 278ms/step - accuracy: 0.9219 - loss: 0.1991 - val_accuracy: 0.9373 - val_loss: 0.1680 - learning_rate: 0.0010\nEpoch 12/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9224 - loss: 0.1983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12: val_loss improved from 0.16176 to 0.13831, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 286ms/step - accuracy: 0.9224 - loss: 0.1982 - val_accuracy: 0.9525 - val_loss: 0.1383 - learning_rate: 0.0010\nEpoch 13/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9402 - loss: 0.1633\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13: val_loss improved from 0.13831 to 0.11422, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 287ms/step - accuracy: 0.9402 - loss: 0.1633 - val_accuracy: 0.9599 - val_loss: 0.1142 - learning_rate: 0.0010\nEpoch 14/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9359 - loss: 0.1663\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14: val_loss did not improve from 0.11422\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 285ms/step - accuracy: 0.9358 - loss: 0.1664 - val_accuracy: 0.9651 - val_loss: 0.1155 - learning_rate: 0.0010\nEpoch 15/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9368 - loss: 0.1686\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15: val_loss improved from 0.11422 to 0.10921, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 286ms/step - accuracy: 0.9368 - loss: 0.1687 - val_accuracy: 0.9644 - val_loss: 0.1092 - learning_rate: 0.0010\nEpoch 16/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9373 - loss: 0.1614\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16: val_loss improved from 0.10921 to 0.10053, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.9373 - loss: 0.1614 - val_accuracy: 0.9658 - val_loss: 0.1005 - learning_rate: 0.0010\nEpoch 17/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9443 - loss: 0.1486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17: val_loss did not improve from 0.10053\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9443 - loss: 0.1487 - val_accuracy: 0.9637 - val_loss: 0.1024 - learning_rate: 0.0010\nEpoch 18/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9422 - loss: 0.1448\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18: val_loss did not improve from 0.10053\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9422 - loss: 0.1449 - val_accuracy: 0.9641 - val_loss: 0.1058 - learning_rate: 0.0010\nEpoch 19/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 0.9448 - loss: 0.1477\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19: val_loss improved from 0.10053 to 0.09414, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 287ms/step - accuracy: 0.9448 - loss: 0.1478 - val_accuracy: 0.9694 - val_loss: 0.0941 - learning_rate: 0.0010\nEpoch 20/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9434 - loss: 0.1459\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20: val_loss did not improve from 0.09414\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 278ms/step - accuracy: 0.9434 - loss: 0.1459 - val_accuracy: 0.9676 - val_loss: 0.0967 - learning_rate: 0.0010\nEpoch 21/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 0.9505 - loss: 0.1338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21: val_loss improved from 0.09414 to 0.08080, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 278ms/step - accuracy: 0.9505 - loss: 0.1338 - val_accuracy: 0.9754 - val_loss: 0.0808 - learning_rate: 0.0010\nEpoch 22/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9516 - loss: 0.1278\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22: val_loss did not improve from 0.08080\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 290ms/step - accuracy: 0.9515 - loss: 0.1279 - val_accuracy: 0.9697 - val_loss: 0.0855 - learning_rate: 0.0010\nEpoch 23/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9508 - loss: 0.1279\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23: val_loss improved from 0.08080 to 0.07912, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9508 - loss: 0.1280 - val_accuracy: 0.9754 - val_loss: 0.0791 - learning_rate: 0.0010\nEpoch 24/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9539 - loss: 0.1312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24: val_loss improved from 0.07912 to 0.07715, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9539 - loss: 0.1313 - val_accuracy: 0.9764 - val_loss: 0.0772 - learning_rate: 0.0010\nEpoch 25/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9496 - loss: 0.1377\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25: val_loss improved from 0.07715 to 0.07640, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.9495 - loss: 0.1377 - val_accuracy: 0.9768 - val_loss: 0.0764 - learning_rate: 0.0010\nEpoch 26/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9537 - loss: 0.1219\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26: val_loss improved from 0.07640 to 0.07592, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9536 - loss: 0.1219 - val_accuracy: 0.9764 - val_loss: 0.0759 - learning_rate: 0.0010\nEpoch 27/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9528 - loss: 0.1213\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27: val_loss improved from 0.07592 to 0.07476, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9528 - loss: 0.1214 - val_accuracy: 0.9764 - val_loss: 0.0748 - learning_rate: 0.0010\nEpoch 28/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9551 - loss: 0.1169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28: val_loss did not improve from 0.07476\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9550 - loss: 0.1170 - val_accuracy: 0.9655 - val_loss: 0.0986 - learning_rate: 0.0010\nEpoch 29/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9564 - loss: 0.1177\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29: val_loss did not improve from 0.07476\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9564 - loss: 0.1178 - val_accuracy: 0.9725 - val_loss: 0.0805 - learning_rate: 0.0010\nEpoch 30/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9600 - loss: 0.1111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30: val_loss improved from 0.07476 to 0.06265, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9600 - loss: 0.1112 - val_accuracy: 0.9827 - val_loss: 0.0627 - learning_rate: 0.0010\nEpoch 31/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9567 - loss: 0.1155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31: val_loss did not improve from 0.06265\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9567 - loss: 0.1155 - val_accuracy: 0.9792 - val_loss: 0.0660 - learning_rate: 0.0010\nEpoch 32/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9568 - loss: 0.1161\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32: val_loss did not improve from 0.06265\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 293ms/step - accuracy: 0.9567 - loss: 0.1162 - val_accuracy: 0.9810 - val_loss: 0.0634 - learning_rate: 0.0010\nEpoch 33/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9633 - loss: 0.0990\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33: val_loss improved from 0.06265 to 0.05658, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.9633 - loss: 0.0991 - val_accuracy: 0.9835 - val_loss: 0.0566 - learning_rate: 0.0010\nEpoch 34/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9547 - loss: 0.1192\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34: val_loss did not improve from 0.05658\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9547 - loss: 0.1192 - val_accuracy: 0.9789 - val_loss: 0.0617 - learning_rate: 0.0010\nEpoch 35/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9603 - loss: 0.1068\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35: val_loss did not improve from 0.05658\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9603 - loss: 0.1068 - val_accuracy: 0.9792 - val_loss: 0.0712 - learning_rate: 0.0010\nEpoch 36/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9610 - loss: 0.1076\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36: val_loss did not improve from 0.05658\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9610 - loss: 0.1076 - val_accuracy: 0.9810 - val_loss: 0.0621 - learning_rate: 0.0010\nEpoch 37/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9611 - loss: 0.1075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37: val_loss did not improve from 0.05658\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 269ms/step - accuracy: 0.9610 - loss: 0.1076 - val_accuracy: 0.9803 - val_loss: 0.0655 - learning_rate: 0.0010\nEpoch 38/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9621 - loss: 0.0975\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38: val_loss improved from 0.05658 to 0.05006, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9621 - loss: 0.0976 - val_accuracy: 0.9845 - val_loss: 0.0501 - learning_rate: 0.0010\nEpoch 39/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9620 - loss: 0.1048\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39: val_loss improved from 0.05006 to 0.04889, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9619 - loss: 0.1048 - val_accuracy: 0.9852 - val_loss: 0.0489 - learning_rate: 0.0010\nEpoch 40/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9602 - loss: 0.1093\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40: val_loss did not improve from 0.04889\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 297ms/step - accuracy: 0.9602 - loss: 0.1093 - val_accuracy: 0.9785 - val_loss: 0.0713 - learning_rate: 0.0010\nEpoch 41/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9651 - loss: 0.1021\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41: val_loss did not improve from 0.04889\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9651 - loss: 0.1021 - val_accuracy: 0.9831 - val_loss: 0.0541 - learning_rate: 0.0010\nEpoch 42/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9671 - loss: 0.0899\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42: val_loss did not improve from 0.04889\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9671 - loss: 0.0900 - val_accuracy: 0.9824 - val_loss: 0.0532 - learning_rate: 0.0010\nEpoch 43/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9645 - loss: 0.1004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43: val_loss did not improve from 0.04889\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9644 - loss: 0.1005 - val_accuracy: 0.9831 - val_loss: 0.0579 - learning_rate: 0.0010\nEpoch 44/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9689 - loss: 0.0853\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44: val_loss improved from 0.04889 to 0.04859, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9689 - loss: 0.0854 - val_accuracy: 0.9845 - val_loss: 0.0486 - learning_rate: 0.0010\nEpoch 45/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9646 - loss: 0.0959\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45: val_loss did not improve from 0.04859\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9646 - loss: 0.0960 - val_accuracy: 0.9827 - val_loss: 0.0568 - learning_rate: 0.0010\nEpoch 46/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9642 - loss: 0.0988\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46: val_loss improved from 0.04859 to 0.04840, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9642 - loss: 0.0988 - val_accuracy: 0.9859 - val_loss: 0.0484 - learning_rate: 0.0010\nEpoch 47/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9690 - loss: 0.0874\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47: val_loss improved from 0.04840 to 0.04440, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 285ms/step - accuracy: 0.9690 - loss: 0.0875 - val_accuracy: 0.9873 - val_loss: 0.0444 - learning_rate: 0.0010\nEpoch 48/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9693 - loss: 0.0875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48: val_loss did not improve from 0.04440\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9693 - loss: 0.0876 - val_accuracy: 0.9852 - val_loss: 0.0471 - learning_rate: 0.0010\nEpoch 49/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9687 - loss: 0.0867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49: val_loss did not improve from 0.04440\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9686 - loss: 0.0868 - val_accuracy: 0.9725 - val_loss: 0.0799 - learning_rate: 0.0010\nEpoch 50/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9648 - loss: 0.1021\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50: val_loss did not improve from 0.04440\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9648 - loss: 0.1021 - val_accuracy: 0.9697 - val_loss: 0.0841 - learning_rate: 0.0010\nEpoch 51/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9678 - loss: 0.0869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51: val_loss did not improve from 0.04440\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9677 - loss: 0.0869 - val_accuracy: 0.9849 - val_loss: 0.0509 - learning_rate: 0.0010\nEpoch 52/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9672 - loss: 0.0919\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 52: val_loss did not improve from 0.04440\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9672 - loss: 0.0919 - val_accuracy: 0.9856 - val_loss: 0.0474 - learning_rate: 0.0010\nEpoch 53/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9687 - loss: 0.0829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53: val_loss improved from 0.04440 to 0.03924, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 276ms/step - accuracy: 0.9687 - loss: 0.0829 - val_accuracy: 0.9877 - val_loss: 0.0392 - learning_rate: 0.0010\nEpoch 54/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9723 - loss: 0.0788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54: val_loss did not improve from 0.03924\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9722 - loss: 0.0789 - val_accuracy: 0.9863 - val_loss: 0.0495 - learning_rate: 0.0010\nEpoch 55/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9657 - loss: 0.0896\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55: val_loss did not improve from 0.03924\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.9658 - loss: 0.0896 - val_accuracy: 0.9806 - val_loss: 0.0568 - learning_rate: 0.0010\nEpoch 56/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9703 - loss: 0.0821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 56: val_loss improved from 0.03924 to 0.03755, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9702 - loss: 0.0822 - val_accuracy: 0.9852 - val_loss: 0.0375 - learning_rate: 0.0010\nEpoch 57/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9698 - loss: 0.0805\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 57: val_loss improved from 0.03755 to 0.02982, saving model to fold_02_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9698 - loss: 0.0805 - val_accuracy: 0.9937 - val_loss: 0.0298 - learning_rate: 0.0010\nEpoch 58/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9716 - loss: 0.0806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 58: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9716 - loss: 0.0806 - val_accuracy: 0.9863 - val_loss: 0.0418 - learning_rate: 0.0010\nEpoch 59/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9686 - loss: 0.0895\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 59: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9685 - loss: 0.0896 - val_accuracy: 0.9849 - val_loss: 0.0513 - learning_rate: 0.0010\nEpoch 60/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9718 - loss: 0.0754\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 60: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9718 - loss: 0.0755 - val_accuracy: 0.9898 - val_loss: 0.0349 - learning_rate: 0.0010\nEpoch 61/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9715 - loss: 0.0773\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 61: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 292ms/step - accuracy: 0.9714 - loss: 0.0773 - val_accuracy: 0.9901 - val_loss: 0.0355 - learning_rate: 0.0010\nEpoch 62/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9685 - loss: 0.0867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 62: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 279ms/step - accuracy: 0.9684 - loss: 0.0868 - val_accuracy: 0.9873 - val_loss: 0.0404 - learning_rate: 0.0010\nEpoch 63/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9695 - loss: 0.0823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 63: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9695 - loss: 0.0824 - val_accuracy: 0.9880 - val_loss: 0.0401 - learning_rate: 0.0010\nEpoch 64/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9749 - loss: 0.0689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 64: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9749 - loss: 0.0689 - val_accuracy: 0.9908 - val_loss: 0.0342 - learning_rate: 0.0010\nEpoch 65/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9732 - loss: 0.0736\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 65: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9732 - loss: 0.0736 - val_accuracy: 0.9894 - val_loss: 0.0370 - learning_rate: 0.0010\nEpoch 66/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9736 - loss: 0.0743\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 66: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9735 - loss: 0.0745 - val_accuracy: 0.9880 - val_loss: 0.0440 - learning_rate: 0.0010\nEpoch 67/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9690 - loss: 0.0810\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 67: val_loss did not improve from 0.02982\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9690 - loss: 0.0810 - val_accuracy: 0.9898 - val_loss: 0.0414 - learning_rate: 0.0010\nEpoch 67: early stopping\nRestoring model weights from the end of the best epoch: 57.\n[FOLD 2] ✅ Training finished.\n[FOLD 2] Best val_loss=0.029817\n[FOLD 2] Evaluating on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.9957 - loss: 0.0236\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 2] val_loss=0.0298 | val_acc=0.9937\n[FOLD 2] Predicting probabilities on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 2] Confusion matrix:\n[[2352    8]\n [  10  470]]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 500x400 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[FOLD 2] Metrics: acc=0.9937, prec=0.9833, rec=0.9792, spec=0.9966, f1=0.9812, auc=0.9987\n\n======================================================================\n[FOLD 3/5] Building fold data...\n[FOLD 3] Train size: 11360 | Val size: 2840\n[FOLD 3] Train class count (pre-balance): (array([0, 1], dtype=int32), array([9440, 1920]))\n[FOLD 3] Val   class count:              (array([0, 1], dtype=int32), array([2360,  480]))\n[FOLD 3] Computing normalization stats from TRAIN only...\n[FOLD 3] ✅ Normalization done.\n[FOLD 3] Preparing data for SMOTE (flatten to 2D)...\n[FOLD 3] ✅ Class count BEFORE SMOTE: {0: 9440, 1: 1920}\n[FOLD 3] ✅ SMOTE applied (k_neighbors=5).\n[FOLD 3] ✅ Class count AFTER balancing (2D): {0: 9440, 1: 9440}\n[FOLD 3] Reshaping back to CNN format...\n[FOLD 3] ✅ Class count AFTER balancing (final): {0.0: 9440, 1.0: 9440}\n[FOLD 3] X_train_bal shape: (18880, 61, 100, 1)\n[FOLD 3] Building model...\n[FOLD 3] Model compiled. Initial LR=0.0010000000474974513\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"EEGNet_simple\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EEGNet_simple\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m1,952\u001b[0m │\n│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_2              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,136\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,952</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_2              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,457\u001b[0m (29.13 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,457</span> (29.13 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,329\u001b[0m (28.63 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,329</span> (28.63 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "None\n[FOLD 3] Training started...\nEpoch 1/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.5865 - loss: 0.6683\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 1: val_loss improved from inf to 0.80975, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 270ms/step - accuracy: 0.5871 - loss: 0.6680 - val_accuracy: 0.1894 - val_loss: 0.8097 - learning_rate: 0.0010\nEpoch 2/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.7357 - loss: 0.5447\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2: val_loss did not improve from 0.80975\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.7358 - loss: 0.5446 - val_accuracy: 0.2475 - val_loss: 0.9423 - learning_rate: 0.0010\nEpoch 3/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.7755 - loss: 0.4856\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3: val_loss improved from 0.80975 to 0.75224, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.7755 - loss: 0.4854 - val_accuracy: 0.5275 - val_loss: 0.7522 - learning_rate: 0.0010\nEpoch 4/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.8242 - loss: 0.3828\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4: val_loss improved from 0.75224 to 0.43028, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.8243 - loss: 0.3826 - val_accuracy: 0.8018 - val_loss: 0.4303 - learning_rate: 0.0010\nEpoch 5/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.8767 - loss: 0.2943\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5: val_loss improved from 0.43028 to 0.32220, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.8767 - loss: 0.2943 - val_accuracy: 0.8496 - val_loss: 0.3222 - learning_rate: 0.0010\nEpoch 6/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.8910 - loss: 0.2655\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6: val_loss did not improve from 0.32220\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 274ms/step - accuracy: 0.8910 - loss: 0.2654 - val_accuracy: 0.8180 - val_loss: 0.3985 - learning_rate: 0.0010\nEpoch 7/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9059 - loss: 0.2320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7: val_loss improved from 0.32220 to 0.30042, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 265ms/step - accuracy: 0.9059 - loss: 0.2320 - val_accuracy: 0.8560 - val_loss: 0.3004 - learning_rate: 0.0010\nEpoch 8/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9156 - loss: 0.2127\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8: val_loss improved from 0.30042 to 0.25843, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.9156 - loss: 0.2127 - val_accuracy: 0.8873 - val_loss: 0.2584 - learning_rate: 0.0010\nEpoch 9/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9222 - loss: 0.1927\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9: val_loss improved from 0.25843 to 0.15383, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9222 - loss: 0.1927 - val_accuracy: 0.9465 - val_loss: 0.1538 - learning_rate: 0.0010\nEpoch 10/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9262 - loss: 0.1869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10: val_loss did not improve from 0.15383\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9262 - loss: 0.1869 - val_accuracy: 0.9391 - val_loss: 0.1608 - learning_rate: 0.0010\nEpoch 11/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9302 - loss: 0.1792\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11: val_loss improved from 0.15383 to 0.12949, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9302 - loss: 0.1793 - val_accuracy: 0.9553 - val_loss: 0.1295 - learning_rate: 0.0010\nEpoch 12/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9367 - loss: 0.1604\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12: val_loss did not improve from 0.12949\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9367 - loss: 0.1605 - val_accuracy: 0.9546 - val_loss: 0.1309 - learning_rate: 0.0010\nEpoch 13/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9443 - loss: 0.1497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13: val_loss did not improve from 0.12949\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9442 - loss: 0.1498 - val_accuracy: 0.9363 - val_loss: 0.1622 - learning_rate: 0.0010\nEpoch 14/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9401 - loss: 0.1580\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14: val_loss improved from 0.12949 to 0.09833, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9401 - loss: 0.1580 - val_accuracy: 0.9676 - val_loss: 0.0983 - learning_rate: 0.0010\nEpoch 15/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9468 - loss: 0.1375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15: val_loss did not improve from 0.09833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9468 - loss: 0.1375 - val_accuracy: 0.9461 - val_loss: 0.1368 - learning_rate: 0.0010\nEpoch 16/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9448 - loss: 0.1424\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16: val_loss did not improve from 0.09833\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9448 - loss: 0.1424 - val_accuracy: 0.9465 - val_loss: 0.1392 - learning_rate: 0.0010\nEpoch 17/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9469 - loss: 0.1395\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17: val_loss improved from 0.09833 to 0.09665, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 268ms/step - accuracy: 0.9469 - loss: 0.1395 - val_accuracy: 0.9669 - val_loss: 0.0966 - learning_rate: 0.0010\nEpoch 18/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9530 - loss: 0.1238\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18: val_loss did not improve from 0.09665\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9530 - loss: 0.1239 - val_accuracy: 0.9609 - val_loss: 0.0991 - learning_rate: 0.0010\nEpoch 19/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9532 - loss: 0.1194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19: val_loss improved from 0.09665 to 0.07701, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9532 - loss: 0.1195 - val_accuracy: 0.9754 - val_loss: 0.0770 - learning_rate: 0.0010\nEpoch 20/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9517 - loss: 0.1213\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20: val_loss improved from 0.07701 to 0.07206, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9517 - loss: 0.1213 - val_accuracy: 0.9750 - val_loss: 0.0721 - learning_rate: 0.0010\nEpoch 21/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9611 - loss: 0.1058\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21: val_loss did not improve from 0.07206\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9610 - loss: 0.1059 - val_accuracy: 0.9739 - val_loss: 0.0771 - learning_rate: 0.0010\nEpoch 22/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9562 - loss: 0.1160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22: val_loss did not improve from 0.07206\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9562 - loss: 0.1161 - val_accuracy: 0.9634 - val_loss: 0.0972 - learning_rate: 0.0010\nEpoch 23/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9548 - loss: 0.1126\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23: val_loss did not improve from 0.07206\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9548 - loss: 0.1127 - val_accuracy: 0.9715 - val_loss: 0.0726 - learning_rate: 0.0010\nEpoch 24/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9618 - loss: 0.1038\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24: val_loss improved from 0.07206 to 0.05260, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9618 - loss: 0.1038 - val_accuracy: 0.9845 - val_loss: 0.0526 - learning_rate: 0.0010\nEpoch 25/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9587 - loss: 0.1055\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25: val_loss did not improve from 0.05260\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9587 - loss: 0.1055 - val_accuracy: 0.9778 - val_loss: 0.0650 - learning_rate: 0.0010\nEpoch 26/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9613 - loss: 0.1004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26: val_loss did not improve from 0.05260\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9613 - loss: 0.1005 - val_accuracy: 0.9827 - val_loss: 0.0570 - learning_rate: 0.0010\nEpoch 27/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9634 - loss: 0.0952\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27: val_loss improved from 0.05260 to 0.04522, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9634 - loss: 0.0953 - val_accuracy: 0.9863 - val_loss: 0.0452 - learning_rate: 0.0010\nEpoch 28/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9650 - loss: 0.0894\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28: val_loss did not improve from 0.04522\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9650 - loss: 0.0894 - val_accuracy: 0.9842 - val_loss: 0.0471 - learning_rate: 0.0010\nEpoch 29/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9679 - loss: 0.0866\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29: val_loss did not improve from 0.04522\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.9678 - loss: 0.0867 - val_accuracy: 0.9859 - val_loss: 0.0480 - learning_rate: 0.0010\nEpoch 30/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9699 - loss: 0.0808\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30: val_loss improved from 0.04522 to 0.04268, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9699 - loss: 0.0808 - val_accuracy: 0.9856 - val_loss: 0.0427 - learning_rate: 0.0010\nEpoch 31/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9686 - loss: 0.0905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31: val_loss improved from 0.04268 to 0.03992, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9685 - loss: 0.0906 - val_accuracy: 0.9884 - val_loss: 0.0399 - learning_rate: 0.0010\nEpoch 32/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9726 - loss: 0.0774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32: val_loss improved from 0.03992 to 0.03736, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9725 - loss: 0.0775 - val_accuracy: 0.9856 - val_loss: 0.0374 - learning_rate: 0.0010\nEpoch 33/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9720 - loss: 0.0791\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33: val_loss did not improve from 0.03736\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.9719 - loss: 0.0792 - val_accuracy: 0.9849 - val_loss: 0.0417 - learning_rate: 0.0010\nEpoch 34/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9685 - loss: 0.0798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34: val_loss did not improve from 0.03736\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9686 - loss: 0.0797 - val_accuracy: 0.9866 - val_loss: 0.0410 - learning_rate: 0.0010\nEpoch 35/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9737 - loss: 0.0713\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35: val_loss improved from 0.03736 to 0.02835, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9736 - loss: 0.0713 - val_accuracy: 0.9915 - val_loss: 0.0283 - learning_rate: 0.0010\nEpoch 36/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9753 - loss: 0.0679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36: val_loss did not improve from 0.02835\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9753 - loss: 0.0680 - val_accuracy: 0.9915 - val_loss: 0.0305 - learning_rate: 0.0010\nEpoch 37/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9744 - loss: 0.0678\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37: val_loss did not improve from 0.02835\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9743 - loss: 0.0679 - val_accuracy: 0.9873 - val_loss: 0.0388 - learning_rate: 0.0010\nEpoch 38/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9748 - loss: 0.0663\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38: val_loss did not improve from 0.02835\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.9748 - loss: 0.0663 - val_accuracy: 0.9898 - val_loss: 0.0306 - learning_rate: 0.0010\nEpoch 39/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9773 - loss: 0.0607\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39: val_loss did not improve from 0.02835\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9772 - loss: 0.0608 - val_accuracy: 0.9651 - val_loss: 0.1044 - learning_rate: 0.0010\nEpoch 40/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9728 - loss: 0.0721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40: val_loss improved from 0.02835 to 0.02637, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9728 - loss: 0.0721 - val_accuracy: 0.9933 - val_loss: 0.0264 - learning_rate: 0.0010\nEpoch 41/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9767 - loss: 0.0628\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41: val_loss did not improve from 0.02637\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9767 - loss: 0.0629 - val_accuracy: 0.9912 - val_loss: 0.0283 - learning_rate: 0.0010\nEpoch 42/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9737 - loss: 0.0787\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42: val_loss did not improve from 0.02637\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9737 - loss: 0.0787 - val_accuracy: 0.9873 - val_loss: 0.0352 - learning_rate: 0.0010\nEpoch 43/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9771 - loss: 0.0687\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43: val_loss did not improve from 0.02637\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9770 - loss: 0.0687 - val_accuracy: 0.9894 - val_loss: 0.0317 - learning_rate: 0.0010\nEpoch 44/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9782 - loss: 0.0594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44: val_loss did not improve from 0.02637\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.9782 - loss: 0.0594 - val_accuracy: 0.9919 - val_loss: 0.0290 - learning_rate: 0.0010\nEpoch 45/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9795 - loss: 0.0572\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45: val_loss did not improve from 0.02637\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.9794 - loss: 0.0572 - val_accuracy: 0.9894 - val_loss: 0.0303 - learning_rate: 0.0010\nEpoch 46/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9785 - loss: 0.0609\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46: val_loss did not improve from 0.02637\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9785 - loss: 0.0610 - val_accuracy: 0.9908 - val_loss: 0.0315 - learning_rate: 0.0010\nEpoch 47/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9791 - loss: 0.0594\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47: val_loss did not improve from 0.02637\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.9791 - loss: 0.0595 - val_accuracy: 0.9866 - val_loss: 0.0404 - learning_rate: 0.0010\nEpoch 48/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9826 - loss: 0.0505\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48: val_loss improved from 0.02637 to 0.02025, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9826 - loss: 0.0505 - val_accuracy: 0.9947 - val_loss: 0.0202 - learning_rate: 0.0010\nEpoch 49/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9822 - loss: 0.0495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49: val_loss did not improve from 0.02025\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9822 - loss: 0.0495 - val_accuracy: 0.9525 - val_loss: 0.1493 - learning_rate: 0.0010\nEpoch 50/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9795 - loss: 0.0601\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50: val_loss did not improve from 0.02025\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 257ms/step - accuracy: 0.9795 - loss: 0.0601 - val_accuracy: 0.9930 - val_loss: 0.0232 - learning_rate: 0.0010\nEpoch 51/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9833 - loss: 0.0479\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51: val_loss did not improve from 0.02025\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9833 - loss: 0.0479 - val_accuracy: 0.9915 - val_loss: 0.0230 - learning_rate: 0.0010\nEpoch 52/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9824 - loss: 0.0497\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 52: val_loss did not improve from 0.02025\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9824 - loss: 0.0498 - val_accuracy: 0.9873 - val_loss: 0.0368 - learning_rate: 0.0010\nEpoch 53/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9822 - loss: 0.0496\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53: val_loss improved from 0.02025 to 0.01841, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9822 - loss: 0.0496 - val_accuracy: 0.9937 - val_loss: 0.0184 - learning_rate: 0.0010\nEpoch 54/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9810 - loss: 0.0534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54: val_loss did not improve from 0.01841\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.9810 - loss: 0.0535 - val_accuracy: 0.9930 - val_loss: 0.0209 - learning_rate: 0.0010\nEpoch 55/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9802 - loss: 0.0533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55: val_loss did not improve from 0.01841\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 271ms/step - accuracy: 0.9802 - loss: 0.0535 - val_accuracy: 0.9894 - val_loss: 0.0304 - learning_rate: 0.0010\nEpoch 56/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9812 - loss: 0.0519\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 56: val_loss improved from 0.01841 to 0.01782, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.9812 - loss: 0.0519 - val_accuracy: 0.9958 - val_loss: 0.0178 - learning_rate: 0.0010\nEpoch 57/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9849 - loss: 0.0420\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 57: val_loss did not improve from 0.01782\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 268ms/step - accuracy: 0.9849 - loss: 0.0420 - val_accuracy: 0.9944 - val_loss: 0.0189 - learning_rate: 0.0010\nEpoch 58/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9841 - loss: 0.0460\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 58: val_loss improved from 0.01782 to 0.01593, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 280ms/step - accuracy: 0.9841 - loss: 0.0460 - val_accuracy: 0.9958 - val_loss: 0.0159 - learning_rate: 0.0010\nEpoch 59/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9861 - loss: 0.0413\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 59: val_loss did not improve from 0.01593\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 275ms/step - accuracy: 0.9861 - loss: 0.0414 - val_accuracy: 0.9940 - val_loss: 0.0207 - learning_rate: 0.0010\nEpoch 60/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9838 - loss: 0.0431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 60: val_loss did not improve from 0.01593\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.9838 - loss: 0.0432 - val_accuracy: 0.9923 - val_loss: 0.0223 - learning_rate: 0.0010\nEpoch 61/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9841 - loss: 0.0446\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 61: val_loss did not improve from 0.01593\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9841 - loss: 0.0447 - val_accuracy: 0.9894 - val_loss: 0.0277 - learning_rate: 0.0010\nEpoch 62/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 0.9812 - loss: 0.0501\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 62: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 62: val_loss did not improve from 0.01593\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 285ms/step - accuracy: 0.9812 - loss: 0.0501 - val_accuracy: 0.9944 - val_loss: 0.0183 - learning_rate: 0.0010\nEpoch 63/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9868 - loss: 0.0368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 63: val_loss did not improve from 0.01593\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 288ms/step - accuracy: 0.9868 - loss: 0.0368 - val_accuracy: 0.9965 - val_loss: 0.0171 - learning_rate: 5.0000e-04\nEpoch 64/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9867 - loss: 0.0363\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 64: val_loss improved from 0.01593 to 0.01530, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 295ms/step - accuracy: 0.9867 - loss: 0.0363 - val_accuracy: 0.9968 - val_loss: 0.0153 - learning_rate: 5.0000e-04\nEpoch 65/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.9875 - loss: 0.0345\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 65: val_loss did not improve from 0.01530\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 283ms/step - accuracy: 0.9875 - loss: 0.0346 - val_accuracy: 0.9965 - val_loss: 0.0156 - learning_rate: 5.0000e-04\nEpoch 66/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9884 - loss: 0.0342\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 66: val_loss did not improve from 0.01530\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9884 - loss: 0.0342 - val_accuracy: 0.9937 - val_loss: 0.0175 - learning_rate: 5.0000e-04\nEpoch 67/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9869 - loss: 0.0347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 67: val_loss improved from 0.01530 to 0.01459, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9869 - loss: 0.0347 - val_accuracy: 0.9954 - val_loss: 0.0146 - learning_rate: 5.0000e-04\nEpoch 68/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9876 - loss: 0.0353\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 68: val_loss did not improve from 0.01459\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.9876 - loss: 0.0353 - val_accuracy: 0.9954 - val_loss: 0.0157 - learning_rate: 5.0000e-04\nEpoch 69/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9879 - loss: 0.0364\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 69: val_loss did not improve from 0.01459\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9879 - loss: 0.0364 - val_accuracy: 0.9961 - val_loss: 0.0150 - learning_rate: 5.0000e-04\nEpoch 70/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9884 - loss: 0.0337\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 70: val_loss did not improve from 0.01459\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9883 - loss: 0.0338 - val_accuracy: 0.9944 - val_loss: 0.0195 - learning_rate: 5.0000e-04\nEpoch 71/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9889 - loss: 0.0298\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 71: val_loss did not improve from 0.01459\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9889 - loss: 0.0299 - val_accuracy: 0.9954 - val_loss: 0.0180 - learning_rate: 5.0000e-04\nEpoch 72/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9871 - loss: 0.0358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 72: val_loss did not improve from 0.01459\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9871 - loss: 0.0358 - val_accuracy: 0.9961 - val_loss: 0.0157 - learning_rate: 5.0000e-04\nEpoch 73/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9899 - loss: 0.0285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 73: val_loss did not improve from 0.01459\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.9899 - loss: 0.0286 - val_accuracy: 0.9958 - val_loss: 0.0179 - learning_rate: 5.0000e-04\nEpoch 74/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9892 - loss: 0.0322\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 74: val_loss improved from 0.01459 to 0.01430, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 270ms/step - accuracy: 0.9892 - loss: 0.0322 - val_accuracy: 0.9958 - val_loss: 0.0143 - learning_rate: 5.0000e-04\nEpoch 75/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9888 - loss: 0.0326\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 75: val_loss improved from 0.01430 to 0.01170, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 273ms/step - accuracy: 0.9887 - loss: 0.0326 - val_accuracy: 0.9979 - val_loss: 0.0117 - learning_rate: 5.0000e-04\nEpoch 76/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9887 - loss: 0.0320\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 76: val_loss did not improve from 0.01170\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 277ms/step - accuracy: 0.9887 - loss: 0.0320 - val_accuracy: 0.9958 - val_loss: 0.0136 - learning_rate: 5.0000e-04\nEpoch 77/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 0.9905 - loss: 0.0297\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 77: val_loss did not improve from 0.01170\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 272ms/step - accuracy: 0.9905 - loss: 0.0297 - val_accuracy: 0.9951 - val_loss: 0.0153 - learning_rate: 5.0000e-04\nEpoch 78/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9901 - loss: 0.0270\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 78: val_loss did not improve from 0.01170\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9901 - loss: 0.0270 - val_accuracy: 0.9912 - val_loss: 0.0260 - learning_rate: 5.0000e-04\nEpoch 79/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9890 - loss: 0.0323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 79: val_loss did not improve from 0.01170\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 269ms/step - accuracy: 0.9890 - loss: 0.0323 - val_accuracy: 0.9937 - val_loss: 0.0182 - learning_rate: 5.0000e-04\nEpoch 80/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9887 - loss: 0.0323\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 80: val_loss did not improve from 0.01170\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 271ms/step - accuracy: 0.9887 - loss: 0.0324 - val_accuracy: 0.9961 - val_loss: 0.0144 - learning_rate: 5.0000e-04\nEpoch 81/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9882 - loss: 0.0340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 81: val_loss improved from 0.01170 to 0.01124, saving model to fold_03_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 292ms/step - accuracy: 0.9882 - loss: 0.0341 - val_accuracy: 0.9982 - val_loss: 0.0112 - learning_rate: 5.0000e-04\nEpoch 82/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9869 - loss: 0.0327\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 82: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 82: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 283ms/step - accuracy: 0.9869 - loss: 0.0328 - val_accuracy: 0.9954 - val_loss: 0.0145 - learning_rate: 5.0000e-04\nEpoch 83/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.9909 - loss: 0.0267\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 83: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 289ms/step - accuracy: 0.9909 - loss: 0.0268 - val_accuracy: 0.9972 - val_loss: 0.0135 - learning_rate: 2.5000e-04\nEpoch 84/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9887 - loss: 0.0311\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 84: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 287ms/step - accuracy: 0.9887 - loss: 0.0311 - val_accuracy: 0.9965 - val_loss: 0.0141 - learning_rate: 2.5000e-04\nEpoch 85/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.9911 - loss: 0.0259\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 85: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 287ms/step - accuracy: 0.9911 - loss: 0.0259 - val_accuracy: 0.9954 - val_loss: 0.0149 - learning_rate: 2.5000e-04\nEpoch 86/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9913 - loss: 0.0250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 86: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 284ms/step - accuracy: 0.9913 - loss: 0.0251 - val_accuracy: 0.9961 - val_loss: 0.0139 - learning_rate: 2.5000e-04\nEpoch 87/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 273ms/step - accuracy: 0.9904 - loss: 0.0286\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 87: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 280ms/step - accuracy: 0.9904 - loss: 0.0286 - val_accuracy: 0.9972 - val_loss: 0.0121 - learning_rate: 2.5000e-04\nEpoch 88/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 0.9905 - loss: 0.0279\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 88: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 275ms/step - accuracy: 0.9905 - loss: 0.0279 - val_accuracy: 0.9961 - val_loss: 0.0125 - learning_rate: 2.5000e-04\nEpoch 89/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9903 - loss: 0.0269\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 89: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9903 - loss: 0.0269 - val_accuracy: 0.9968 - val_loss: 0.0135 - learning_rate: 2.5000e-04\nEpoch 90/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.9900 - loss: 0.0253\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 90: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9901 - loss: 0.0254 - val_accuracy: 0.9961 - val_loss: 0.0124 - learning_rate: 2.5000e-04\nEpoch 91/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9904 - loss: 0.0279\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 91: val_loss did not improve from 0.01124\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9904 - loss: 0.0279 - val_accuracy: 0.9972 - val_loss: 0.0131 - learning_rate: 2.5000e-04\nEpoch 91: early stopping\nRestoring model weights from the end of the best epoch: 81.\n[FOLD 3] ✅ Training finished.\n[FOLD 3] Best val_loss=0.011236\n[FOLD 3] Evaluating on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9983 - loss: 0.0147\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 3] val_loss=0.0112 | val_acc=0.9982\n[FOLD 3] Predicting probabilities on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 3] Confusion matrix:\n[[2356    4]\n [   1  479]]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 500x400 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[FOLD 3] Metrics: acc=0.9982, prec=0.9917, rec=0.9979, spec=0.9983, f1=0.9948, auc=0.9997\n\n======================================================================\n[FOLD 4/5] Building fold data...\n[FOLD 4] Train size: 11360 | Val size: 2840\n[FOLD 4] Train class count (pre-balance): (array([0, 1], dtype=int32), array([9440, 1920]))\n[FOLD 4] Val   class count:              (array([0, 1], dtype=int32), array([2360,  480]))\n[FOLD 4] Computing normalization stats from TRAIN only...\n[FOLD 4] ✅ Normalization done.\n[FOLD 4] Preparing data for SMOTE (flatten to 2D)...\n[FOLD 4] ✅ Class count BEFORE SMOTE: {0: 9440, 1: 1920}\n[FOLD 4] ✅ SMOTE applied (k_neighbors=5).\n[FOLD 4] ✅ Class count AFTER balancing (2D): {0: 9440, 1: 9440}\n[FOLD 4] Reshaping back to CNN format...\n[FOLD 4] ✅ Class count AFTER balancing (final): {0.0: 9440, 1.0: 9440}\n[FOLD 4] X_train_bal shape: (18880, 61, 100, 1)\n[FOLD 4] Building model...\n[FOLD 4] Model compiled. Initial LR=0.0010000000474974513\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"EEGNet_simple\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EEGNet_simple\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m1,952\u001b[0m │\n│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_6             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_3              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_7             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,136\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,952</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_6             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_3              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_7             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,457\u001b[0m (29.13 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,457</span> (29.13 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,329\u001b[0m (28.63 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,329</span> (28.63 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "None\n[FOLD 4] Training started...\nEpoch 1/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.5898 - loss: 0.6650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 1: val_loss improved from inf to 0.69091, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 263ms/step - accuracy: 0.5902 - loss: 0.6647 - val_accuracy: 0.5616 - val_loss: 0.6909 - learning_rate: 0.0010\nEpoch 2/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.7219 - loss: 0.5532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2: val_loss did not improve from 0.69091\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.7219 - loss: 0.5531 - val_accuracy: 0.3377 - val_loss: 0.8307 - learning_rate: 0.0010\nEpoch 3/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 254ms/step - accuracy: 0.7725 - loss: 0.4910\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3: val_loss improved from 0.69091 to 0.66987, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 261ms/step - accuracy: 0.7726 - loss: 0.4908 - val_accuracy: 0.5915 - val_loss: 0.6699 - learning_rate: 0.0010\nEpoch 4/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.8438 - loss: 0.3699\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4: val_loss improved from 0.66987 to 0.38437, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.8438 - loss: 0.3697 - val_accuracy: 0.8282 - val_loss: 0.3844 - learning_rate: 0.0010\nEpoch 5/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.8787 - loss: 0.2883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5: val_loss improved from 0.38437 to 0.27172, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.8787 - loss: 0.2883 - val_accuracy: 0.9025 - val_loss: 0.2717 - learning_rate: 0.0010\nEpoch 6/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9035 - loss: 0.2464\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6: val_loss improved from 0.27172 to 0.25581, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 257ms/step - accuracy: 0.9034 - loss: 0.2465 - val_accuracy: 0.8944 - val_loss: 0.2558 - learning_rate: 0.0010\nEpoch 7/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9061 - loss: 0.2340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7: val_loss improved from 0.25581 to 0.22260, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9061 - loss: 0.2340 - val_accuracy: 0.9151 - val_loss: 0.2226 - learning_rate: 0.0010\nEpoch 8/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 0.9202 - loss: 0.2004\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8: val_loss improved from 0.22260 to 0.17374, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 269ms/step - accuracy: 0.9201 - loss: 0.2004 - val_accuracy: 0.9366 - val_loss: 0.1737 - learning_rate: 0.0010\nEpoch 9/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9182 - loss: 0.2103\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9: val_loss did not improve from 0.17374\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9182 - loss: 0.2102 - val_accuracy: 0.9310 - val_loss: 0.1800 - learning_rate: 0.0010\nEpoch 10/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9351 - loss: 0.1758\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10: val_loss improved from 0.17374 to 0.14103, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.9350 - loss: 0.1759 - val_accuracy: 0.9489 - val_loss: 0.1410 - learning_rate: 0.0010\nEpoch 11/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9332 - loss: 0.1751\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11: val_loss did not improve from 0.14103\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 257ms/step - accuracy: 0.9332 - loss: 0.1752 - val_accuracy: 0.9349 - val_loss: 0.1707 - learning_rate: 0.0010\nEpoch 12/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9430 - loss: 0.1550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12: val_loss improved from 0.14103 to 0.12823, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.9430 - loss: 0.1551 - val_accuracy: 0.9567 - val_loss: 0.1282 - learning_rate: 0.0010\nEpoch 13/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9404 - loss: 0.1551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13: val_loss did not improve from 0.12823\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9404 - loss: 0.1552 - val_accuracy: 0.9553 - val_loss: 0.1389 - learning_rate: 0.0010\nEpoch 14/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9445 - loss: 0.1507\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14: val_loss improved from 0.12823 to 0.11267, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9444 - loss: 0.1508 - val_accuracy: 0.9627 - val_loss: 0.1127 - learning_rate: 0.0010\nEpoch 15/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9445 - loss: 0.1475\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15: val_loss did not improve from 0.11267\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9444 - loss: 0.1476 - val_accuracy: 0.9542 - val_loss: 0.1317 - learning_rate: 0.0010\nEpoch 16/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9481 - loss: 0.1368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16: val_loss improved from 0.11267 to 0.10218, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9480 - loss: 0.1369 - val_accuracy: 0.9673 - val_loss: 0.1022 - learning_rate: 0.0010\nEpoch 17/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9529 - loss: 0.1305\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17: val_loss improved from 0.10218 to 0.09231, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9529 - loss: 0.1305 - val_accuracy: 0.9669 - val_loss: 0.0923 - learning_rate: 0.0010\nEpoch 18/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9535 - loss: 0.1254\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18: val_loss did not improve from 0.09231\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9535 - loss: 0.1254 - val_accuracy: 0.9651 - val_loss: 0.1000 - learning_rate: 0.0010\nEpoch 19/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9562 - loss: 0.1165\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19: val_loss did not improve from 0.09231\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9562 - loss: 0.1165 - val_accuracy: 0.9637 - val_loss: 0.1040 - learning_rate: 0.0010\nEpoch 20/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9566 - loss: 0.1236\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20: val_loss did not improve from 0.09231\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9566 - loss: 0.1236 - val_accuracy: 0.9648 - val_loss: 0.0998 - learning_rate: 0.0010\nEpoch 21/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9606 - loss: 0.1151\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21: val_loss did not improve from 0.09231\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9606 - loss: 0.1152 - val_accuracy: 0.9669 - val_loss: 0.1023 - learning_rate: 0.0010\nEpoch 22/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9599 - loss: 0.1072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22: val_loss improved from 0.09231 to 0.08623, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9598 - loss: 0.1074 - val_accuracy: 0.9736 - val_loss: 0.0862 - learning_rate: 0.0010\nEpoch 23/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9571 - loss: 0.1214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23: val_loss improved from 0.08623 to 0.07164, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9571 - loss: 0.1213 - val_accuracy: 0.9746 - val_loss: 0.0716 - learning_rate: 0.0010\nEpoch 24/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9609 - loss: 0.1072\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24: val_loss did not improve from 0.07164\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9609 - loss: 0.1072 - val_accuracy: 0.9746 - val_loss: 0.0724 - learning_rate: 0.0010\nEpoch 25/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9643 - loss: 0.1033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25: val_loss did not improve from 0.07164\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9643 - loss: 0.1034 - val_accuracy: 0.9750 - val_loss: 0.0790 - learning_rate: 0.0010\nEpoch 26/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9613 - loss: 0.1014\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26: val_loss improved from 0.07164 to 0.07093, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9613 - loss: 0.1014 - val_accuracy: 0.9764 - val_loss: 0.0709 - learning_rate: 0.0010\nEpoch 27/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9656 - loss: 0.0908\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27: val_loss improved from 0.07093 to 0.06837, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9656 - loss: 0.0908 - val_accuracy: 0.9771 - val_loss: 0.0684 - learning_rate: 0.0010\nEpoch 28/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9673 - loss: 0.0905\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28: val_loss improved from 0.06837 to 0.05709, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9673 - loss: 0.0906 - val_accuracy: 0.9799 - val_loss: 0.0571 - learning_rate: 0.0010\nEpoch 29/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9680 - loss: 0.0877\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29: val_loss did not improve from 0.05709\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9679 - loss: 0.0878 - val_accuracy: 0.9761 - val_loss: 0.0732 - learning_rate: 0.0010\nEpoch 30/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9680 - loss: 0.0849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30: val_loss did not improve from 0.05709\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9679 - loss: 0.0850 - val_accuracy: 0.9761 - val_loss: 0.0733 - learning_rate: 0.0010\nEpoch 31/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9679 - loss: 0.0901\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31: val_loss did not improve from 0.05709\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9679 - loss: 0.0902 - val_accuracy: 0.9806 - val_loss: 0.0617 - learning_rate: 0.0010\nEpoch 32/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9685 - loss: 0.0907\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32: val_loss improved from 0.05709 to 0.04975, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9685 - loss: 0.0908 - val_accuracy: 0.9852 - val_loss: 0.0498 - learning_rate: 0.0010\nEpoch 33/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9705 - loss: 0.0814\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33: val_loss improved from 0.04975 to 0.04477, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 254ms/step - accuracy: 0.9705 - loss: 0.0815 - val_accuracy: 0.9849 - val_loss: 0.0448 - learning_rate: 0.0010\nEpoch 34/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9694 - loss: 0.0820\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34: val_loss did not improve from 0.04477\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9694 - loss: 0.0820 - val_accuracy: 0.9838 - val_loss: 0.0494 - learning_rate: 0.0010\nEpoch 35/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9707 - loss: 0.0823\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35: val_loss did not improve from 0.04477\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9707 - loss: 0.0824 - val_accuracy: 0.9824 - val_loss: 0.0551 - learning_rate: 0.0010\nEpoch 36/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9714 - loss: 0.0784\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36: val_loss did not improve from 0.04477\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9714 - loss: 0.0784 - val_accuracy: 0.9806 - val_loss: 0.0583 - learning_rate: 0.0010\nEpoch 37/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9720 - loss: 0.0774\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37: val_loss did not improve from 0.04477\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 250ms/step - accuracy: 0.9720 - loss: 0.0774 - val_accuracy: 0.9859 - val_loss: 0.0466 - learning_rate: 0.0010\nEpoch 38/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9737 - loss: 0.0723\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38: val_loss improved from 0.04477 to 0.04397, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9737 - loss: 0.0723 - val_accuracy: 0.9866 - val_loss: 0.0440 - learning_rate: 0.0010\nEpoch 39/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9746 - loss: 0.0757\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39: val_loss did not improve from 0.04397\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.9746 - loss: 0.0758 - val_accuracy: 0.9838 - val_loss: 0.0467 - learning_rate: 0.0010\nEpoch 40/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9742 - loss: 0.0726\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40: val_loss did not improve from 0.04397\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9742 - loss: 0.0726 - val_accuracy: 0.9849 - val_loss: 0.0481 - learning_rate: 0.0010\nEpoch 41/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9753 - loss: 0.0669\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41: val_loss improved from 0.04397 to 0.04080, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9753 - loss: 0.0669 - val_accuracy: 0.9866 - val_loss: 0.0408 - learning_rate: 0.0010\nEpoch 42/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9740 - loss: 0.0812\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42: val_loss did not improve from 0.04080\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9739 - loss: 0.0812 - val_accuracy: 0.9856 - val_loss: 0.0447 - learning_rate: 0.0010\nEpoch 43/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9777 - loss: 0.0644\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43: val_loss did not improve from 0.04080\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9777 - loss: 0.0644 - val_accuracy: 0.9870 - val_loss: 0.0420 - learning_rate: 0.0010\nEpoch 44/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9792 - loss: 0.0616\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44: val_loss did not improve from 0.04080\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9792 - loss: 0.0617 - val_accuracy: 0.9866 - val_loss: 0.0414 - learning_rate: 0.0010\nEpoch 45/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 0.9783 - loss: 0.0617\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45: val_loss did not improve from 0.04080\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 265ms/step - accuracy: 0.9783 - loss: 0.0618 - val_accuracy: 0.9725 - val_loss: 0.0724 - learning_rate: 0.0010\nEpoch 46/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9721 - loss: 0.0829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46: val_loss did not improve from 0.04080\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9721 - loss: 0.0829 - val_accuracy: 0.9845 - val_loss: 0.0439 - learning_rate: 0.0010\nEpoch 47/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9805 - loss: 0.0551\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47: val_loss improved from 0.04080 to 0.04067, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9804 - loss: 0.0552 - val_accuracy: 0.9873 - val_loss: 0.0407 - learning_rate: 0.0010\nEpoch 48/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9770 - loss: 0.0640\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48: val_loss improved from 0.04067 to 0.03900, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9770 - loss: 0.0641 - val_accuracy: 0.9852 - val_loss: 0.0390 - learning_rate: 0.0010\nEpoch 49/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9821 - loss: 0.0554\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49: val_loss improved from 0.03900 to 0.03597, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9821 - loss: 0.0554 - val_accuracy: 0.9866 - val_loss: 0.0360 - learning_rate: 0.0010\nEpoch 50/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9820 - loss: 0.0516\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50: val_loss improved from 0.03597 to 0.03481, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9820 - loss: 0.0516 - val_accuracy: 0.9887 - val_loss: 0.0348 - learning_rate: 0.0010\nEpoch 51/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9803 - loss: 0.0545\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51: val_loss did not improve from 0.03481\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9802 - loss: 0.0545 - val_accuracy: 0.9859 - val_loss: 0.0403 - learning_rate: 0.0010\nEpoch 52/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9792 - loss: 0.0588\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 52: val_loss improved from 0.03481 to 0.03453, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9792 - loss: 0.0588 - val_accuracy: 0.9898 - val_loss: 0.0345 - learning_rate: 0.0010\nEpoch 53/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9834 - loss: 0.0476\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53: val_loss improved from 0.03453 to 0.03064, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9834 - loss: 0.0477 - val_accuracy: 0.9908 - val_loss: 0.0306 - learning_rate: 0.0010\nEpoch 54/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9825 - loss: 0.0491\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54: val_loss did not improve from 0.03064\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9825 - loss: 0.0491 - val_accuracy: 0.9908 - val_loss: 0.0329 - learning_rate: 0.0010\nEpoch 55/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9802 - loss: 0.0564\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 55: val_loss did not improve from 0.03064\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9802 - loss: 0.0564 - val_accuracy: 0.9863 - val_loss: 0.0411 - learning_rate: 0.0010\nEpoch 56/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9824 - loss: 0.0517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 56: val_loss improved from 0.03064 to 0.02980, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9824 - loss: 0.0517 - val_accuracy: 0.9894 - val_loss: 0.0298 - learning_rate: 5.0000e-04\nEpoch 57/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9858 - loss: 0.0441\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 57: val_loss did not improve from 0.02980\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9858 - loss: 0.0442 - val_accuracy: 0.9884 - val_loss: 0.0326 - learning_rate: 5.0000e-04\nEpoch 58/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9831 - loss: 0.0488\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 58: val_loss improved from 0.02980 to 0.02907, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9831 - loss: 0.0488 - val_accuracy: 0.9908 - val_loss: 0.0291 - learning_rate: 5.0000e-04\nEpoch 59/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9861 - loss: 0.0417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 59: val_loss improved from 0.02907 to 0.02774, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9861 - loss: 0.0418 - val_accuracy: 0.9905 - val_loss: 0.0277 - learning_rate: 5.0000e-04\nEpoch 60/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9859 - loss: 0.0402\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 60: val_loss did not improve from 0.02774\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9859 - loss: 0.0403 - val_accuracy: 0.9912 - val_loss: 0.0300 - learning_rate: 5.0000e-04\nEpoch 61/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9852 - loss: 0.0409\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 61: val_loss did not improve from 0.02774\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9852 - loss: 0.0410 - val_accuracy: 0.9898 - val_loss: 0.0318 - learning_rate: 5.0000e-04\nEpoch 62/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9865 - loss: 0.0427\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 62: val_loss improved from 0.02774 to 0.02747, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9865 - loss: 0.0428 - val_accuracy: 0.9919 - val_loss: 0.0275 - learning_rate: 5.0000e-04\nEpoch 63/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9841 - loss: 0.0474\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 63: val_loss did not improve from 0.02747\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9841 - loss: 0.0474 - val_accuracy: 0.9898 - val_loss: 0.0300 - learning_rate: 5.0000e-04\nEpoch 64/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9858 - loss: 0.0417\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 64: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 64: val_loss did not improve from 0.02747\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9858 - loss: 0.0418 - val_accuracy: 0.9912 - val_loss: 0.0292 - learning_rate: 5.0000e-04\nEpoch 65/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9858 - loss: 0.0423\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 65: val_loss improved from 0.02747 to 0.02512, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9858 - loss: 0.0423 - val_accuracy: 0.9933 - val_loss: 0.0251 - learning_rate: 2.5000e-04\nEpoch 66/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9857 - loss: 0.0431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 66: val_loss improved from 0.02512 to 0.02446, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9857 - loss: 0.0431 - val_accuracy: 0.9926 - val_loss: 0.0245 - learning_rate: 2.5000e-04\nEpoch 67/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9876 - loss: 0.0361\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 67: val_loss did not improve from 0.02446\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9875 - loss: 0.0362 - val_accuracy: 0.9926 - val_loss: 0.0252 - learning_rate: 2.5000e-04\nEpoch 68/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9877 - loss: 0.0379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 68: val_loss improved from 0.02446 to 0.02442, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9877 - loss: 0.0379 - val_accuracy: 0.9923 - val_loss: 0.0244 - learning_rate: 2.5000e-04\nEpoch 69/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9878 - loss: 0.0372\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 69: val_loss did not improve from 0.02442\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9878 - loss: 0.0373 - val_accuracy: 0.9930 - val_loss: 0.0253 - learning_rate: 2.5000e-04\nEpoch 70/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9857 - loss: 0.0406\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 70: val_loss did not improve from 0.02442\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9857 - loss: 0.0406 - val_accuracy: 0.9912 - val_loss: 0.0263 - learning_rate: 2.5000e-04\nEpoch 71/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9883 - loss: 0.0358\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 71: val_loss did not improve from 0.02442\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.9883 - loss: 0.0358 - val_accuracy: 0.9894 - val_loss: 0.0290 - learning_rate: 2.5000e-04\nEpoch 72/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9861 - loss: 0.0378\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 72: val_loss did not improve from 0.02442\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9861 - loss: 0.0378 - val_accuracy: 0.9912 - val_loss: 0.0264 - learning_rate: 2.5000e-04\nEpoch 73/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9882 - loss: 0.0370\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 73: val_loss improved from 0.02442 to 0.02439, saving model to fold_04_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9882 - loss: 0.0370 - val_accuracy: 0.9923 - val_loss: 0.0244 - learning_rate: 2.5000e-04\nEpoch 74/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 0.9868 - loss: 0.0392\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 74: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 247ms/step - accuracy: 0.9868 - loss: 0.0392 - val_accuracy: 0.9926 - val_loss: 0.0245 - learning_rate: 2.5000e-04\nEpoch 75/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9876 - loss: 0.0330\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 75: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9876 - loss: 0.0331 - val_accuracy: 0.9915 - val_loss: 0.0255 - learning_rate: 2.5000e-04\nEpoch 76/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9886 - loss: 0.0334\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 76: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 247ms/step - accuracy: 0.9885 - loss: 0.0334 - val_accuracy: 0.9894 - val_loss: 0.0280 - learning_rate: 2.5000e-04\nEpoch 77/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9858 - loss: 0.0398\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 77: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9858 - loss: 0.0399 - val_accuracy: 0.9905 - val_loss: 0.0275 - learning_rate: 2.5000e-04\nEpoch 78/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9868 - loss: 0.0369\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 78: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9868 - loss: 0.0370 - val_accuracy: 0.9912 - val_loss: 0.0268 - learning_rate: 2.5000e-04\nEpoch 79/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9894 - loss: 0.0310\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 79: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9894 - loss: 0.0310 - val_accuracy: 0.9908 - val_loss: 0.0286 - learning_rate: 2.5000e-04\nEpoch 80/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9888 - loss: 0.0338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 80: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9888 - loss: 0.0338 - val_accuracy: 0.9915 - val_loss: 0.0282 - learning_rate: 2.5000e-04\nEpoch 81/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9879 - loss: 0.0360\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 81: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9879 - loss: 0.0360 - val_accuracy: 0.9908 - val_loss: 0.0272 - learning_rate: 2.5000e-04\nEpoch 82/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9872 - loss: 0.0368\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 82: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9872 - loss: 0.0368 - val_accuracy: 0.9915 - val_loss: 0.0263 - learning_rate: 2.5000e-04\nEpoch 83/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 0.9882 - loss: 0.0349\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 83: val_loss did not improve from 0.02439\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9882 - loss: 0.0349 - val_accuracy: 0.9912 - val_loss: 0.0254 - learning_rate: 2.5000e-04\nEpoch 83: early stopping\nRestoring model weights from the end of the best epoch: 73.\n[FOLD 4] ✅ Training finished.\n[FOLD 4] Best val_loss=0.024392\n[FOLD 4] Evaluating on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9935 - loss: 0.0232\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 4] val_loss=0.0244 | val_acc=0.9923\n[FOLD 4] Predicting probabilities on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 4] Confusion matrix:\n[[2343   17]\n [   5  475]]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 500x400 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[FOLD 4] Metrics: acc=0.9923, prec=0.9654, rec=0.9896, spec=0.9928, f1=0.9774, auc=0.9991\n\n======================================================================\n[FOLD 5/5] Building fold data...\n[FOLD 5] Train size: 11360 | Val size: 2840\n[FOLD 5] Train class count (pre-balance): (array([0, 1], dtype=int32), array([9440, 1920]))\n[FOLD 5] Val   class count:              (array([0, 1], dtype=int32), array([2360,  480]))\n[FOLD 5] Computing normalization stats from TRAIN only...\n[FOLD 5] ✅ Normalization done.\n[FOLD 5] Preparing data for SMOTE (flatten to 2D)...\n[FOLD 5] ✅ Class count BEFORE SMOTE: {0: 9440, 1: 1920}\n[FOLD 5] ✅ SMOTE applied (k_neighbors=5).\n[FOLD 5] ✅ Class count AFTER balancing (2D): {0: 9440, 1: 9440}\n[FOLD 5] Reshaping back to CNN format...\n[FOLD 5] ✅ Class count AFTER balancing (final): {0.0: 9440, 1.0: 9440}\n[FOLD 5] X_train_bal shape: (18880, 61, 100, 1)\n[FOLD 5] Building model...\n[FOLD 5] Model compiled. Initial LR=0.0010000000474974513\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"EEGNet_simple\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"EEGNet_simple\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m1,952\u001b[0m │\n│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_13          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_8             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_4              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m16\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_9             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m3,136\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ depthwise_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,952</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_8             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ separable_conv2d_4              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ average_pooling2d_9             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,457\u001b[0m (29.13 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,457</span> (29.13 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,329\u001b[0m (28.63 KB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,329</span> (28.63 KB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "None\n[FOLD 5] Training started...\nEpoch 1/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.5761 - loss: 0.6738\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 1: val_loss improved from inf to 0.70699, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 252ms/step - accuracy: 0.5766 - loss: 0.6735 - val_accuracy: 0.4539 - val_loss: 0.7070 - learning_rate: 0.0010\nEpoch 2/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.7207 - loss: 0.5603\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 2: val_loss improved from 0.70699 to 0.69807, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.7209 - loss: 0.5601 - val_accuracy: 0.5229 - val_loss: 0.6981 - learning_rate: 0.0010\nEpoch 3/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.7980 - loss: 0.4495\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 3: val_loss improved from 0.69807 to 0.47990, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.7981 - loss: 0.4493 - val_accuracy: 0.7817 - val_loss: 0.4799 - learning_rate: 0.0010\nEpoch 4/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.8487 - loss: 0.3601\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 4: val_loss improved from 0.47990 to 0.33022, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.8488 - loss: 0.3600 - val_accuracy: 0.8775 - val_loss: 0.3302 - learning_rate: 0.0010\nEpoch 5/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.8707 - loss: 0.3129\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5: val_loss improved from 0.33022 to 0.31876, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.8707 - loss: 0.3129 - val_accuracy: 0.8739 - val_loss: 0.3188 - learning_rate: 0.0010\nEpoch 6/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.8952 - loss: 0.2657\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 6: val_loss improved from 0.31876 to 0.28506, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.8952 - loss: 0.2657 - val_accuracy: 0.8754 - val_loss: 0.2851 - learning_rate: 0.0010\nEpoch 7/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9007 - loss: 0.2443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 7: val_loss improved from 0.28506 to 0.19205, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9007 - loss: 0.2443 - val_accuracy: 0.9292 - val_loss: 0.1920 - learning_rate: 0.0010\nEpoch 8/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9124 - loss: 0.2285\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 8: val_loss improved from 0.19205 to 0.15812, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9124 - loss: 0.2285 - val_accuracy: 0.9447 - val_loss: 0.1581 - learning_rate: 0.0010\nEpoch 9/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9185 - loss: 0.2154\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 9: val_loss improved from 0.15812 to 0.12460, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9185 - loss: 0.2154 - val_accuracy: 0.9627 - val_loss: 0.1246 - learning_rate: 0.0010\nEpoch 10/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9195 - loss: 0.2057\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 10: val_loss did not improve from 0.12460\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9195 - loss: 0.2057 - val_accuracy: 0.9613 - val_loss: 0.1291 - learning_rate: 0.0010\nEpoch 11/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9272 - loss: 0.1934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 11: val_loss did not improve from 0.12460\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9272 - loss: 0.1935 - val_accuracy: 0.9577 - val_loss: 0.1282 - learning_rate: 0.0010\nEpoch 12/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9299 - loss: 0.1826\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 12: val_loss did not improve from 0.12460\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9298 - loss: 0.1826 - val_accuracy: 0.9574 - val_loss: 0.1298 - learning_rate: 0.0010\nEpoch 13/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9362 - loss: 0.1734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 13: val_loss did not improve from 0.12460\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9362 - loss: 0.1735 - val_accuracy: 0.9532 - val_loss: 0.1303 - learning_rate: 0.0010\nEpoch 14/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9340 - loss: 0.1733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 14: val_loss improved from 0.12460 to 0.12267, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.9340 - loss: 0.1734 - val_accuracy: 0.9606 - val_loss: 0.1227 - learning_rate: 0.0010\nEpoch 15/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9317 - loss: 0.1790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 15: val_loss improved from 0.12267 to 0.08517, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9316 - loss: 0.1791 - val_accuracy: 0.9722 - val_loss: 0.0852 - learning_rate: 0.0010\nEpoch 16/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9424 - loss: 0.1534\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 16: val_loss did not improve from 0.08517\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9423 - loss: 0.1534 - val_accuracy: 0.9655 - val_loss: 0.1048 - learning_rate: 0.0010\nEpoch 17/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9417 - loss: 0.1542\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 17: val_loss did not improve from 0.08517\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9416 - loss: 0.1544 - val_accuracy: 0.9532 - val_loss: 0.1378 - learning_rate: 0.0010\nEpoch 18/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9438 - loss: 0.1536\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 18: val_loss did not improve from 0.08517\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9437 - loss: 0.1536 - val_accuracy: 0.9694 - val_loss: 0.0973 - learning_rate: 0.0010\nEpoch 19/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9414 - loss: 0.1541\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 19: val_loss did not improve from 0.08517\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9414 - loss: 0.1542 - val_accuracy: 0.9683 - val_loss: 0.0893 - learning_rate: 0.0010\nEpoch 20/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9448 - loss: 0.1532\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 20: val_loss did not improve from 0.08517\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9448 - loss: 0.1532 - val_accuracy: 0.9701 - val_loss: 0.0882 - learning_rate: 0.0010\nEpoch 21/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9440 - loss: 0.1431\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 21: val_loss improved from 0.08517 to 0.08308, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9440 - loss: 0.1432 - val_accuracy: 0.9736 - val_loss: 0.0831 - learning_rate: 0.0010\nEpoch 22/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9467 - loss: 0.1414\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 22: val_loss did not improve from 0.08308\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9467 - loss: 0.1415 - val_accuracy: 0.8856 - val_loss: 0.3380 - learning_rate: 0.0010\nEpoch 23/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9320 - loss: 0.1842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 23: val_loss improved from 0.08308 to 0.07662, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9321 - loss: 0.1839 - val_accuracy: 0.9750 - val_loss: 0.0766 - learning_rate: 0.0010\nEpoch 24/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9482 - loss: 0.1359\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 24: val_loss did not improve from 0.07662\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9482 - loss: 0.1360 - val_accuracy: 0.9725 - val_loss: 0.0860 - learning_rate: 0.0010\nEpoch 25/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9490 - loss: 0.1365\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 25: val_loss did not improve from 0.07662\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 268ms/step - accuracy: 0.9490 - loss: 0.1366 - val_accuracy: 0.9729 - val_loss: 0.0774 - learning_rate: 0.0010\nEpoch 26/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.9480 - loss: 0.1379\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 26: val_loss did not improve from 0.07662\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 277ms/step - accuracy: 0.9480 - loss: 0.1379 - val_accuracy: 0.9690 - val_loss: 0.0907 - learning_rate: 0.0010\nEpoch 27/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9501 - loss: 0.1341\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 27: val_loss did not improve from 0.07662\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 268ms/step - accuracy: 0.9501 - loss: 0.1342 - val_accuracy: 0.9746 - val_loss: 0.0768 - learning_rate: 0.0010\nEpoch 28/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 0.9499 - loss: 0.1347\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 28: val_loss did not improve from 0.07662\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 263ms/step - accuracy: 0.9499 - loss: 0.1347 - val_accuracy: 0.9732 - val_loss: 0.0835 - learning_rate: 0.0010\nEpoch 29/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 0.9512 - loss: 0.1306\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 29: val_loss improved from 0.07662 to 0.06918, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 261ms/step - accuracy: 0.9512 - loss: 0.1306 - val_accuracy: 0.9782 - val_loss: 0.0692 - learning_rate: 0.0010\nEpoch 30/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9517 - loss: 0.1292\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 30: val_loss improved from 0.06918 to 0.06317, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9517 - loss: 0.1292 - val_accuracy: 0.9792 - val_loss: 0.0632 - learning_rate: 0.0010\nEpoch 31/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9569 - loss: 0.1204\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 31: val_loss did not improve from 0.06317\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.9569 - loss: 0.1205 - val_accuracy: 0.9796 - val_loss: 0.0660 - learning_rate: 0.0010\nEpoch 32/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9560 - loss: 0.1170\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 32: val_loss did not improve from 0.06317\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.9559 - loss: 0.1170 - val_accuracy: 0.9799 - val_loss: 0.0667 - learning_rate: 0.0010\nEpoch 33/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9550 - loss: 0.1214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 33: val_loss improved from 0.06317 to 0.05791, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 260ms/step - accuracy: 0.9550 - loss: 0.1214 - val_accuracy: 0.9831 - val_loss: 0.0579 - learning_rate: 0.0010\nEpoch 34/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9572 - loss: 0.1188\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 34: val_loss did not improve from 0.05791\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9572 - loss: 0.1188 - val_accuracy: 0.9813 - val_loss: 0.0588 - learning_rate: 0.0010\nEpoch 35/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9572 - loss: 0.1195\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 35: val_loss did not improve from 0.05791\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9571 - loss: 0.1196 - val_accuracy: 0.9789 - val_loss: 0.0670 - learning_rate: 0.0010\nEpoch 36/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9567 - loss: 0.1155\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 36: val_loss improved from 0.05791 to 0.05585, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 259ms/step - accuracy: 0.9567 - loss: 0.1155 - val_accuracy: 0.9817 - val_loss: 0.0558 - learning_rate: 0.0010\nEpoch 37/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9567 - loss: 0.1185\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 37: val_loss did not improve from 0.05585\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 276ms/step - accuracy: 0.9567 - loss: 0.1185 - val_accuracy: 0.9813 - val_loss: 0.0617 - learning_rate: 0.0010\nEpoch 38/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9550 - loss: 0.1204\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 38: val_loss did not improve from 0.05585\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 257ms/step - accuracy: 0.9550 - loss: 0.1205 - val_accuracy: 0.9817 - val_loss: 0.0595 - learning_rate: 0.0010\nEpoch 39/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9588 - loss: 0.1102\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 39: val_loss did not improve from 0.05585\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 257ms/step - accuracy: 0.9588 - loss: 0.1103 - val_accuracy: 0.9806 - val_loss: 0.0591 - learning_rate: 0.0010\nEpoch 40/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 0.9620 - loss: 0.1047\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 40: val_loss improved from 0.05585 to 0.05311, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 258ms/step - accuracy: 0.9620 - loss: 0.1047 - val_accuracy: 0.9831 - val_loss: 0.0531 - learning_rate: 0.0010\nEpoch 41/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9584 - loss: 0.1194\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 41: val_loss did not improve from 0.05311\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9584 - loss: 0.1194 - val_accuracy: 0.9771 - val_loss: 0.0658 - learning_rate: 0.0010\nEpoch 42/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9636 - loss: 0.1001\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 42: val_loss did not improve from 0.05311\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9636 - loss: 0.1002 - val_accuracy: 0.9817 - val_loss: 0.0611 - learning_rate: 0.0010\nEpoch 43/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9596 - loss: 0.1044\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 43: val_loss did not improve from 0.05311\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9596 - loss: 0.1045 - val_accuracy: 0.9792 - val_loss: 0.0629 - learning_rate: 0.0010\nEpoch 44/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9580 - loss: 0.1128\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 44: val_loss did not improve from 0.05311\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9580 - loss: 0.1128 - val_accuracy: 0.9799 - val_loss: 0.0651 - learning_rate: 0.0010\nEpoch 45/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9586 - loss: 0.1077\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 45: val_loss did not improve from 0.05311\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9586 - loss: 0.1078 - val_accuracy: 0.9817 - val_loss: 0.0597 - learning_rate: 0.0010\nEpoch 46/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9627 - loss: 0.1044\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 46: val_loss improved from 0.05311 to 0.05288, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9627 - loss: 0.1045 - val_accuracy: 0.9820 - val_loss: 0.0529 - learning_rate: 0.0010\nEpoch 47/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9630 - loss: 0.0995\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 47: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 47: val_loss did not improve from 0.05288\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9629 - loss: 0.0996 - val_accuracy: 0.9725 - val_loss: 0.0746 - learning_rate: 0.0010\nEpoch 48/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9624 - loss: 0.0990\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 48: val_loss did not improve from 0.05288\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9624 - loss: 0.0991 - val_accuracy: 0.9817 - val_loss: 0.0581 - learning_rate: 5.0000e-04\nEpoch 49/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9654 - loss: 0.0961\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 49: val_loss improved from 0.05288 to 0.04739, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 252ms/step - accuracy: 0.9654 - loss: 0.0961 - val_accuracy: 0.9842 - val_loss: 0.0474 - learning_rate: 5.0000e-04\nEpoch 50/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9664 - loss: 0.0936\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 50: val_loss did not improve from 0.04739\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9663 - loss: 0.0936 - val_accuracy: 0.9842 - val_loss: 0.0483 - learning_rate: 5.0000e-04\nEpoch 51/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9657 - loss: 0.0960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 51: val_loss improved from 0.04739 to 0.04448, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9657 - loss: 0.0960 - val_accuracy: 0.9852 - val_loss: 0.0445 - learning_rate: 5.0000e-04\nEpoch 52/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9661 - loss: 0.0967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 52: val_loss did not improve from 0.04448\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9661 - loss: 0.0968 - val_accuracy: 0.9842 - val_loss: 0.0476 - learning_rate: 5.0000e-04\nEpoch 53/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9667 - loss: 0.0900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 53: val_loss did not improve from 0.04448\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9667 - loss: 0.0900 - val_accuracy: 0.9842 - val_loss: 0.0457 - learning_rate: 5.0000e-04\nEpoch 54/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9686 - loss: 0.0917\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 54: val_loss did not improve from 0.04448\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9686 - loss: 0.0917 - val_accuracy: 0.9831 - val_loss: 0.0458 - learning_rate: 5.0000e-04\nEpoch 55/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9689 - loss: 0.0909\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 55: val_loss did not improve from 0.04448\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9689 - loss: 0.0910 - val_accuracy: 0.9838 - val_loss: 0.0448 - learning_rate: 5.0000e-04\nEpoch 56/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9675 - loss: 0.0887\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 56: val_loss did not improve from 0.04448\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9675 - loss: 0.0888 - val_accuracy: 0.9835 - val_loss: 0.0484 - learning_rate: 5.0000e-04\nEpoch 57/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9638 - loss: 0.0967\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 57: val_loss did not improve from 0.04448\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9638 - loss: 0.0967 - val_accuracy: 0.9856 - val_loss: 0.0446 - learning_rate: 5.0000e-04\nEpoch 58/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9659 - loss: 0.0929\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 58: val_loss improved from 0.04448 to 0.04286, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9659 - loss: 0.0929 - val_accuracy: 0.9863 - val_loss: 0.0429 - learning_rate: 5.0000e-04\nEpoch 59/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9687 - loss: 0.0869\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 59: val_loss improved from 0.04286 to 0.04219, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9687 - loss: 0.0869 - val_accuracy: 0.9870 - val_loss: 0.0422 - learning_rate: 5.0000e-04\nEpoch 60/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 0.9677 - loss: 0.0924\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 60: val_loss did not improve from 0.04219\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 255ms/step - accuracy: 0.9677 - loss: 0.0923 - val_accuracy: 0.9866 - val_loss: 0.0428 - learning_rate: 5.0000e-04\nEpoch 61/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9678 - loss: 0.0892\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 61: val_loss did not improve from 0.04219\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9678 - loss: 0.0891 - val_accuracy: 0.9852 - val_loss: 0.0457 - learning_rate: 5.0000e-04\nEpoch 62/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9687 - loss: 0.0874\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 62: val_loss did not improve from 0.04219\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9687 - loss: 0.0874 - val_accuracy: 0.9863 - val_loss: 0.0446 - learning_rate: 5.0000e-04\nEpoch 63/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 0.9676 - loss: 0.0845\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 63: val_loss did not improve from 0.04219\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 251ms/step - accuracy: 0.9676 - loss: 0.0846 - val_accuracy: 0.9859 - val_loss: 0.0441 - learning_rate: 5.0000e-04\nEpoch 64/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9695 - loss: 0.0827\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 64: val_loss improved from 0.04219 to 0.04132, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9695 - loss: 0.0827 - val_accuracy: 0.9863 - val_loss: 0.0413 - learning_rate: 5.0000e-04\nEpoch 65/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9639 - loss: 0.0945\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 65: val_loss did not improve from 0.04132\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9639 - loss: 0.0945 - val_accuracy: 0.9863 - val_loss: 0.0454 - learning_rate: 5.0000e-04\nEpoch 66/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9698 - loss: 0.0880\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 66: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 66: val_loss did not improve from 0.04132\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9698 - loss: 0.0880 - val_accuracy: 0.9775 - val_loss: 0.0630 - learning_rate: 5.0000e-04\nEpoch 67/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9689 - loss: 0.0834\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 67: val_loss did not improve from 0.04132\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 248ms/step - accuracy: 0.9689 - loss: 0.0834 - val_accuracy: 0.9849 - val_loss: 0.0451 - learning_rate: 2.5000e-04\nEpoch 68/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9690 - loss: 0.0842\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 68: val_loss did not improve from 0.04132\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9691 - loss: 0.0842 - val_accuracy: 0.9863 - val_loss: 0.0427 - learning_rate: 2.5000e-04\nEpoch 69/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9710 - loss: 0.0813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 69: val_loss did not improve from 0.04132\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 250ms/step - accuracy: 0.9710 - loss: 0.0813 - val_accuracy: 0.9842 - val_loss: 0.0460 - learning_rate: 2.5000e-04\nEpoch 70/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 0.9701 - loss: 0.0822\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 70: val_loss improved from 0.04132 to 0.04018, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9701 - loss: 0.0823 - val_accuracy: 0.9859 - val_loss: 0.0402 - learning_rate: 2.5000e-04\nEpoch 71/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 0.9688 - loss: 0.0847\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 71: val_loss improved from 0.04018 to 0.03998, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.9688 - loss: 0.0847 - val_accuracy: 0.9866 - val_loss: 0.0400 - learning_rate: 2.5000e-04\nEpoch 72/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 0.9720 - loss: 0.0770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 72: val_loss improved from 0.03998 to 0.03657, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 256ms/step - accuracy: 0.9720 - loss: 0.0770 - val_accuracy: 0.9880 - val_loss: 0.0366 - learning_rate: 2.5000e-04\nEpoch 73/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 264ms/step - accuracy: 0.9721 - loss: 0.0781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 73: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 272ms/step - accuracy: 0.9721 - loss: 0.0781 - val_accuracy: 0.9884 - val_loss: 0.0376 - learning_rate: 2.5000e-04\nEpoch 74/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step - accuracy: 0.9694 - loss: 0.0815\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 74: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 283ms/step - accuracy: 0.9694 - loss: 0.0815 - val_accuracy: 0.9880 - val_loss: 0.0374 - learning_rate: 2.5000e-04\nEpoch 75/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 0.9728 - loss: 0.0771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 75: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 267ms/step - accuracy: 0.9728 - loss: 0.0771 - val_accuracy: 0.9870 - val_loss: 0.0422 - learning_rate: 2.5000e-04\nEpoch 76/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 0.9722 - loss: 0.0790\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 76: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 264ms/step - accuracy: 0.9722 - loss: 0.0790 - val_accuracy: 0.9863 - val_loss: 0.0402 - learning_rate: 2.5000e-04\nEpoch 77/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 0.9723 - loss: 0.0769\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 77: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9723 - loss: 0.0769 - val_accuracy: 0.9870 - val_loss: 0.0381 - learning_rate: 2.5000e-04\nEpoch 78/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 0.9708 - loss: 0.0771\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 78: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 266ms/step - accuracy: 0.9708 - loss: 0.0771 - val_accuracy: 0.9880 - val_loss: 0.0373 - learning_rate: 2.5000e-04\nEpoch 79/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.9735 - loss: 0.0749\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 79: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 258ms/step - accuracy: 0.9735 - loss: 0.0749 - val_accuracy: 0.9877 - val_loss: 0.0375 - learning_rate: 2.5000e-04\nEpoch 80/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.9731 - loss: 0.0768\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 80: val_loss did not improve from 0.03657\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 277ms/step - accuracy: 0.9731 - loss: 0.0768 - val_accuracy: 0.9873 - val_loss: 0.0389 - learning_rate: 2.5000e-04\nEpoch 81/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9745 - loss: 0.0722\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 81: val_loss improved from 0.03657 to 0.03574, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 310ms/step - accuracy: 0.9744 - loss: 0.0723 - val_accuracy: 0.9891 - val_loss: 0.0357 - learning_rate: 2.5000e-04\nEpoch 82/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9723 - loss: 0.0782\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 82: val_loss did not improve from 0.03574\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 310ms/step - accuracy: 0.9723 - loss: 0.0783 - val_accuracy: 0.9880 - val_loss: 0.0405 - learning_rate: 2.5000e-04\nEpoch 83/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9732 - loss: 0.0770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 83: val_loss did not improve from 0.03574\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - accuracy: 0.9732 - loss: 0.0770 - val_accuracy: 0.9884 - val_loss: 0.0382 - learning_rate: 2.5000e-04\nEpoch 84/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9742 - loss: 0.0732\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 84: val_loss improved from 0.03574 to 0.03571, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 323ms/step - accuracy: 0.9742 - loss: 0.0732 - val_accuracy: 0.9880 - val_loss: 0.0357 - learning_rate: 2.5000e-04\nEpoch 85/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9729 - loss: 0.0781\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 85: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 85: val_loss did not improve from 0.03571\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 310ms/step - accuracy: 0.9729 - loss: 0.0781 - val_accuracy: 0.9887 - val_loss: 0.0358 - learning_rate: 2.5000e-04\nEpoch 86/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.9739 - loss: 0.0765\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 86: val_loss did not improve from 0.03571\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 318ms/step - accuracy: 0.9739 - loss: 0.0765 - val_accuracy: 0.9887 - val_loss: 0.0358 - learning_rate: 1.2500e-04\nEpoch 87/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.9766 - loss: 0.0677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 87: val_loss did not improve from 0.03571\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 318ms/step - accuracy: 0.9766 - loss: 0.0678 - val_accuracy: 0.9866 - val_loss: 0.0359 - learning_rate: 1.2500e-04\nEpoch 88/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.9741 - loss: 0.0691\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 88: val_loss did not improve from 0.03571\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.9741 - loss: 0.0692 - val_accuracy: 0.9870 - val_loss: 0.0359 - learning_rate: 1.2500e-04\nEpoch 89/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 315ms/step - accuracy: 0.9745 - loss: 0.0740\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 89: val_loss improved from 0.03571 to 0.03443, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 325ms/step - accuracy: 0.9745 - loss: 0.0740 - val_accuracy: 0.9884 - val_loss: 0.0344 - learning_rate: 1.2500e-04\nEpoch 90/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step - accuracy: 0.9750 - loss: 0.0674\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 90: val_loss improved from 0.03443 to 0.03364, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 326ms/step - accuracy: 0.9750 - loss: 0.0675 - val_accuracy: 0.9880 - val_loss: 0.0336 - learning_rate: 1.2500e-04\nEpoch 91/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.9740 - loss: 0.0714\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 91: val_loss did not improve from 0.03364\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 327ms/step - accuracy: 0.9740 - loss: 0.0714 - val_accuracy: 0.9898 - val_loss: 0.0341 - learning_rate: 1.2500e-04\nEpoch 92/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.9773 - loss: 0.0679\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 92: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 92: val_loss did not improve from 0.03364\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 320ms/step - accuracy: 0.9773 - loss: 0.0679 - val_accuracy: 0.9898 - val_loss: 0.0337 - learning_rate: 1.2500e-04\nEpoch 93/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9775 - loss: 0.0672\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 93: val_loss improved from 0.03364 to 0.03282, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 318ms/step - accuracy: 0.9775 - loss: 0.0672 - val_accuracy: 0.9905 - val_loss: 0.0328 - learning_rate: 6.2500e-05\nEpoch 94/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9770 - loss: 0.0667\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 94: val_loss improved from 0.03282 to 0.03258, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 309ms/step - accuracy: 0.9770 - loss: 0.0667 - val_accuracy: 0.9905 - val_loss: 0.0326 - learning_rate: 6.2500e-05\nEpoch 95/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9754 - loss: 0.0728\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 95: val_loss did not improve from 0.03258\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 305ms/step - accuracy: 0.9754 - loss: 0.0728 - val_accuracy: 0.9908 - val_loss: 0.0330 - learning_rate: 6.2500e-05\nEpoch 96/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9754 - loss: 0.0694\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 96: val_loss improved from 0.03258 to 0.03217, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 307ms/step - accuracy: 0.9754 - loss: 0.0694 - val_accuracy: 0.9901 - val_loss: 0.0322 - learning_rate: 6.2500e-05\nEpoch 97/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302ms/step - accuracy: 0.9739 - loss: 0.0702\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 97: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 309ms/step - accuracy: 0.9739 - loss: 0.0703 - val_accuracy: 0.9905 - val_loss: 0.0329 - learning_rate: 6.2500e-05\nEpoch 98/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9773 - loss: 0.0648\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 98: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 310ms/step - accuracy: 0.9773 - loss: 0.0648 - val_accuracy: 0.9894 - val_loss: 0.0331 - learning_rate: 6.2500e-05\nEpoch 99/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9763 - loss: 0.0689\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 99: val_loss improved from 0.03217 to 0.03217, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 317ms/step - accuracy: 0.9763 - loss: 0.0689 - val_accuracy: 0.9894 - val_loss: 0.0322 - learning_rate: 6.2500e-05\nEpoch 100/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9785 - loss: 0.0629\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 100: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 317ms/step - accuracy: 0.9784 - loss: 0.0629 - val_accuracy: 0.9891 - val_loss: 0.0330 - learning_rate: 6.2500e-05\nEpoch 101/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303ms/step - accuracy: 0.9753 - loss: 0.0698\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 101: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 317ms/step - accuracy: 0.9753 - loss: 0.0698 - val_accuracy: 0.9887 - val_loss: 0.0324 - learning_rate: 6.2500e-05\nEpoch 102/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295ms/step - accuracy: 0.9755 - loss: 0.0701\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 102: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 302ms/step - accuracy: 0.9755 - loss: 0.0701 - val_accuracy: 0.9894 - val_loss: 0.0328 - learning_rate: 6.2500e-05\nEpoch 103/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 300ms/step - accuracy: 0.9761 - loss: 0.0666\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 103: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 308ms/step - accuracy: 0.9761 - loss: 0.0667 - val_accuracy: 0.9898 - val_loss: 0.0323 - learning_rate: 6.2500e-05\nEpoch 104/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9748 - loss: 0.0706\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 104: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 330ms/step - accuracy: 0.9748 - loss: 0.0706 - val_accuracy: 0.9898 - val_loss: 0.0323 - learning_rate: 6.2500e-05\nEpoch 105/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.9767 - loss: 0.0641\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 105: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 105: val_loss did not improve from 0.03217\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 327ms/step - accuracy: 0.9767 - loss: 0.0641 - val_accuracy: 0.9898 - val_loss: 0.0322 - learning_rate: 6.2500e-05\nEpoch 106/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 312ms/step - accuracy: 0.9780 - loss: 0.0645\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 106: val_loss improved from 0.03217 to 0.03200, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.9780 - loss: 0.0645 - val_accuracy: 0.9898 - val_loss: 0.0320 - learning_rate: 3.1250e-05\nEpoch 107/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.9767 - loss: 0.0677\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 107: val_loss improved from 0.03200 to 0.03166, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 319ms/step - accuracy: 0.9767 - loss: 0.0677 - val_accuracy: 0.9908 - val_loss: 0.0317 - learning_rate: 3.1250e-05\nEpoch 108/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9754 - loss: 0.0659\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 108: val_loss did not improve from 0.03166\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 316ms/step - accuracy: 0.9754 - loss: 0.0659 - val_accuracy: 0.9898 - val_loss: 0.0320 - learning_rate: 3.1250e-05\nEpoch 109/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 310ms/step - accuracy: 0.9742 - loss: 0.0737\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 109: val_loss improved from 0.03166 to 0.03136, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 318ms/step - accuracy: 0.9742 - loss: 0.0737 - val_accuracy: 0.9905 - val_loss: 0.0314 - learning_rate: 3.1250e-05\nEpoch 110/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9764 - loss: 0.0668\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 110: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 110: val_loss did not improve from 0.03136\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 306ms/step - accuracy: 0.9764 - loss: 0.0668 - val_accuracy: 0.9898 - val_loss: 0.0316 - learning_rate: 3.1250e-05\nEpoch 111/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 307ms/step - accuracy: 0.9764 - loss: 0.0721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 111: val_loss did not improve from 0.03136\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 315ms/step - accuracy: 0.9764 - loss: 0.0720 - val_accuracy: 0.9894 - val_loss: 0.0321 - learning_rate: 1.5625e-05\nEpoch 112/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step - accuracy: 0.9775 - loss: 0.0627\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 112: val_loss did not improve from 0.03136\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 317ms/step - accuracy: 0.9775 - loss: 0.0627 - val_accuracy: 0.9912 - val_loss: 0.0316 - learning_rate: 1.5625e-05\nEpoch 113/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297ms/step - accuracy: 0.9762 - loss: 0.0652\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 113: val_loss improved from 0.03136 to 0.03129, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 305ms/step - accuracy: 0.9762 - loss: 0.0652 - val_accuracy: 0.9901 - val_loss: 0.0313 - learning_rate: 1.5625e-05\nEpoch 114/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 309ms/step - accuracy: 0.9763 - loss: 0.0690\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 114: val_loss did not improve from 0.03129\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 317ms/step - accuracy: 0.9763 - loss: 0.0690 - val_accuracy: 0.9912 - val_loss: 0.0313 - learning_rate: 1.5625e-05\nEpoch 115/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305ms/step - accuracy: 0.9774 - loss: 0.0647\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 115: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 115: val_loss improved from 0.03129 to 0.03106, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 320ms/step - accuracy: 0.9773 - loss: 0.0648 - val_accuracy: 0.9915 - val_loss: 0.0311 - learning_rate: 1.5625e-05\nEpoch 116/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 0.9772 - loss: 0.0646\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 116: val_loss improved from 0.03106 to 0.03100, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 305ms/step - accuracy: 0.9771 - loss: 0.0646 - val_accuracy: 0.9908 - val_loss: 0.0310 - learning_rate: 7.8125e-06\nEpoch 117/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9775 - loss: 0.0636\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 117: val_loss did not improve from 0.03100\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 292ms/step - accuracy: 0.9775 - loss: 0.0636 - val_accuracy: 0.9898 - val_loss: 0.0312 - learning_rate: 7.8125e-06\nEpoch 118/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9768 - loss: 0.0671\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 118: val_loss did not improve from 0.03100\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 298ms/step - accuracy: 0.9768 - loss: 0.0671 - val_accuracy: 0.9908 - val_loss: 0.0311 - learning_rate: 7.8125e-06\nEpoch 119/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 0.9767 - loss: 0.0654\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 119: val_loss improved from 0.03100 to 0.03076, saving model to fold_05_best_model.keras\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 295ms/step - accuracy: 0.9766 - loss: 0.0654 - val_accuracy: 0.9905 - val_loss: 0.0308 - learning_rate: 7.8125e-06\nEpoch 120/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9739 - loss: 0.0718\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 120: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\nEpoch 120: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 315ms/step - accuracy: 0.9739 - loss: 0.0718 - val_accuracy: 0.9905 - val_loss: 0.0309 - learning_rate: 7.8125e-06\nEpoch 121/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9787 - loss: 0.0623\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 121: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 307ms/step - accuracy: 0.9787 - loss: 0.0623 - val_accuracy: 0.9905 - val_loss: 0.0310 - learning_rate: 3.9063e-06\nEpoch 122/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step - accuracy: 0.9748 - loss: 0.0721\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 122: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 309ms/step - accuracy: 0.9748 - loss: 0.0721 - val_accuracy: 0.9908 - val_loss: 0.0313 - learning_rate: 3.9063e-06\nEpoch 123/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294ms/step - accuracy: 0.9758 - loss: 0.0695\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 123: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 302ms/step - accuracy: 0.9758 - loss: 0.0696 - val_accuracy: 0.9905 - val_loss: 0.0315 - learning_rate: 3.9063e-06\nEpoch 124/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 298ms/step - accuracy: 0.9792 - loss: 0.0639\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 124: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 306ms/step - accuracy: 0.9792 - loss: 0.0640 - val_accuracy: 0.9901 - val_loss: 0.0315 - learning_rate: 3.9063e-06\nEpoch 125/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9762 - loss: 0.0683\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 125: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 306ms/step - accuracy: 0.9762 - loss: 0.0683 - val_accuracy: 0.9905 - val_loss: 0.0312 - learning_rate: 3.9063e-06\nEpoch 126/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9800 - loss: 0.0578\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 126: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 306ms/step - accuracy: 0.9800 - loss: 0.0578 - val_accuracy: 0.9898 - val_loss: 0.0310 - learning_rate: 3.9063e-06\nEpoch 127/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.9735 - loss: 0.0697\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 127: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 295ms/step - accuracy: 0.9735 - loss: 0.0697 - val_accuracy: 0.9898 - val_loss: 0.0313 - learning_rate: 3.9063e-06\nEpoch 128/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299ms/step - accuracy: 0.9773 - loss: 0.0662\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 128: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 306ms/step - accuracy: 0.9773 - loss: 0.0662 - val_accuracy: 0.9901 - val_loss: 0.0312 - learning_rate: 3.9063e-06\nEpoch 129/300\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 0.9784 - loss: 0.0596\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 129: val_loss did not improve from 0.03076\n\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 295ms/step - accuracy: 0.9784 - loss: 0.0597 - val_accuracy: 0.9905 - val_loss: 0.0310 - learning_rate: 3.9063e-06\nEpoch 129: early stopping\nRestoring model weights from the end of the best epoch: 119.\n[FOLD 5] ✅ Training finished.\n[FOLD 5] Best val_loss=0.030762\n[FOLD 5] Evaluating on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - accuracy: 0.9913 - loss: 0.0271\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 5] val_loss=0.0308 | val_acc=0.9905\n[FOLD 5] Predicting probabilities on validation fold...\n\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n[FOLD 5] Confusion matrix:\n[[2342   18]\n [   9  471]]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 500x400 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[FOLD 5] Metrics: acc=0.9905, prec=0.9632, rec=0.9812, spec=0.9924, f1=0.9721, auc=0.9988\n\n======================================================================\n[STEP 10] Cross-validation finished.\n\n[FINAL] Average CV metrics (mean ± std):\n  val_loss    : 0.0268 ± 0.0089\n  val_acc     : 0.9927 ± 0.0032\n  accuracy    : 0.9927 ± 0.0032\n  precision   : 0.9733 ± 0.0119\n  recall      : 0.9842 ± 0.0087\n  specificity : 0.9945 ± 0.0025\n  f1          : 0.9787 ± 0.0092\n  auc         : 0.9985 ± 0.0012\n\n[FINAL] Sum of confusion matrices across folds:\n[[11735    65]\n [   38  2362]]\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 500x400 with 2 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1767941453854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.10 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}