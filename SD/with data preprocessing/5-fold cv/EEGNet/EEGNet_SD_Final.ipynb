{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cell 0 — Install packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q mne PyWavelets scikit-learn seaborn\n",
        "%pip install -q imbalanced-learn\n",
        "%pip install -q azureml-core azure-ai-ml azure-identity\n",
        "\n",
        "print(\"✅ Packages installed (if no errors above).\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Note: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n✅ Packages installed (if no errors above).\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1768748506465
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1 — Load libraries + set seeds"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import mne\n",
        "import pywt\n",
        "from sklearn.decomposition import FastICA\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from collections import defaultdict\n",
        "from typing import Optional, Union, Sequence, Dict, Tuple, List\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, AveragePooling2D, Flatten, Dense, Dropout, BatchNormalization,\n",
        "    Input, DepthwiseConv2D, SeparableConv2D, Activation\n",
        ")\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.metrics import BinaryAccuracy\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n",
        "\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
        "\n",
        "try:\n",
        "    tf.keras.utils.enable_interactive_logging()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"✅ Imports done + seeds set.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Imports done + seeds set.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1768748530782
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2 — Helper: load EEG (.set) with labels"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_eeg_data_with_target(\n",
        "    folder_path: str,\n",
        "    session_name: str,\n",
        "    max_samples: int = 118000,\n",
        "    discard_samples: int = 10000\n",
        "):\n",
        "    eeg_files = [f for f in os.listdir(folder_path) if f.endswith('.set')]\n",
        "    data_list = []\n",
        "    targets = []\n",
        "    sfreq_list = []\n",
        "\n",
        "    for eeg_file in eeg_files:\n",
        "        file_path = os.path.join(folder_path, eeg_file)\n",
        "\n",
        "        raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose=False)\n",
        "        data = raw.get_data().astype(np.float32)\n",
        "        sfreq = float(raw.info[\"sfreq\"])\n",
        "\n",
        "        if data.shape[1] > max_samples:\n",
        "            data = data[:, :max_samples]\n",
        "\n",
        "        if data.shape[1] > discard_samples:\n",
        "            data = data[:, discard_samples:]\n",
        "        else:\n",
        "            print(f\"⚠️ Not enough samples to discard in {eeg_file}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        data_list.append(data)\n",
        "        sfreq_list.append(sfreq)\n",
        "\n",
        "        if session_name == 'ses-1':\n",
        "            targets.append(0)\n",
        "        elif session_name == 'ses-2':\n",
        "            targets.append(1)\n",
        "        else:\n",
        "            print(f\"⚠️ Unknown session name: {session_name}\")\n",
        "\n",
        "    return data_list, targets, sfreq_list\n"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1768749785543
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3 — Leakage-safe preprocessing classes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _names_from_index_mapping(\n",
        "    n_channels: int,\n",
        "    index_to_name: Optional[Dict[int, str]]\n",
        ") -> List[str]:\n",
        "    if index_to_name is None:\n",
        "        return [f\"EEG{i+1}\" for i in range(n_channels)]\n",
        "\n",
        "    keys = list(index_to_name.keys())\n",
        "    is_zero_based = (0 in keys) and (1 not in keys)\n",
        "\n",
        "    names = []\n",
        "    for i in range(n_channels):\n",
        "        key = i if is_zero_based else (i + 1)\n",
        "        names.append(index_to_name.get(key, f\"EEG{i+1}\"))\n",
        "    return names\n",
        "\n",
        "\n",
        "def _make_raw(\n",
        "    eeg: np.ndarray,\n",
        "    sfreq: float,\n",
        "    ch_names: List[str],\n",
        "    use_standard_1020: bool = True\n",
        ") -> Tuple[mne.io.Raw, bool]:\n",
        "    ch_types = ['eog' if str(n).upper().startswith(\"EOG\") else 'eeg' for n in ch_names]\n",
        "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
        "    raw = mne.io.RawArray(eeg.astype(np.float32, copy=False), info, verbose=False)\n",
        "\n",
        "    montage_applied = False\n",
        "    if use_standard_1020:\n",
        "        try:\n",
        "            mont = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "            raw.set_montage(mont, match_case=False, on_missing=\"ignore\")\n",
        "            montage_applied = True\n",
        "        except Exception:\n",
        "            montage_applied = False\n",
        "\n",
        "    return raw, montage_applied\n",
        "\n",
        "\n",
        "class WaveletICA:\n",
        "    def __init__(self, wavelet=\"db4\", level=3, n_components=10, random_state=42):\n",
        "        self.wavelet = wavelet\n",
        "        self.level = level\n",
        "        self.n_components = n_components\n",
        "        self.random_state = random_state\n",
        "        self.ica_: Optional[FastICA] = None\n",
        "        self._n_ch: Optional[int] = None\n",
        "\n",
        "    def fit(self, X: np.ndarray):\n",
        "        C = X.shape[0]\n",
        "        self._n_ch = C\n",
        "\n",
        "        coeffs = pywt.wavedec(X, wavelet=self.wavelet, level=self.level, axis=1)\n",
        "        A = coeffs[0]\n",
        "\n",
        "        k = int(min(self.n_components, C))\n",
        "        self.ica_ = FastICA(n_components=k, random_state=self.random_state)\n",
        "\n",
        "        S = self.ica_.fit_transform(A.T)\n",
        "        A_denoised = self.ica_.inverse_transform(S).T\n",
        "\n",
        "        coeffs[0] = A_denoised\n",
        "        _ = pywt.waverec(coeffs, wavelet=self.wavelet, axis=1)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: np.ndarray) -> np.ndarray:\n",
        "        assert self.ica_ is not None, \"WaveletICA not fitted yet.\"\n",
        "\n",
        "        coeffs = pywt.wavedec(X, wavelet=self.wavelet, level=self.level, axis=1)\n",
        "        A = coeffs[0]\n",
        "\n",
        "        S = self.ica_.transform(A.T)\n",
        "        A_denoised = self.ica_.inverse_transform(S).T\n",
        "\n",
        "        coeffs[0] = A_denoised\n",
        "        Y = pywt.waverec(coeffs, wavelet=self.wavelet, axis=1)\n",
        "\n",
        "        if Y.shape[1] < X.shape[1]:\n",
        "            pad_width = X.shape[1] - Y.shape[1]\n",
        "            Y = np.pad(Y, ((0, 0), (0, pad_width)), mode=\"constant\")\n",
        "        elif Y.shape[1] > X.shape[1]:\n",
        "            Y = Y[:, :X.shape[1]]\n",
        "\n",
        "        return Y.astype(np.float32, copy=False)\n",
        "\n",
        "\n",
        "class EEGPreprocessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        index_to_name: Optional[Dict[int, str]] = None,\n",
        "        use_standard_1020: bool = True,\n",
        "        resample_to: Optional[float] = None,\n",
        "        notch_freqs: Union[None, float, Sequence[float]] = 50.0,\n",
        "        highpass: Optional[float] = 0.05,\n",
        "        bad_point_z: float = 6.0,\n",
        "        bad_channel_z: float = 5.0,\n",
        "        interpolate_bad_channels: bool = False,\n",
        "        car: bool = True,\n",
        "        use_wica: bool = True,\n",
        "        wica_components: int = 10,\n",
        "        wica_wavelet: str = \"db4\",\n",
        "        wica_level: int = 3,\n",
        "        wica_random_state: int = 42\n",
        "    ):\n",
        "        self.index_to_name = index_to_name\n",
        "        self.use_standard_1020 = use_standard_1020\n",
        "        self.resample_to = resample_to\n",
        "        self.notch_freqs = notch_freqs\n",
        "        self.highpass = highpass\n",
        "        self.bad_point_z = bad_point_z\n",
        "        self.bad_channel_z = bad_channel_z\n",
        "        self.interpolate_bad_channels = interpolate_bad_channels\n",
        "        self.car = car\n",
        "        self.use_wica = use_wica\n",
        "\n",
        "        self._sfreq_out: Optional[float] = None\n",
        "        self._train_mu: Optional[np.ndarray] = None\n",
        "        self._train_sd: Optional[np.ndarray] = None\n",
        "        self._robust_med: Optional[float] = None\n",
        "        self._robust_mad: Optional[float] = None\n",
        "        self._train_eeg_names: Optional[List[str]] = None\n",
        "\n",
        "        self._wica = WaveletICA(\n",
        "            wavelet=wica_wavelet,\n",
        "            level=wica_level,\n",
        "            n_components=wica_components,\n",
        "            random_state=wica_random_state\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def sfreq_out(self) -> float:\n",
        "        assert self._sfreq_out is not None, \"Preprocessor not run yet.\"\n",
        "        return float(self._sfreq_out)\n",
        "\n",
        "    def _filter_and_reference(self, raw: mne.io.Raw):\n",
        "        if self.resample_to is not None and float(self.resample_to) != float(raw.info[\"sfreq\"]):\n",
        "            raw.resample(self.resample_to, npad=\"auto\")\n",
        "\n",
        "        self._sfreq_out = float(raw.info[\"sfreq\"])\n",
        "\n",
        "        if self.notch_freqs is not None:\n",
        "            raw.notch_filter(freqs=self.notch_freqs, verbose=False)\n",
        "\n",
        "        if self.highpass is not None:\n",
        "            raw.filter(l_freq=self.highpass, h_freq=None, verbose=False)\n",
        "\n",
        "        if self.car:\n",
        "            raw.set_eeg_reference(\"average\", projection=True)\n",
        "            raw.apply_proj()\n",
        "\n",
        "    def _repair_transients_with_train_stats(self, raw: mne.io.Raw):\n",
        "        X = raw.get_data()\n",
        "        mu = self._train_mu\n",
        "        sd = self._train_sd\n",
        "        assert mu is not None and sd is not None, \"Training stats not set.\"\n",
        "\n",
        "        hi = mu + self.bad_point_z * sd\n",
        "        lo = mu - self.bad_point_z * sd\n",
        "        mask = (X > hi) | (X < lo)\n",
        "\n",
        "        if np.any(mask):\n",
        "            X_fixed = X.copy()\n",
        "            t = np.arange(X.shape[1], dtype=float)\n",
        "            for ch in range(X.shape[0]):\n",
        "                m = mask[ch]\n",
        "                if m.any():\n",
        "                    good = ~m\n",
        "                    if good.sum() >= 2:\n",
        "                        X_fixed[ch, m] = np.interp(t[m], t[good], X_fixed[ch, good])\n",
        "            raw._data = X_fixed\n",
        "\n",
        "    def _interpolate_bad_channels_with_train_calibration(self, raw: mne.io.Raw):\n",
        "        if not self.interpolate_bad_channels:\n",
        "            return\n",
        "\n",
        "        picks = mne.pick_types(raw.info, eeg=True)\n",
        "        if len(picks) == 0:\n",
        "            return\n",
        "\n",
        "        X = raw.get_data(picks=picks)\n",
        "        ch_std = X.std(axis=1)\n",
        "\n",
        "        med = self._robust_med\n",
        "        mad = self._robust_mad\n",
        "        if med is None or mad is None or mad == 0:\n",
        "            return\n",
        "\n",
        "        z = 0.6745 * (ch_std - med) / mad\n",
        "        eeg_names = mne.pick_info(raw.info, picks).ch_names\n",
        "        bads = [eeg_names[i] for i in np.where(np.abs(z) > self.bad_channel_z)[0]]\n",
        "\n",
        "        raw.info[\"bads\"] = bads\n",
        "        if bads:\n",
        "            raw.interpolate_bads(reset_bads=True, verbose=False)\n",
        "\n",
        "    def fit(self, X_train: np.ndarray, sfreq: float):\n",
        "        C = X_train.shape[0]\n",
        "        ch_names = _names_from_index_mapping(C, self.index_to_name)\n",
        "\n",
        "        raw_train, montage_applied = _make_raw(X_train, sfreq, ch_names, self.use_standard_1020)\n",
        "        self._filter_and_reference(raw_train)\n",
        "\n",
        "        Xt = raw_train.get_data()\n",
        "        self._train_mu = Xt.mean(axis=1, keepdims=True)\n",
        "        self._train_sd = Xt.std(axis=1, keepdims=True) + 1e-12\n",
        "\n",
        "        if montage_applied:\n",
        "            picks_eeg = mne.pick_types(raw_train.info, eeg=True)\n",
        "            if len(picks_eeg):\n",
        "                X_eeg = Xt[picks_eeg]\n",
        "                ch_std = X_eeg.std(axis=1)\n",
        "                med = np.median(ch_std)\n",
        "                mad = np.median(np.abs(ch_std - med)) + 1e-12\n",
        "                self._robust_med = float(med)\n",
        "                self._robust_mad = float(mad)\n",
        "                self._train_eeg_names = mne.pick_info(raw_train.info, picks_eeg).ch_names\n",
        "            else:\n",
        "                self._robust_med = None\n",
        "                self._robust_mad = None\n",
        "        else:\n",
        "            self._robust_med = None\n",
        "            self._robust_mad = None\n",
        "\n",
        "        self._repair_transients_with_train_stats(raw_train)\n",
        "        Xt = raw_train.get_data()\n",
        "\n",
        "        if montage_applied and self.interpolate_bad_channels:\n",
        "            self._interpolate_bad_channels_with_train_calibration(raw_train)\n",
        "            Xt = raw_train.get_data()\n",
        "\n",
        "        if self.use_wica:\n",
        "            self._wica.fit(Xt)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X: np.ndarray, sfreq: float) -> Tuple[np.ndarray, float]:\n",
        "        C = X.shape[0]\n",
        "        ch_names = _names_from_index_mapping(C, self.index_to_name)\n",
        "\n",
        "        raw, montage_applied = _make_raw(X, sfreq, ch_names, self.use_standard_1020)\n",
        "        self._filter_and_reference(raw)\n",
        "        self._repair_transients_with_train_stats(raw)\n",
        "\n",
        "        if montage_applied and self.interpolate_bad_channels:\n",
        "            self._interpolate_bad_channels_with_train_calibration(raw)\n",
        "\n",
        "        Xf = raw.get_data()\n",
        "        if self.use_wica:\n",
        "            Xf = self._wica.transform(Xf)\n",
        "\n",
        "        return Xf.astype(np.float32, copy=False), self.sfreq_out\n",
        "\n",
        "    def fit_transform(self, X_train: np.ndarray, sfreq: float) -> Tuple[np.ndarray, float]:\n",
        "        self.fit(X_train, sfreq)\n",
        "        X_clean, fs_out = self.transform(X_train, sfreq)\n",
        "        return X_clean, fs_out\n",
        "\n",
        "print(\"✅ Preprocessing classes loaded.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Preprocessing classes loaded.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1768749804886
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4 — Azure download + load raw EEG"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Datastore\n",
        "\n",
        "print(\"[STEP 4] Connecting to Azure ML workspace...\")\n",
        "\n",
        "subscription_id = \"eccc04ba-d8b0-4f70-864a-b4a6753bfc72\"\n",
        "resource_group  = \"somnasnest\"\n",
        "workspace_name  = \"SomnasNest\"\n",
        "\n",
        "ws = Workspace(\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group=resource_group,\n",
        "    workspace_name=workspace_name\n",
        ")\n",
        "\n",
        "print(\"[STEP 4] Getting datastore 'workspaceblobstore'...\")\n",
        "datastore = Datastore.get(ws, \"workspaceblobstore\")\n",
        "\n",
        "remote_prefix = \"UI/2025-12-11_033542_UTC/New Dataset\"\n",
        "local_root = \"./azureml_eeg_data\"\n",
        "os.makedirs(local_root, exist_ok=True)\n",
        "\n",
        "print(f\"[STEP 4] Downloading datastore prefix: {remote_prefix}\")\n",
        "n_files = datastore.download(\n",
        "    target_path=local_root,\n",
        "    prefix=remote_prefix,\n",
        "    overwrite=False,\n",
        "    show_progress=True,\n",
        ")\n",
        "print(f\"[STEP 4] Downloaded {n_files} file(s).\")\n",
        "\n",
        "base_path = os.path.join(local_root, *remote_prefix.split(\"/\"))\n",
        "print(f\"[STEP 4] base_path = {base_path}\")\n",
        "\n",
        "if not os.path.isdir(base_path):\n",
        "    raise RuntimeError(f\"[STEP 4] base_path does not exist: {base_path}\")\n",
        "\n",
        "print(\"[STEP 4] Listing base_path contents:\")\n",
        "print(os.listdir(base_path)[:10], \"...\")\n",
        "\n",
        "sub_ses1 = [f\"sub-{i:02d}\" for i in range(1, 60)]\n",
        "sub_ses2 = [f\"sub-{i:02d}\" for i in range(60, 72)]\n",
        "subjects_used = sub_ses1 + sub_ses2\n",
        "\n",
        "print(\"\\n[STEP 4] Dataset rule summary:\")\n",
        "print(f\"  ses-1 subjects count: {len(sub_ses1)} (sub-01..sub-59)\")\n",
        "print(f\"  ses-2 subjects count: {len(sub_ses2)} (sub-60..sub-71)\")\n",
        "print(f\"  total subjects used : {len(subjects_used)}\")\n",
        "\n",
        "raw_list = []\n",
        "targets = []\n",
        "sfreqs = []\n",
        "subject_ids = []\n",
        "\n",
        "print(\"\\n[STEP 4] Loading raw EEG data according to rule...\")\n",
        "\n",
        "for sub in sub_ses1:\n",
        "    session = \"ses-1\"\n",
        "    path = os.path.join(base_path, sub, session)\n",
        "    if not os.path.isdir(path):\n",
        "        print(f\"⚠️ Missing folder: {path}, skipping.\")\n",
        "        continue\n",
        "    data_list, t_list, sf_list = load_eeg_data_with_target(path, session)\n",
        "    print(f\"  Loaded {len(data_list)} trial(s) from {sub}/{session}\")\n",
        "    for data, t, sf in zip(data_list, t_list, sf_list):\n",
        "        raw_list.append(data.astype(np.float32, copy=False))\n",
        "        targets.append(int(t))\n",
        "        sfreqs.append(float(sf))\n",
        "        subject_ids.append(sub)\n",
        "\n",
        "for sub in sub_ses2:\n",
        "    session = \"ses-2\"\n",
        "    path = os.path.join(base_path, sub, session)\n",
        "    if not os.path.isdir(path):\n",
        "        print(f\"⚠️ Missing folder: {path}, skipping.\")\n",
        "        continue\n",
        "    data_list, t_list, sf_list = load_eeg_data_with_target(path, session)\n",
        "    print(f\"  Loaded {len(data_list)} trial(s) from {sub}/{session}\")\n",
        "    for data, t, sf in zip(data_list, t_list, sf_list):\n",
        "        raw_list.append(data.astype(np.float32, copy=False))\n",
        "        targets.append(int(t))\n",
        "        sfreqs.append(float(sf))\n",
        "        subject_ids.append(sub)\n",
        "\n",
        "targets = np.array(targets, dtype=np.int32)\n",
        "subject_ids = np.array(subject_ids)\n",
        "\n",
        "print(\"\\n[STEP 4] Finished loading raw trials.\")\n",
        "print(\"  Total trials loaded:\", len(raw_list))\n",
        "print(\"  Targets shape:\", targets.shape)\n",
        "print(\"  Unique labels + counts:\", np.unique(targets, return_counts=True))\n",
        "\n",
        "sfreqs = np.array(sfreqs, dtype=np.float32)\n",
        "if len(sfreqs) == 0:\n",
        "    raise RuntimeError(\"No EEG data found. Check paths / dataset.\")\n",
        "\n",
        "fs = float(sfreqs[0])\n",
        "if not np.allclose(sfreqs, fs):\n",
        "    print(\"⚠️ Warning: Not all sampling frequencies are identical!\")\n",
        "print(f\"[STEP 4] Using fs={fs} Hz\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 4] Connecting to Azure ML workspace...\n[STEP 4] Getting datastore 'workspaceblobstore'...\n[STEP 4] Downloaded 0 file(s).\n[STEP 4] base_path = ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset\n[STEP 4] Listing base_path contents:\n['CHANGES', 'code', 'dataset_description.json', 'participants.json', 'participants.tsv', 'README', 'session_1_eeg_data.csv', 'session_2_eeg_data.csv', 'sub-01', 'sub-01_eeg_data.pkl'] ...\n\n[STEP 4] Dataset rule summary:\n  ses-1 subjects count: 59 (sub-01..sub-59)\n  ses-2 subjects count: 12 (sub-60..sub-71)\n  total subjects used : 71\n\n[STEP 4] Loading raw EEG data according to rule...\n  Loaded 1 trial(s) from sub-01/ses-1\n  Loaded 1 trial(s) from sub-02/ses-1\n  Loaded 1 trial(s) from sub-03/ses-1\n  Loaded 1 trial(s) from sub-04/ses-1\n  Loaded 1 trial(s) from sub-05/ses-1\n  Loaded 1 trial(s) from sub-06/ses-1\n  Loaded 1 trial(s) from sub-07/ses-1\n  Loaded 1 trial(s) from sub-08/ses-1\n  Loaded 1 trial(s) from sub-09/ses-1\n  Loaded 1 trial(s) from sub-10/ses-1\n  Loaded 1 trial(s) from sub-11/ses-1\n  Loaded 1 trial(s) from sub-12/ses-1\n  Loaded 1 trial(s) from sub-13/ses-1\n  Loaded 1 trial(s) from sub-14/ses-1\n  Loaded 1 trial(s) from sub-15/ses-1\n  Loaded 1 trial(s) from sub-16/ses-1\n  Loaded 1 trial(s) from sub-17/ses-1\n  Loaded 1 trial(s) from sub-18/ses-1\n  Loaded 1 trial(s) from sub-19/ses-1\n  Loaded 1 trial(s) from sub-20/ses-1\n  Loaded 1 trial(s) from sub-21/ses-1\n  Loaded 1 trial(s) from sub-22/ses-1\n  Loaded 1 trial(s) from sub-23/ses-1\n  Loaded 1 trial(s) from sub-24/ses-1\n  Loaded 1 trial(s) from sub-25/ses-1\n  Loaded 1 trial(s) from sub-26/ses-1\n  Loaded 1 trial(s) from sub-27/ses-1\n  Loaded 1 trial(s) from sub-28/ses-1\n  Loaded 1 trial(s) from sub-29/ses-1\n  Loaded 1 trial(s) from sub-30/ses-1\n  Loaded 1 trial(s) from sub-31/ses-1\n  Loaded 1 trial(s) from sub-32/ses-1\n  Loaded 1 trial(s) from sub-33/ses-1\n  Loaded 1 trial(s) from sub-34/ses-1\n  Loaded 1 trial(s) from sub-35/ses-1\n  Loaded 1 trial(s) from sub-36/ses-1\n  Loaded 1 trial(s) from sub-37/ses-1\n  Loaded 1 trial(s) from sub-38/ses-1\n  Loaded 1 trial(s) from sub-39/ses-1\n  Loaded 1 trial(s) from sub-40/ses-1\n  Loaded 1 trial(s) from sub-42/ses-1\n  Loaded 1 trial(s) from sub-44/ses-1\n  Loaded 1 trial(s) from sub-45/ses-1\n  Loaded 1 trial(s) from sub-46/ses-1\n  Loaded 1 trial(s) from sub-47/ses-1\n  Loaded 1 trial(s) from sub-48/ses-1\n  Loaded 1 trial(s) from sub-49/ses-1\n  Loaded 1 trial(s) from sub-50/ses-1\n  Loaded 1 trial(s) from sub-51/ses-1\n  Loaded 1 trial(s) from sub-52/ses-1\n  Loaded 1 trial(s) from sub-53/ses-1\n  Loaded 1 trial(s) from sub-54/ses-1\n  Loaded 1 trial(s) from sub-55/ses-1\n  Loaded 1 trial(s) from sub-56/ses-1\n  Loaded 1 trial(s) from sub-57/ses-1\n  Loaded 1 trial(s) from sub-58/ses-1\n  Loaded 1 trial(s) from sub-59/ses-1\n  Loaded 1 trial(s) from sub-60/ses-2\n  Loaded 1 trial(s) from sub-61/ses-2\n  Loaded 1 trial(s) from sub-62/ses-2\n  Loaded 1 trial(s) from sub-63/ses-2\n  Loaded 1 trial(s) from sub-65/ses-2\n  Loaded 1 trial(s) from sub-66/ses-2\n  Loaded 1 trial(s) from sub-67/ses-2\n  Loaded 1 trial(s) from sub-68/ses-2\n  Loaded 1 trial(s) from sub-69/ses-2\n  Loaded 1 trial(s) from sub-70/ses-2\n  Loaded 1 trial(s) from sub-71/ses-2\n\n[STEP 4] Finished loading raw trials.\n  Total trials loaded: 71\n  Targets shape: (71,)\n  Unique labels + counts: (array([0, 1], dtype=int32), array([59, 12]))\n[STEP 4] Using fs=500.0 Hz\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Path already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/participants.tsv\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/session_1_eeg_data.csv\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/session_2_eeg_data.csv\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-1/sub-01_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-1/sub-01_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-2/sub-01_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01/ses-2/sub-01_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-01_eeg_data.pkl\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-1/sub-02_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-1/sub-02_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-2/sub-02_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-02/ses-2/sub-02_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-1/sub-03_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-1/sub-03_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-2/sub-03_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-03/ses-2/sub-03_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-1/sub-04_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-1/sub-04_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-2/sub-04_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-04/ses-2/sub-04_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-1/sub-05_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-1/sub-05_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-2/sub-05_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-05/ses-2/sub-05_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-1/sub-06_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-1/sub-06_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-2/sub-06_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-06/ses-2/sub-06_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-1/sub-07_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-1/sub-07_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-2/sub-07_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-07/ses-2/sub-07_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-1/sub-08_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-1/sub-08_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-2/sub-08_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-08/ses-2/sub-08_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-1/sub-09_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-1/sub-09_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-2/sub-09_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-09/ses-2/sub-09_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-1/sub-10_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-1/sub-10_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-2/sub-10_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-10/ses-2/sub-10_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-1/sub-11_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-1/sub-11_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-2/sub-11_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-11/ses-2/sub-11_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-1/sub-12_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-1/sub-12_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-2/sub-12_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-12/ses-2/sub-12_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-1/sub-13_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-1/sub-13_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-2/sub-13_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-13/ses-2/sub-13_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-1/sub-14_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-1/sub-14_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-2/sub-14_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-14/ses-2/sub-14_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-1/sub-15_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-1/sub-15_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-2/sub-15_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-15/ses-2/sub-15_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-1/sub-16_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-1/sub-16_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-2/sub-16_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-16/ses-2/sub-16_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-1/sub-17_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-1/sub-17_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-2/sub-17_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-17/ses-2/sub-17_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-1/sub-18_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-1/sub-18_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-2/sub-18_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-18/ses-2/sub-18_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-1/sub-19_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-1/sub-19_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-2/sub-19_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-19/ses-2/sub-19_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-1/sub-20_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-1/sub-20_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-2/sub-20_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-20/ses-2/sub-20_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-1/sub-21_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-1/sub-21_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-2/sub-21_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-21/ses-2/sub-21_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-1/sub-22_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-1/sub-22_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-2/sub-22_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-22/ses-2/sub-22_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-1/sub-23_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-1/sub-23_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-2/sub-23_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-23/ses-2/sub-23_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-1/sub-24_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-1/sub-24_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-2/sub-24_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-24/ses-2/sub-24_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-1/sub-25_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-1/sub-25_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-2/sub-25_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-25/ses-2/sub-25_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-1/sub-26_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-1/sub-26_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-2/sub-26_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-26/ses-2/sub-26_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-1/sub-27_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-1/sub-27_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-2/sub-27_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-27/ses-2/sub-27_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-1/sub-28_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-1/sub-28_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-2/sub-28_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-28/ses-2/sub-28_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-1/sub-29_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-1/sub-29_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-2/sub-29_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-29/ses-2/sub-29_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-1/sub-30_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-1/sub-30_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-2/sub-30_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-30/ses-2/sub-30_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-1/sub-31_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-1/sub-31_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-2/sub-31_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-31/ses-2/sub-31_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-1/sub-32_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-1/sub-32_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-2/sub-32_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-32/ses-2/sub-32_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-1/sub-33_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-1/sub-33_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-2/sub-33_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-33/ses-2/sub-33_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-1/sub-34_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-1/sub-34_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-2/sub-34_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-34/ses-2/sub-34_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-1/sub-35_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-1/sub-35_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-2/sub-35_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-35/ses-2/sub-35_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-1/sub-36_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-1/sub-36_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-2/sub-36_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-36/ses-2/sub-36_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-1/sub-37_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-1/sub-37_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-2/sub-37_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-37/ses-2/sub-37_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-1/sub-38_ses-1_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-1/sub-38_ses-1_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-2/sub-38_ses-2_task-eyesclosed_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-38/ses-2/sub-38_ses-2_task-eyesclosed_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-1/sub-39_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-1/sub-39_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-2/sub-39_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-39/ses-2/sub-39_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-1/sub-40_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-1/sub-40_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-2/sub-40_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-40/ses-2/sub-40_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-1/sub-41_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-1/sub-41_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-2/sub-41_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-41/ses-2/sub-41_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-1/sub-42_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-1/sub-42_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-2/sub-42_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-42/ses-2/sub-42_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-1/sub-43_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-1/sub-43_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-2/sub-43_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-43/ses-2/sub-43_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-1/sub-44_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-1/sub-44_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-2/sub-44_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-44/ses-2/sub-44_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-1/sub-45_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-1/sub-45_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-2/sub-45_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-45/ses-2/sub-45_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-1/sub-46_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-1/sub-46_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-2/sub-46_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-46/ses-2/sub-46_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-1/sub-47_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-1/sub-47_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-2/sub-47_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-47/ses-2/sub-47_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-1/sub-48_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-1/sub-48_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-2/sub-48_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-48/ses-2/sub-48_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-1/sub-49_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-1/sub-49_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-2/sub-49_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-49/ses-2/sub-49_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-1/sub-50_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-1/sub-50_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-2/sub-50_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-50/ses-2/sub-50_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-1/sub-51_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-1/sub-51_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-2/sub-51_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-51/ses-2/sub-51_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-1/sub-52_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-1/sub-52_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-2/sub-52_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-52/ses-2/sub-52_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-1/sub-53_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-1/sub-53_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-2/sub-53_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-53/ses-2/sub-53_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-1/sub-54_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-1/sub-54_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-2/sub-54_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-54/ses-2/sub-54_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-1/sub-55_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-1/sub-55_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-2/sub-55_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-55/ses-2/sub-55_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-1/sub-56_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-1/sub-56_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-2/sub-56_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-56/ses-2/sub-56_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-1/sub-57_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-1/sub-57_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-2/sub-57_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-57/ses-2/sub-57_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-1/sub-58_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-1/sub-58_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-2/sub-58_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-58/ses-2/sub-58_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-1/sub-59_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-1/sub-59_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-2/sub-59_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-59/ses-2/sub-59_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-1/sub-60_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-1/sub-60_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-2/sub-60_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-60/ses-2/sub-60_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-1/sub-61_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-1/sub-61_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-2/sub-61_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-61/ses-2/sub-61_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-1/sub-62_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-1/sub-62_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-2/sub-62_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-62/ses-2/sub-62_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-1/sub-63_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-1/sub-63_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-2/sub-63_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-63/ses-2/sub-63_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-1/sub-64_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-1/sub-64_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-2/sub-64_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-64/ses-2/sub-64_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-1/sub-65_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-1/sub-65_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-2/sub-65_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-65/ses-2/sub-65_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-1/sub-66_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-1/sub-66_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-2/sub-66_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-66/ses-2/sub-66_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-1/sub-67_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-1/sub-67_ses-1_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-2/sub-67_ses-2_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-67/ses-2/sub-67_ses-2_task-eyesopen_eeg.set\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-68/ses-1/sub-68_ses-1_task-eyesopen_eeg.fdt\nPath already exists. Skipping download for ./azureml_eeg_data/UI/2025-12-11_033542_UTC/New Dataset/sub-68/ses-1/sub-68_ses-1_task-eyesopen_eeg.set\n/tmp/ipykernel_5730/1233017696.py:15: RuntimeWarning: Data file name in EEG.data (sub-41_ses-1_task-eyesopen_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-42_ses-1_task-eyesopen_eeg.fdt).\n  raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose=False)\n/tmp/ipykernel_5730/1233017696.py:15: RuntimeWarning: Data file name in EEG.data (sub-43_ses-1_task-eyesopen_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-44_ses-1_task-eyesopen_eeg.fdt).\n  raw = mne.io.read_raw_eeglab(file_path, preload=True, verbose=False)\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1768749893074
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5 — Fit preprocessor"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHANNEL_MAP = None\n",
        "\n",
        "pre = EEGPreprocessor(\n",
        "    index_to_name=CHANNEL_MAP,\n",
        "    use_standard_1020=True,\n",
        "    resample_to=None,\n",
        "    notch_freqs=[50.0, 100.0, 150.0],\n",
        "    highpass=0.05,\n",
        "    bad_point_z=6.0,\n",
        "    bad_channel_z=5.0,\n",
        "    interpolate_bad_channels=False,\n",
        "    car=True,\n",
        "    use_wica=True,\n",
        "    wica_components=10,\n",
        "    wica_wavelet=\"db4\",\n",
        "    wica_level=3,\n",
        "    wica_random_state=42,\n",
        ")\n",
        "\n",
        "print(\"[STEP 5] Fitting EEGPreprocessor on a subset of loaded trials...\")\n",
        "\n",
        "max_calib_trials = min(10, len(raw_list))\n",
        "if max_calib_trials == 0:\n",
        "    raise RuntimeError(\"No data to fit EEGPreprocessor.\")\n",
        "\n",
        "calib_trials = raw_list[:max_calib_trials]\n",
        "X_calib = np.concatenate(calib_trials, axis=1).astype(np.float32, copy=False)\n",
        "\n",
        "X_calib_clean, fs_out = pre.fit_transform(X_calib, fs)\n",
        "print(f\"[STEP 5] Preprocessor fitted. Output fs: {fs_out} Hz\")\n",
        "\n",
        "data_clean = []\n",
        "for i, segment in enumerate(raw_list):\n",
        "    X_clean, _ = pre.transform(segment, fs)\n",
        "    data_clean.append(X_clean.astype(np.float32, copy=False))\n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f\"[STEP 5] Preprocessed {i+1}/{len(raw_list)} trials\")\n",
        "\n",
        "data_clean = np.array(data_clean, dtype=np.float32)\n",
        "\n",
        "print(\"[STEP 5] Done preprocessing all trials.\")\n",
        "print(\"  data_clean shape:\", data_clean.shape)\n",
        "print(\"  targets shape   :\", targets.shape)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 5] Fitting EEGPreprocessor on a subset of loaded trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessor fitted. Output fs: 500.0 Hz\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessed 20/71 trials\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessed 40/71 trials\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Preprocessed 60/71 trials\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 5] Done preprocessing all trials.\n  data_clean shape: (71, 61, 108000)\n  targets shape   : (71,)\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1768750073101
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6 — Augmentation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_data(data: np.ndarray, target: int, segment_size: int = 100):\n",
        "    augmented_data = []\n",
        "    augmented_targets = []\n",
        "\n",
        "    if data.ndim == 3:\n",
        "        data = data[0]\n",
        "\n",
        "    n_segments = data.shape[1] // segment_size\n",
        "\n",
        "    for i in range(n_segments):\n",
        "        seg = data[:, i * segment_size:(i + 1) * segment_size]\n",
        "        augmented_data.append(seg.astype(np.float32, copy=False))\n",
        "        augmented_targets.append(int(target))\n",
        "\n",
        "    return augmented_data, augmented_targets\n",
        "\n",
        "\n",
        "print(\"[STEP 6] Augmenting all trials...\")\n",
        "\n",
        "augmented = []\n",
        "aug_targets = []\n",
        "aug_subject_ids = []\n",
        "\n",
        "for trial, y, subj in zip(data_clean, targets, subject_ids):\n",
        "    segs, ys = augment_data(trial, int(y), segment_size=100)\n",
        "    augmented.extend(segs)\n",
        "    aug_targets.extend(ys)\n",
        "    aug_subject_ids.extend([subj] * len(segs))\n",
        "\n",
        "augmented = np.array(augmented, dtype=np.float32)\n",
        "aug_targets = np.array(aug_targets, dtype=np.int32)\n",
        "aug_subject_ids = np.array(aug_subject_ids)\n",
        "\n",
        "print(\"[STEP 6] Augmentation done.\")\n",
        "print(\"  augmented shape:\", augmented.shape)\n",
        "print(\"  aug_targets shape:\", aug_targets.shape)\n",
        "print(\"  Class counts (augmented):\", np.unique(aug_targets, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 6] Augmenting all trials...\n[STEP 6] Augmentation done.\n  augmented shape: (76680, 61, 100)\n  aug_targets shape: (76680,)\n  Class counts (augmented): (array([0, 1], dtype=int32), array([63720, 12960]))\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1768750093431
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7 — Fair selection"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 7] Grouping segments by subject and class...\")\n",
        "\n",
        "subject_data = defaultdict(lambda: {0: [], 1: []})\n",
        "\n",
        "for x, y, subj in zip(augmented, aug_targets, aug_subject_ids):\n",
        "    subject_data[subj][int(y)].append(x)\n",
        "\n",
        "max_per_class_per_subject = 200\n",
        "\n",
        "selected_data = []\n",
        "selected_targets = []\n",
        "\n",
        "print(\"[STEP 7] Selecting up to 200 segments per (subject, class)...\")\n",
        "\n",
        "for subj in subjects_used:\n",
        "    for class_label in [0, 1]:\n",
        "        samples = subject_data.get(subj, {0: [], 1: []})[class_label]\n",
        "        picked = samples[:max_per_class_per_subject]\n",
        "        selected_data.extend(picked)\n",
        "        selected_targets.extend([class_label] * len(picked))\n",
        "\n",
        "selected_data = np.array(selected_data, dtype=np.float32)\n",
        "selected_targets = np.array(selected_targets, dtype=np.int32)\n",
        "\n",
        "print(\"[STEP 7] Selection done.\")\n",
        "print(\"  selected_data shape:\", selected_data.shape)\n",
        "print(\"  selected_targets shape:\", selected_targets.shape)\n",
        "print(\"  Class counts (selected):\", np.unique(selected_targets, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 7] Grouping segments by subject and class...\n[STEP 7] Selecting up to 200 segments per (subject, class)...\n[STEP 7] Selection done.\n  selected_data shape: (14200, 61, 100)\n  selected_targets shape: (14200,)\n  Class counts (selected): (array([0, 1], dtype=int32), array([11800,  2400]))\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1768750115902
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8 — Reshape for CNN input"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 8] Reshaping for CNN...\")\n",
        "\n",
        "X_all = selected_data[..., np.newaxis].astype(np.float32, copy=False)\n",
        "y_all = selected_targets.astype(np.int32, copy=False)\n",
        "\n",
        "print(\"[STEP 8] Done.\")\n",
        "print(\"  X_all shape:\", X_all.shape)\n",
        "print(\"  y_all shape:\", y_all.shape)\n",
        "print(\"  Class counts:\", np.unique(y_all, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 8] Reshaping for CNN...\n[STEP 8] Done.\n  X_all shape: (14200, 61, 100, 1)\n  y_all shape: (14200,)\n  Class counts: (array([0, 1], dtype=int32), array([11800,  2400]))\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1768750137812
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9 — EEGNet model definition"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(opt):\n",
        "    try:\n",
        "        return float(tf.keras.backend.get_value(opt.learning_rate))\n",
        "    except Exception:\n",
        "        try:\n",
        "            return float(opt.learning_rate.numpy())\n",
        "        except Exception:\n",
        "            try:\n",
        "                return float(opt.lr.numpy())\n",
        "            except Exception:\n",
        "                return float(getattr(opt, \"lr\", 0.0))\n",
        "\n",
        "\n",
        "def create_eegnet(input_shape, dropout_rate=0.5, num_classes=1):\n",
        "    n_electrodes = input_shape[0]\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(16, (1, 64), padding='same', use_bias=False)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    x = DepthwiseConv2D((n_electrodes, 1), depth_multiplier=2, padding='valid', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('elu')(x)\n",
        "    x = AveragePooling2D((1, 4))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = SeparableConv2D(16, (1, 16), padding='same', use_bias=False)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('elu')(x)\n",
        "    x = AveragePooling2D((1, 8))(x)\n",
        "    x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    outputs = Dense(num_classes, activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs, name=\"EEGNet_simple\")\n",
        "\n",
        "\n",
        "print(\"✅ Model function defined.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Model function defined.\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1768750159134
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10 — Prepare full dataset + normalization"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"[STEP 10A] PREPARE FULL DATASET + NORMALIZATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "X_train_raw = X_all.astype(np.float32, copy=False)\n",
        "y_train_raw = y_all.astype(np.int32, copy=False)\n",
        "\n",
        "n_electrodes = X_train_raw.shape[1]\n",
        "segment_size = X_train_raw.shape[2]\n",
        "input_shape = (n_electrodes, segment_size, 1)\n",
        "\n",
        "print(f\"[STEP 10A] Input shape: {input_shape}\")\n",
        "print(f\"[STEP 10A] Total samples: {X_train_raw.shape[0]}\")\n",
        "\n",
        "epsilon = 1e-6\n",
        "train_mean = np.mean(X_train_raw, axis=(0, 2, 3), keepdims=True)\n",
        "train_std  = np.std(X_train_raw, axis=(0, 2, 3), keepdims=True)\n",
        "train_std  = np.maximum(train_std, epsilon)\n",
        "\n",
        "X_train_norm = ((X_train_raw - train_mean) / train_std).astype(np.float32)\n",
        "\n",
        "print(\"[STEP 10A] ✅ Normalization complete\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n================================================================================\n[STEP 10A] PREPARE FULL DATASET + NORMALIZATION\n================================================================================\n[STEP 10A] Input shape: (61, 100, 1)\n[STEP 10A] Total samples: 14200\n[STEP 10A] ✅ Normalization complete\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1768750212133
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 11 — SMOTE balancing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "print(\"\\n\" + \"-\" * 80)\n",
        "print(\"[STEP 10B] SMOTE CONFIRMATION BLOCK\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "X_train_2d = X_train_norm.reshape(X_train_norm.shape[0], -1)\n",
        "\n",
        "counts_before = Counter(y_train_raw.tolist())\n",
        "total_before = sum(counts_before.values())\n",
        "minority_n = min(counts_before.values())\n",
        "\n",
        "print(\"\\n[STEP 10B] Label counts BEFORE balancing:\")\n",
        "for cls, cnt in sorted(counts_before.items()):\n",
        "    print(f\"  Class {cls}: {cnt}\")\n",
        "\n",
        "print(f\"[STEP 10B] Total samples BEFORE: {total_before}\")\n",
        "print(f\"[STEP 10B] Minority class size : {minority_n}\")\n",
        "\n",
        "if minority_n >= 2:\n",
        "    k_neighbors = max(1, min(5, minority_n - 1))\n",
        "    smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "    X_train_bal_2d, y_train_bal_int = smote.fit_resample(X_train_2d, y_train_raw)\n",
        "    sampler_used = f\"SMOTE (k_neighbors={k_neighbors})\"\n",
        "else:\n",
        "    ros = RandomOverSampler(random_state=42)\n",
        "    X_train_bal_2d, y_train_bal_int = ros.fit_resample(X_train_2d, y_train_raw)\n",
        "    sampler_used = \"RandomOverSampler\"\n",
        "\n",
        "print(f\"\\n[STEP 10B] ✅ Sampler USED: {sampler_used}\")\n",
        "\n",
        "counts_after = Counter(y_train_bal_int.tolist())\n",
        "total_after = sum(counts_after.values())\n",
        "\n",
        "print(\"\\n[STEP 10B] Label counts AFTER balancing:\")\n",
        "for cls, cnt in sorted(counts_after.items()):\n",
        "    print(f\"  Class {cls}: {cnt}\")\n",
        "\n",
        "print(f\"[STEP 10B] Total samples AFTER : {total_after}\")\n",
        "print(f\"[STEP 10B] Samples added       : {total_after - total_before}\")\n",
        "\n",
        "X_train_bal = X_train_bal_2d.reshape(-1, n_electrodes, segment_size, 1).astype(np.float32)\n",
        "y_train_bal = y_train_bal_int.astype(np.float32)\n",
        "\n",
        "print(\"\\n[STEP 10B] Final balanced tensors:\")\n",
        "print(f\"  X_train_bal shape: {X_train_bal.shape}\")\n",
        "print(f\"  y_train_bal shape: {y_train_bal.shape}\")\n",
        "\n",
        "print(\"-\" * 80)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n--------------------------------------------------------------------------------\n[STEP 10B] SMOTE CONFIRMATION BLOCK\n--------------------------------------------------------------------------------\n\n[STEP 10B] Label counts BEFORE balancing:\n  Class 0: 11800\n  Class 1: 2400\n[STEP 10B] Total samples BEFORE: 14200\n[STEP 10B] Minority class size : 2400\n\n[STEP 10B] ✅ Sampler USED: SMOTE (k_neighbors=5)\n\n[STEP 10B] Label counts AFTER balancing:\n  Class 0: 11800\n  Class 1: 11800\n[STEP 10B] Total samples AFTER : 23600\n[STEP 10B] Samples added       : 9400\n\n[STEP 10B] Final balanced tensors:\n  X_train_bal shape: (23600, 61, 100, 1)\n  y_train_bal shape: (23600,)\n--------------------------------------------------------------------------------\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1768750240933
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 13 — Callbacks"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ReduceLROnPlateau(\n",
        "        monitor=\"loss\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    ),\n",
        "    EarlyStopping(\n",
        "        monitor=\"loss\",\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    ModelCheckpoint(\n",
        "        filepath=\"EEGNet-SD-Final.keras\",\n",
        "        monitor=\"loss\",\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    ),\n",
        "    CSVLogger(\"final_model_training_log.csv\", append=False),\n",
        "]\n",
        "\n",
        "print(\"✅ Callbacks ready.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Callbacks ready.\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1768750287969
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 14 — Train"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 300\n",
        "BATCH_SIZE = 200\n",
        "\n",
        "print(\"\\n[STEP 10D] 🚀 Starting training\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_bal,\n",
        "    y_train_bal,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"[STEP 10D] ✅ Training complete\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n[STEP 10D] 🚀 Starting training\n================================================================================\nEpoch 1/300\n\u001b[1m 81/118\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.6566 - loss: 0.6190\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 82/118\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 274ms/step - accuracy: 0.6568 - loss: 0.6187 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 95/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 274ms/step - accuracy: 0.6604 - loss: 0.6150\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m 96/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 274ms/step - accuracy: 0.6607 - loss: 0.6147"
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 15 — Evaluation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss, train_acc = model.evaluate(\n",
        "    X_train_bal,\n",
        "    y_train_bal,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(f\"\\n[FINAL] Training loss    : {train_loss:.6f}\")\n",
        "print(f\"[FINAL] Training accuracy: {train_acc:.6f}\")\n",
        "\n",
        "y_prob = model.predict(\n",
        "    X_train_bal,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    verbose=1\n",
        ").reshape(-1)\n",
        "\n",
        "y_pred = (y_prob > 0.5).astype(int)\n",
        "\n",
        "cm = confusion_matrix(y_train_bal.astype(int), y_pred)\n",
        "\n",
        "print(\"\\n[FINAL] Training Confusion Matrix\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\n[FINAL] Classification Report\")\n",
        "print(classification_report(\n",
        "    y_train_bal.astype(int),\n",
        "    y_pred,\n",
        "    target_names=[\"Class 0\", \"Class 1\"]\n",
        "))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"[FINAL] ✅ FULL PIPELINE COMPLETED SUCCESSFULLY\")\n",
        "print(\"       Model: EEGNet-SD-Final.keras\")\n",
        "print(\"       Log  : final_model_training_log.csv\")\n",
        "print(\"=\" * 80)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.10 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}