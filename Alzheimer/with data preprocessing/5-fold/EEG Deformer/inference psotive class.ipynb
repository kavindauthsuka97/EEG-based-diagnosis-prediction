{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4b572c-0225-422f-8d84-10fb8b49d2c2",
   "metadata": {},
   "source": [
    "CELL 1 — Imports + seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9555a00-9b76-4e4e-84be-aac3699cf002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\DL\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports loaded and seeds set.\n"
     ]
    }
   ],
   "source": [
    "# Operating system utilities\n",
    "import os\n",
    "\n",
    "# Array handling\n",
    "import numpy as np\n",
    "\n",
    "# Pickle for loading normalization stats\n",
    "import pickle\n",
    "\n",
    "# EEG preprocessing libraries\n",
    "import mne\n",
    "import pywt\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"✅ Imports loaded and seeds set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898c39a-4931-4584-a1b4-465d83bd85c8",
   "metadata": {},
   "source": [
    "CELL 2 — Load trained model + normalization stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08364221-736a-4bb5-af25-c225104902fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EEG Deformer model loaded successfully.\n",
      "✅ Training mean and std loaded.\n",
      "✅ Safe model saved to:\n",
      "C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Alzheimer\\model inference\\ad_deformer-v1_SAFE.h5\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# EEG DEFORMER – SAFE INFERENCE SCRIPT (ALL-IN-ONE)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "\n",
    "MODEL_PATH = r\"C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Alzheimer\\model inference\\eeg deformer model\\ad_deformer-v1.keras\"\n",
    "MEAN_PATH  = r\"C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Alzheimer\\model inference\\train_mean.pkl\"\n",
    "STD_PATH   = r\"C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Alzheimer\\model inference\\train_std.pkl\"\n",
    "SAFE_MODEL_PATH = r\"C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Alzheimer\\model inference\\ad_deformer-v1_SAFE.h5\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# DEFORMER BUILDING BLOCKS\n",
    "# ============================================================\n",
    "\n",
    "def feed_forward_block(x, hidden_dim, dropout=0.5):\n",
    "    d = tf.keras.backend.int_shape(x)[-1]\n",
    "    y = layers.LayerNormalization()(x)\n",
    "    y = layers.Dense(hidden_dim, activation=\"gelu\")(y)\n",
    "    y = layers.Dropout(dropout)(y)\n",
    "    y = layers.Dense(d)(y)\n",
    "    y = layers.Dropout(dropout)(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def attention_block(x, dim_head=16, heads=16, dropout=0.5):\n",
    "    D = tf.keras.backend.int_shape(x)[-1]\n",
    "    mha = layers.MultiHeadAttention(\n",
    "        num_heads=heads,\n",
    "        key_dim=dim_head,\n",
    "        dropout=dropout,\n",
    "        output_shape=D\n",
    "    )\n",
    "    y = mha(x, x)\n",
    "    y = layers.Dropout(dropout)(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def cnn_1d_block(x, in_chan, kernel_size, dropout=0.5):\n",
    "    y = layers.Dropout(dropout)(x)\n",
    "    y = layers.Conv1D(\n",
    "        filters=in_chan,\n",
    "        kernel_size=kernel_size,\n",
    "        padding=\"same\",\n",
    "        data_format=\"channels_first\"\n",
    "    )(y)\n",
    "    y = layers.BatchNormalization(axis=1)(y)\n",
    "    y = layers.ELU()(y)\n",
    "    y = layers.MaxPooling1D(\n",
    "        pool_size=2,\n",
    "        strides=2,\n",
    "        data_format=\"channels_first\"\n",
    "    )(y)\n",
    "    return y\n",
    "\n",
    "\n",
    "def get_info_tensor(x):\n",
    "    return tf.math.log(tf.reduce_mean(tf.square(x), axis=-1) + 1e-12)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EEG DEFORMER MODEL (MATCHES TRAINING EXACTLY)\n",
    "# ============================================================\n",
    "\n",
    "def build_eeg_deformer_keras(\n",
    "    num_chan=127,\n",
    "    num_time=100,\n",
    "    temporal_kernel=15,\n",
    "    num_kernel=64,\n",
    "    num_classes=1,\n",
    "    depth=4,\n",
    "    heads=16,\n",
    "    mlp_dim=16,\n",
    "    dim_head=16,\n",
    "    dropout=0.5,\n",
    "):\n",
    "\n",
    "    inp = layers.Input(shape=(num_chan, num_time), name=\"eeg_input\")\n",
    "    x = layers.Lambda(lambda t: tf.expand_dims(t, axis=1))(inp)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        num_kernel,\n",
    "        (1, temporal_kernel),\n",
    "        padding=\"same\",\n",
    "        data_format=\"channels_first\",\n",
    "        kernel_constraint=max_norm(2.0)\n",
    "    )(x)\n",
    "\n",
    "    x = layers.Conv2D(\n",
    "        num_kernel,\n",
    "        (num_chan, 1),\n",
    "        padding=\"valid\",\n",
    "        data_format=\"channels_first\",\n",
    "        kernel_constraint=max_norm(2.0)\n",
    "    )(x)\n",
    "\n",
    "    x = layers.BatchNormalization(axis=1)(x)\n",
    "    x = layers.ELU()(x)\n",
    "    x = layers.MaxPool2D(\n",
    "        pool_size=(1, 2),\n",
    "        strides=(1, 2),\n",
    "        data_format=\"channels_first\"\n",
    "    )(x)\n",
    "\n",
    "    dim = num_time // 2\n",
    "    x = layers.Permute((1, 3, 2))(x)\n",
    "    x = layers.Reshape((num_kernel, dim))(x)\n",
    "\n",
    "    dense_features = []\n",
    "    pool_coarse = layers.MaxPooling1D(\n",
    "        pool_size=2,\n",
    "        strides=2,\n",
    "        data_format=\"channels_first\"\n",
    "    )\n",
    "\n",
    "    for _ in range(depth):\n",
    "        x_cg = pool_coarse(x)\n",
    "\n",
    "        attn = attention_block(\n",
    "            x_cg,\n",
    "            dim_head=dim_head,\n",
    "            heads=heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        x_cg = layers.Add()([x_cg, attn])\n",
    "\n",
    "        x_fg = cnn_1d_block(\n",
    "            x,\n",
    "            in_chan=num_kernel,\n",
    "            kernel_size=temporal_kernel,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        info = layers.Lambda(get_info_tensor)(x_fg)\n",
    "        dense_features.append(info)\n",
    "\n",
    "        ff = feed_forward_block(\n",
    "            x_cg,\n",
    "            hidden_dim=mlp_dim,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        x = layers.Add()([ff, x_fg])\n",
    "\n",
    "    x_flat = layers.Flatten()(x)\n",
    "    x_dense = layers.Concatenate(axis=-1)(dense_features)\n",
    "    embedding = layers.Concatenate(axis=-1)([x_flat, x_dense])\n",
    "\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(embedding)\n",
    "    return Model(inp, out, name=\"EEG_Deformer\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EXTRACT WEIGHTS FROM .KERAS\n",
    "# ============================================================\n",
    "\n",
    "def extract_weights_from_keras(keras_path):\n",
    "    tmp_dir = tempfile.mkdtemp(prefix=\"keras_weights_\")\n",
    "    with zipfile.ZipFile(keras_path, \"r\") as z:\n",
    "        names = z.namelist()\n",
    "        weight_files = [\n",
    "            n for n in names\n",
    "            if n.endswith(\".h5\") and \"weights\" in n.lower()\n",
    "        ]\n",
    "        if not weight_files:\n",
    "            raise FileNotFoundError(\n",
    "                f\"No weights file found inside {keras_path}\"\n",
    "            )\n",
    "        z.extract(weight_files[0], tmp_dir)\n",
    "        return os.path.join(tmp_dir, weight_files[0])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BUILD MODEL + LOAD WEIGHTS\n",
    "# ============================================================\n",
    "\n",
    "model = build_eeg_deformer_keras()\n",
    "\n",
    "weights_path = extract_weights_from_keras(MODEL_PATH)\n",
    "model.load_weights(weights_path)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\", threshold=0.5)]\n",
    ")\n",
    "\n",
    "print(\"✅ EEG Deformer model loaded successfully.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOAD TRAINING MEAN / STD\n",
    "# ============================================================\n",
    "\n",
    "with open(MEAN_PATH, \"rb\") as f:\n",
    "    train_mean = pickle.load(f)\n",
    "\n",
    "with open(STD_PATH, \"rb\") as f:\n",
    "    train_std = pickle.load(f)\n",
    "\n",
    "print(\"✅ Training mean and std loaded.\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SAVE SAFE MODEL (NO .KERAS ISSUES)\n",
    "# ============================================================\n",
    "\n",
    "model.save(SAFE_MODEL_PATH)\n",
    "print(f\"✅ Safe model saved to:\\n{SAFE_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44d222-4daf-466f-b55f-07ccac26ebb3",
   "metadata": {},
   "source": [
    "CELL 3 — Load ONLY excluded trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4552ccad-4bc8-4f23-aa72-b04edccd2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EEG arrays loaded.\n",
      "Negative shape: (31, 127, 150000)\n",
      "Positive shape: (46, 127, 150000)\n",
      "✅ Extracted excluded trials:\n",
      "Excluded negative: (5, 127, 150000)\n",
      "Excluded positive: (5, 127, 150000)\n"
     ]
    }
   ],
   "source": [
    "# Local EEG data paths\n",
    "NEG_PATH = r\"D:\\Dermerzel\\SomnasNest\\Alzheimer\\Data\\ad_negative.npy\"\n",
    "POS_PATH = r\"D:\\Dermerzel\\SomnasNest\\Alzheimer\\Data\\ad_positive.npy\"\n",
    "\n",
    "# Load full arrays\n",
    "X_neg_full = np.load(NEG_PATH).astype(np.float32)\n",
    "X_pos_full = np.load(POS_PATH).astype(np.float32)\n",
    "\n",
    "print(\"✅ EEG arrays loaded.\")\n",
    "print(\"Negative shape:\", X_neg_full.shape)\n",
    "print(\"Positive shape:\", X_pos_full.shape)\n",
    "\n",
    "# Extract ONLY last 5 trials (excluded during training)\n",
    "X_neg_excluded = X_neg_full[-5:]\n",
    "X_pos_excluded = X_pos_full[-5:]\n",
    "\n",
    "print(\"✅ Extracted excluded trials:\")\n",
    "print(\"Excluded negative:\", X_neg_excluded.shape)\n",
    "print(\"Excluded positive:\", X_pos_excluded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14208a60-780a-419f-8239-5bdba714d398",
   "metadata": {},
   "source": [
    "CELL 4 — Select ONLY last ad_negative sample (target = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ee70b32e-df6b-4001-b9ec-e84ce66475a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selected last excluded ad_positive trial.\n",
      "Trial shape: (127, 150000)\n",
      "Ground truth label: 1\n"
     ]
    }
   ],
   "source": [
    "# Select ONLY the last excluded positive trial\n",
    "X_test_trial = X_pos_excluded[-5]        # last unseen ad_positive sample\n",
    "y_test_trial = 1                         # ground truth label (positive)\n",
    "\n",
    "print(\"✅ Selected last excluded ad_positive trial.\")\n",
    "print(\"Trial shape:\", X_test_trial.shape)\n",
    "print(\"Ground truth label:\", y_test_trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0295f-fe0e-489d-97df-27399a0c364a",
   "metadata": {},
   "source": [
    "* downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6e6702a-c1e9-4bd6-b1c8-88a49c9fd15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 246\n",
      "✅ Downsampled X_test_trial to 500 Hz.\n",
      "Trial shape after downsampling: (127, 75000) float32\n"
     ]
    }
   ],
   "source": [
    "# --- Downsample from 1000 Hz -> 500 Hz (keep output name: X_test_trial) ---\n",
    "sfreq_in = 1000\n",
    "sfreq_out = 500\n",
    "\n",
    "X_test_trial = mne.filter.resample(\n",
    "    X_test_trial.astype(np.float64, copy=False),\n",
    "    down=sfreq_in // sfreq_out,   # 2\n",
    "    npad=\"auto\",\n",
    "    axis=-1,\n",
    "    verbose=True\n",
    ").astype(np.float32, copy=False)\n",
    "\n",
    "print(\"✅ Downsampled X_test_trial to 500 Hz.\")\n",
    "print(\"Trial shape after downsampling:\", X_test_trial.shape, X_test_trial.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1148bf-53c8-4dc9-b4c7-7a619900d547",
   "metadata": {},
   "source": [
    "CELL 5 — Helper + preprocessing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0a5bed4-e578-451a-b8c7-3b69c8269fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing helpers defined.\n"
     ]
    }
   ],
   "source": [
    "# Helper to generate channel names\n",
    "def _names_from_index_mapping(n_channels, index_to_name):\n",
    "    return [f\"EEG{i+1}\" for i in range(n_channels)]\n",
    "\n",
    "# Helper to create MNE Raw object\n",
    "def _make_raw(eeg, sfreq, ch_names):\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=\"eeg\")\n",
    "    return mne.io.RawArray(eeg, info, verbose=False)\n",
    "\n",
    "# Wavelet ICA class\n",
    "class WaveletICA:\n",
    "    def __init__(self, wavelet=\"db4\", level=3, n_components=10):\n",
    "        self.wavelet = wavelet\n",
    "        self.level = level\n",
    "        self.n_components = n_components\n",
    "        self.ica = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        coeffs = pywt.wavedec(X, self.wavelet, level=self.level, axis=1)\n",
    "        A = coeffs[0]\n",
    "        self.ica = FastICA(n_components=min(self.n_components, X.shape[0]), random_state=42)\n",
    "        S = self.ica.fit_transform(A.T)\n",
    "        coeffs[0] = self.ica.inverse_transform(S).T\n",
    "        pywt.waverec(coeffs, self.wavelet, axis=1)\n",
    "\n",
    "    def transform(self, X):\n",
    "        coeffs = pywt.wavedec(X, self.wavelet, level=self.level, axis=1)\n",
    "        A = coeffs[0]\n",
    "        S = self.ica.transform(A.T)\n",
    "        coeffs[0] = self.ica.inverse_transform(S).T\n",
    "        return pywt.waverec(coeffs, self.wavelet, axis=1)\n",
    "\n",
    "print(\"✅ Preprocessing helpers defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecabba65-f176-40ee-9616-ad5b75683307",
   "metadata": {},
   "source": [
    "CELL 6 — Apply preprocessing to unseen test trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9e670665-042a-4004-a0c1-e5028b004408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "✅ Preprocessing applied.\n",
      "Cleaned trial shape: (127, 75000)\n"
     ]
    }
   ],
   "source": [
    "# Sampling frequency (same as training)\n",
    "fs = 500.0\n",
    "\n",
    "# Create Raw object\n",
    "raw = _make_raw(X_test_trial, fs, _names_from_index_mapping(X_test_trial.shape[0], None))\n",
    "\n",
    "# Notch filtering\n",
    "raw.notch_filter([50, 100, 150], verbose=False)\n",
    "\n",
    "# High-pass filtering\n",
    "raw.filter(l_freq=0.05, h_freq=None, verbose=False)\n",
    "\n",
    "# Common average reference\n",
    "raw.set_eeg_reference(\"average\", projection=True)\n",
    "raw.apply_proj()\n",
    "\n",
    "# Extract cleaned signal\n",
    "X_clean = raw.get_data().astype(np.float32)\n",
    "\n",
    "print(\"✅ Preprocessing applied.\")\n",
    "print(\"Cleaned trial shape:\", X_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880869e-281e-48f6-adde-aeb7969bf9e4",
   "metadata": {},
   "source": [
    "CELL 7 — Segment test trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8840de4-a842-4379-ac3c-3b6385c9981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial segmented.\n",
      "Segments shape: (750, 127, 100)\n"
     ]
    }
   ],
   "source": [
    "# Segment size\n",
    "SEGMENT_SIZE = 100\n",
    "\n",
    "# Segment the trial\n",
    "segments = []\n",
    "for i in range(X_clean.shape[1] // SEGMENT_SIZE):\n",
    "    seg = X_clean[:, i*SEGMENT_SIZE:(i+1)*SEGMENT_SIZE]\n",
    "    segments.append(seg)\n",
    "\n",
    "# Convert to array\n",
    "X_test_segments = np.array(segments, dtype=np.float32)\n",
    "\n",
    "print(\"✅ Trial segmented.\")\n",
    "print(\"Segments shape:\", X_test_segments.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73a256-a43b-42ea-b6de-1ef798c1e7b7",
   "metadata": {},
   "source": [
    "CELL 8 — Reshape + normalize using TRAINING stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94c63994-1590-45d6-90cb-29ab2674e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalization applied using training statistics.\n",
      "Final test shape: (750, 127, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add channel dimension\n",
    "X_test = X_test_segments[..., np.newaxis]\n",
    "\n",
    "# Normalize using training mean/std\n",
    "X_test_norm = (X_test - train_mean) / train_std\n",
    "\n",
    "print(\"✅ Normalization applied using training statistics.\")\n",
    "print(\"Final test shape:\", X_test_norm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2331cf-a7bc-4b88-84a8-a99960ade91e",
   "metadata": {},
   "source": [
    "CELL 9 — Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67b0ffea-89a3-483a-8b2e-d4f1669879f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference completed for ad_positive trial.\n",
      "First 10 predicted labels: [1 1 1 1 1 1 1 1 1 1]\n",
      "Total segments: 750\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for each segment\n",
    "y_probs = model.predict(X_test_norm, verbose=0)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_preds = (y_probs >= 0.5).astype(int).flatten()\n",
    "\n",
    "# Ground truth labels (ALL ones because ad_positive)\n",
    "y_true = np.ones_like(y_preds)\n",
    "\n",
    "print(\"✅ Inference completed for ad_positive trial.\")\n",
    "print(\"First 10 predicted labels:\", y_preds[:10])\n",
    "print(\"Total segments:\", len(y_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c815e60-49db-4e87-9b17-38152116265f",
   "metadata": {},
   "source": [
    "CELL 10 — Confusion matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "000085f8-31ca-407c-acbb-62678e563ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion matrix plotted for ad_positive trial.\n"
     ]
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_preds)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Negative\", \"Positive\"],\n",
    "    yticklabels=[\"Negative\", \"Positive\"]\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix — Last Excluded ad_positive Sample\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Confusion matrix plotted for ad_positive trial.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6490f5e3-268a-42af-91a1-501235308314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Saliency (segments):   5%|▍         | 37/750 [00:20<06:34,  1.81it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_5808\\2866596788.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Compute saliency for each segment in your unseen trial\u001b[39;00m\n\u001b[32m     59\u001b[39m all_saliencies = []\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m tqdm(range(X_test_norm.shape[\u001b[32m0\u001b[39m]), desc=\u001b[33m\"Computing Saliency (segments)\"\u001b[39m):\n\u001b[32m     61\u001b[39m     sample = X_test_norm[i:i+\u001b[32m1\u001b[39m]                          \u001b[38;5;66;03m# (1, C, T, 1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     sal = compute_electrode_saliency(model, sample, class_index=\u001b[32m1\u001b[39m)\n\u001b[32m     63\u001b[39m     all_saliencies.append(sal)\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m all_saliencies = np.array(all_saliencies, dtype=np.float32)   \u001b[38;5;66;03m# (n_segments, C)\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_5808\\2866596788.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(model, input_sample, class_index)\u001b[39m\n\u001b[32m     38\u001b[39m     input_sample = tf.convert_to_tensor(input_sample, dtype=tf.float32)\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     41\u001b[39m         tape.watch(input_sample)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         pred = model(input_sample, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m         \u001b[38;5;66;03m# Make a scalar target to differentiate\u001b[39;00m\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pred.shape[-\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    976\u001b[39m                 )\n\u001b[32m    977\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    978\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    980\u001b[39m \n\u001b[32m    981\u001b[39m         \u001b[38;5;66;03m################################################\u001b[39;00m\n\u001b[32m    982\u001b[39m         \u001b[38;5;66;03m# 8. Add a node in the graph for symbolic calls.\u001b[39;00m\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m                 call_fn,\n\u001b[32m     57\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     58\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\models\\functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m             masks = tree.flatten(mask)\n\u001b[32m    180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m x, mask \u001b[38;5;28;01min\u001b[39;00m zip(inputs, masks):\n\u001b[32m    181\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m                     backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         outputs = self._run_through_graph(\n\u001b[32m    184\u001b[39m             inputs,\n\u001b[32m    185\u001b[39m             operation_fn=lambda op: operation_fn(\n\u001b[32m    186\u001b[39m                 op, training=training, **kwargs\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    202\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m                     \u001b[38;5;66;03m# Use NNX operation mapping\u001b[39;00m\n\u001b[32m    204\u001b[39m                     operation = self._get_operation_for_node(node)\n\u001b[32m    205\u001b[39m                     op = operation_fn(operation)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m                     outputs = op(*args, **kwargs)\n\u001b[32m    207\u001b[39m \n\u001b[32m    208\u001b[39m                 \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    209\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;28;01min\u001b[39;00m zip(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\models\\functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    640\u001b[39m                 \u001b[38;5;28;01mand\u001b[39;00m value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m             ):\n\u001b[32m    642\u001b[39m                 kwargs[name] = value\n\u001b[32m    643\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m operation(*args, **kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    976\u001b[39m                 )\n\u001b[32m    977\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    978\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    980\u001b[39m \n\u001b[32m    981\u001b[39m         \u001b[38;5;66;03m################################################\u001b[39;00m\n\u001b[32m    982\u001b[39m         \u001b[38;5;66;03m# 8. Add a node in the graph for symbolic calls.\u001b[39;00m\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m                 call_fn,\n\u001b[32m     57\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     58\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\conv1d.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    147\u001b[39m             \u001b[38;5;66;03m# Apply causal padding to inputs.\u001b[39;00m\n\u001b[32m    148\u001b[39m             inputs = ops.pad(inputs, self._compute_causal_padding())\n\u001b[32m    149\u001b[39m             padding = \u001b[33m\"valid\"\u001b[39m\n\u001b[32m    150\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m         outputs = ops.conv(\n\u001b[32m    152\u001b[39m             inputs,\n\u001b[32m    153\u001b[39m             self.kernel,\n\u001b[32m    154\u001b[39m             strides=list(self.strides),\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\nn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(inputs, kernel, strides, padding, data_format, dilation_rate)\u001b[39m\n\u001b[32m   1338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((inputs,)):\n\u001b[32m   1339\u001b[39m         return Conv(strides, padding, data_format, dilation_rate).symbolic_call(\n\u001b[32m   1340\u001b[39m             inputs, kernel\n\u001b[32m   1341\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     return backend.nn.conv(\n\u001b[32m   1343\u001b[39m         inputs, kernel, strides, padding, data_format, dilation_rate\n\u001b[32m   1344\u001b[39m     )\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(inputs, kernel, strides, padding, data_format, dilation_rate)\u001b[39m\n\u001b[32m    336\u001b[39m     needs_xla = needs_xla \u001b[38;5;28;01mor\u001b[39;00m channels != kernel.shape[-\u001b[32m2\u001b[39m]\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m needs_xla:\n\u001b[32m    338\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _conv_xla()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _conv()\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m _conv():\n\u001b[32m    312\u001b[39m         tf_data_format = _convert_data_format(data_format, len(inputs.shape))\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m         return tf.nn.convolution(\n\u001b[32m    314\u001b[39m             inputs,\n\u001b[32m    315\u001b[39m             kernel,\n\u001b[32m    316\u001b[39m             strides,\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1261\u001b[39m \n\u001b[32m   1262\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1266\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input, filters, strides, padding, data_format, dilations, name)\u001b[39m\n\u001b[32m   1182\u001b[39m     padding=\u001b[33m\"VALID\"\u001b[39m,\n\u001b[32m   1183\u001b[39m     data_format=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1184\u001b[39m     dilations=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1185\u001b[39m     name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1186\u001b[39m   return convolution_internal(\n\u001b[32m   1187\u001b[39m       input,  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[32m   1188\u001b[39m       filters,\n\u001b[32m   1189\u001b[39m       strides=strides,\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[39m\n\u001b[32m   1315\u001b[39m         op = _conv3d_expanded_batch\n\u001b[32m   1316\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1317\u001b[39m         op = conv1d\n\u001b[32m   1318\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1319\u001b[39m       return op(\n\u001b[32m   1320\u001b[39m           input,\n\u001b[32m   1321\u001b[39m           filters,\n\u001b[32m   1322\u001b[39m           strides,\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1261\u001b[39m \n\u001b[32m   1262\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1266\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    656\u001b[39m                   _call_location(), decorator_utils.get_qualified_name(func),\n\u001b[32m    657\u001b[39m                   func.__module__, arg_name, arg_value,\n\u001b[32m    658\u001b[39m                   \u001b[33m'in a future version'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[32m    659\u001b[39m                   (\u001b[33m'after %s'\u001b[39m % date), instructions)\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    656\u001b[39m                   _call_location(), decorator_utils.get_qualified_name(func),\n\u001b[32m    657\u001b[39m                   func.__module__, arg_name, arg_value,\n\u001b[32m    658\u001b[39m                   \u001b[33m'in a future version'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[32m    659\u001b[39m                   (\u001b[33m'after %s'\u001b[39m % date), instructions)\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name, input, dilations)\u001b[39m\n\u001b[32m   2069\u001b[39m \n\u001b[32m   2070\u001b[39m     value = array_ops.expand_dims(value, spatial_start_dim)\n\u001b[32m   2071\u001b[39m     filters = array_ops.expand_dims(filters, \u001b[32m0\u001b[39m)\n\u001b[32m   2072\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m value.shape.ndims \u001b[38;5;28;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2073\u001b[39m       result = gen_nn_ops.conv2d(\n\u001b[32m   2074\u001b[39m           value,\n\u001b[32m   2075\u001b[39m           filters,\n\u001b[32m   2076\u001b[39m           strides,\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[39m\n\u001b[32m   1338\u001b[39m         \u001b[33m\"dilations\"\u001b[39m, dilations)\n\u001b[32m   1339\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1341\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m1342\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   1343\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1344\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1345\u001b[39m       return conv2d_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% Step 11 - Gradient-based saliency scores (for your unseen trial segments)\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Your electrode list (must match channel order in X_test_norm)\n",
    "electrode_names = [\n",
    "    'Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2',\n",
    "    'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', 'AFz',\n",
    "    'F1', 'F5', 'FT7', 'FC3', 'C1', 'C5', 'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'P6', 'P2',\n",
    "    'CPz', 'CP4', 'TP8', 'C6', 'C2', 'FC4', 'FT8', 'F6', 'AF8', 'AF4', 'F2', 'F9', 'AFF1h', 'FFC1h', 'FFC5h', 'FTT7h',\n",
    "    'FCC3h', 'CCP1h', 'CCP5h', 'TPP7h', 'P9', 'PPO9h', 'PO9', 'O9', 'OI1h', 'PPO1h', 'CPP3h', 'CPP4h', 'PPO2h', 'OI2h',\n",
    "    'O10', 'PO10', 'PPO10h', 'P10', 'TPP8h', 'CCP6h', 'CCP2h', 'FCC4h', 'FTT8h', 'FFC6h', 'FFC2h', 'AFF2h', 'F10',\n",
    "    'AFp1', 'AFF5h', 'FFT9h', 'FFT7h', 'FFC3h', 'FCC1h', 'FCC5h', 'FTT9h', 'TTP7h', 'CCP3h', 'CPP1h', 'CPP5h', 'TPP9h',\n",
    "    'POO9h', 'PPO5h', 'POO1', 'POO2', 'PPO6h', 'POO10h', 'TPP10h', 'CPP6h', 'CPP2h', 'CCP4h', 'TTP8h', 'FTT10h',\n",
    "    'FCC6h', 'FCC2h', 'FFC4h', 'FFT8h', 'FFT10h', 'AFF6h', 'AFp2'\n",
    "]\n",
    "\n",
    "# --- Safety check: electrode count must match your data channel count ---\n",
    "n_channels_data = X_test_norm.shape[1]\n",
    "if len(electrode_names) != n_channels_data:\n",
    "    print(f\"⚠️ Electrode list length = {len(electrode_names)} but X_test_norm has {n_channels_data} channels.\")\n",
    "    # Fallback: auto-generate names to avoid crashing (or trim if electrode list is longer)\n",
    "    if len(electrode_names) > n_channels_data:\n",
    "        electrode_names = electrode_names[:n_channels_data]\n",
    "        print(f\"✅ Trimmed electrode list to {n_channels_data}.\")\n",
    "    else:\n",
    "        electrode_names = [f\"EEG{i+1}\" for i in range(n_channels_data)]\n",
    "        print(f\"✅ Using auto-generated names EEG1..EEG{n_channels_data}.\")\n",
    "\n",
    "def compute_electrode_saliency(model, input_sample, class_index=1):\n",
    "    \"\"\"\n",
    "    Compute per-electrode saliency for ONE sample shaped like (1, C, T, 1).\n",
    "    Works for sigmoid (1 output) or softmax (>=2 outputs).\n",
    "    \"\"\"\n",
    "    input_sample = tf.convert_to_tensor(input_sample, dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_sample)\n",
    "        pred = model(input_sample, training=False)\n",
    "\n",
    "        # Make a scalar target to differentiate\n",
    "        if pred.shape[-1] == 1:\n",
    "            target = pred[:, 0]                          # sigmoid probability\n",
    "        else:\n",
    "            target = pred[:, class_index]                # softmax probability for class_index\n",
    "\n",
    "    grads = tape.gradient(target, input_sample)          # same shape as input_sample\n",
    "    grads = tf.abs(grads)\n",
    "\n",
    "    # Average over time and \"channel dimension\" (the last dim=1) -> keep electrodes\n",
    "    # input shape: (1, C, T, 1) => reduce over T and last dim\n",
    "    saliency = tf.reduce_mean(grads, axis=(2, 3))        # -> (1, C)\n",
    "    return saliency.numpy().flatten()\n",
    "\n",
    "# Compute saliency for each segment in your unseen trial\n",
    "all_saliencies = []\n",
    "for i in tqdm(range(X_test_norm.shape[0]), desc=\"Computing Saliency (segments)\"):\n",
    "    sample = X_test_norm[i:i+1]                          # (1, C, T, 1)\n",
    "    sal = compute_electrode_saliency(model, sample, class_index=1)\n",
    "    all_saliencies.append(sal)\n",
    "\n",
    "all_saliencies = np.array(all_saliencies, dtype=np.float32)   # (n_segments, C)\n",
    "\n",
    "# Aggregate across segments\n",
    "mean_saliency = np.mean(all_saliencies, axis=0)               # (C,)\n",
    "normalized_saliency = mean_saliency / (np.max(mean_saliency) + 1e-8)\n",
    "\n",
    "# Save CSV\n",
    "saliency_df = pd.DataFrame({\n",
    "    \"Electrode\": electrode_names,\n",
    "    \"Saliency Score\": normalized_saliency\n",
    "})\n",
    "\n",
    "out_csv = \"gradient_saliency_scores_last_excluded_ad_positive_trial.csv\"\n",
    "saliency_df.to_csv(out_csv, index=False)\n",
    "print(f\"✅ Saved gradient-based saliency scores to '{out_csv}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081642ef-8230-4e7e-9944-7ab06b9a7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [NEW CELL] Clear topomap: BIG dots + labels with leader lines (robust for your channel set)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "# -------- 1) Load values --------\n",
    "if \"normalized_saliency\" in globals() and \"electrode_names\" in globals():\n",
    "    ch_names_orig = list(electrode_names)\n",
    "    values_orig = np.asarray(normalized_saliency, dtype=float)\n",
    "else:\n",
    "    # Change filename if needed\n",
    "    df = pd.read_csv(\"70th_gradient_saliency_scores.csv\")\n",
    "    ch_names_orig = df[\"Electrode\"].astype(str).tolist()\n",
    "    values_orig = df[\"Saliency Score\"].to_numpy(dtype=float)\n",
    "\n",
    "# -------- 2) Build mapping to montage channel names --------\n",
    "# Many high-density names end with \"h\" (e.g., AFF1h). Standard montages often store them without \"h\".\n",
    "def montage_lookup_name(name: str) -> str:\n",
    "    n = name.strip()\n",
    "    if n.endswith(\"h\") and len(n) > 1:\n",
    "        return n[:-1]  # AFF1h -> AFF1\n",
    "    return n\n",
    "\n",
    "ch_names_lookup = [montage_lookup_name(n) for n in ch_names_orig]\n",
    "\n",
    "# -------- 3) Create info & set a montage with custom positions --------\n",
    "# Use standard_1005 for broader coverage than standard_1020\n",
    "base_montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "base_pos = base_montage.get_positions()[\"ch_pos\"]  # dict: {name: xyz}\n",
    "\n",
    "# Create a custom position dict for *your original* channel names\n",
    "# by borrowing xyz from the lookup name if available.\n",
    "ch_pos_custom = {}\n",
    "keep_idx = []\n",
    "for i, (orig, look) in enumerate(zip(ch_names_orig, ch_names_lookup)):\n",
    "    if look in base_pos:\n",
    "        ch_pos_custom[orig] = base_pos[look]\n",
    "        keep_idx.append(i)\n",
    "\n",
    "if len(keep_idx) == 0:\n",
    "    raise RuntimeError(\n",
    "        \"No channels matched the montage. Try a different montage (e.g., 'biosemi160') \"\n",
    "        \"or provide a custom electrode position file.\"\n",
    "    )\n",
    "\n",
    "# Keep only channels we can place\n",
    "ch_names = [ch_names_orig[i] for i in keep_idx]\n",
    "values = values_orig[keep_idx]\n",
    "\n",
    "# Create info and apply custom dig montage\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=1000.0, ch_types=\"eeg\")\n",
    "custom_montage = mne.channels.make_dig_montage(ch_pos=ch_pos_custom, coord_frame=\"head\")\n",
    "info.set_montage(custom_montage, on_missing=\"ignore\")\n",
    "\n",
    "# -------- 4) Compute 2D topomap coordinates (only valid channels exist here) --------\n",
    "coords2d = mne.channels.layout._find_topomap_coords(info, picks=np.arange(len(ch_names)))\n",
    "\n",
    "# -------- 5) Plot BIG + crisp --------\n",
    "fig, ax = plt.subplots(figsize=(14, 9), dpi=250)\n",
    "\n",
    "vmin, vmax = float(values.min()), float(values.max())  # or set fixed range manually\n",
    "\n",
    "im, cn = mne.viz.plot_topomap(\n",
    "    values,\n",
    "    info,\n",
    "    axes=ax,\n",
    "    show=False,\n",
    "    contours=6,\n",
    "    sensors=False,      # draw our own dots\n",
    "    outlines=\"head\",\n",
    "    vlim=(vmin, vmax),\n",
    "    cmap=\"jet\",\n",
    ")\n",
    "\n",
    "# -------- 6) Draw big dots + labels with outward leader lines --------\n",
    "dot_size = 18\n",
    "font_size = 13\n",
    "arrow_lw = 0.9\n",
    "\n",
    "for (x, y), name in zip(coords2d, ch_names):\n",
    "    # big dot\n",
    "    ax.plot(x, y, \"k.\", markersize=dot_size, zorder=10)\n",
    "\n",
    "    # radial outward label placement\n",
    "    r = np.sqrt(x * x + y * y) + 1e-9\n",
    "    ux, uy = x / r, y / r  # outward unit vector\n",
    "\n",
    "    # base offset outward + a tiny vertical lift to reduce overlap\n",
    "    offset_out = 0.085\n",
    "    offset_lift = 0.015\n",
    "\n",
    "    x_text = x + ux * offset_out\n",
    "    y_text = y + uy * offset_out + (offset_lift if y >= 0 else -offset_lift)\n",
    "\n",
    "    ax.annotate(\n",
    "        name,\n",
    "        xy=(x, y),\n",
    "        xytext=(x_text, y_text),\n",
    "        textcoords=\"data\",\n",
    "        fontsize=font_size,\n",
    "        fontweight=\"bold\",\n",
    "        ha=\"left\" if x_text >= x else \"right\",\n",
    "        va=\"center\",\n",
    "        bbox=dict(facecolor=\"white\", edgecolor=\"black\", alpha=0.88, pad=0.25),\n",
    "        arrowprops=dict(arrowstyle=\"-\", color=\"black\", lw=arrow_lw),\n",
    "        zorder=11,\n",
    "    )\n",
    "\n",
    "# -------- 7) Colorbar + title --------\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label(\"Electrode importance\", fontsize=14)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "missing = len(ch_names_orig) - len(ch_names)\n",
    "ax.set_title(\n",
    "    f\"Topographic map of electrode importance (clear labels)\\n\"\n",
    "    f\"Plotted {len(ch_names)} channels (skipped {missing} without montage positions)\",\n",
    "    fontsize=18,\n",
    ")\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a464ca7-fd1a-4302-a313-134d4d7fcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELL 9B — Calculate Average Probability (Production-Style)\n",
    "\n",
    "\"\"\"\n",
    "This matches the production code calculation:\n",
    "1. Get sigmoid probabilities per segment\n",
    "2. Average across all segments\n",
    "3. Determine class and confidence\n",
    "\"\"\"\n",
    "\n",
    "# Get raw probabilities (already computed in Cell 9)\n",
    "# y_probs is shape (n_segments, 1) - sigmoid output per segment\n",
    "\n",
    "# Calculate average probability across all segments\n",
    "avg_probability = float(np.mean(y_probs))\n",
    "\n",
    "# Determine predicted class using 0.5 threshold\n",
    "predicted_class = \"positive\" if avg_probability >= 0.5 else \"negative\"\n",
    "\n",
    "# Calculate confidence (production logic)\n",
    "if avg_probability >= 0.5:\n",
    "    confidence = avg_probability\n",
    "else:\n",
    "    confidence = 1.0 - avg_probability\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"PRODUCTION-STYLE PROBABILITY CALCULATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total segments analyzed: {len(y_probs)}\")\n",
    "print(f\"Average sigmoid probability: {avg_probability:.6f}\")\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Confidence: {confidence:.3f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Breakdown statistics\n",
    "print(\"\\nSegment Probability Statistics:\")\n",
    "print(f\"  Min probability: {y_probs.min():.6f}\")\n",
    "print(f\"  Max probability: {y_probs.max():.6f}\")\n",
    "print(f\"  Median probability: {np.median(y_probs):.6f}\")\n",
    "print(f\"  Std dev: {y_probs.std():.6f}\")\n",
    "\n",
    "# Distribution of predictions\n",
    "num_positive_segments = (y_probs >= 0.5).sum()\n",
    "num_negative_segments = (y_probs < 0.5).sum()\n",
    "print(f\"\\nSegment-level predictions:\")\n",
    "print(f\"  Positive segments: {num_positive_segments} ({100*num_positive_segments/len(y_probs):.1f}%)\")\n",
    "print(f\"  Negative segments: {num_negative_segments} ({100*num_negative_segments/len(y_probs):.1f}%)\")\n",
    "\n",
    "# Expected output format (matches production)\n",
    "output_json = {\n",
    "    \"status\": predicted_class,\n",
    "    \"confidence\": round(confidence, 3),\n",
    "    \"probability\": round(avg_probability, 3),\n",
    "    \"metadata\": {\n",
    "        \"total_segments\": len(y_probs),\n",
    "        \"positive_segments\": int(num_positive_segments),\n",
    "        \"negative_segments\": int(num_negative_segments),\n",
    "        \"ground_truth\": \"positive\" if y_test_trial == 1 else \"negative\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRODUCTION OUTPUT FORMAT:\")\n",
    "print(\"=\"*60)\n",
    "import json\n",
    "print(json.dumps(output_json, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03be33e-0842-4f11-9342-e61778523f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
