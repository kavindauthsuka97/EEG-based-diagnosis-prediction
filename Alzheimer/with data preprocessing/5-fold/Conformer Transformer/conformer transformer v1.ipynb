{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cell 1 — Install packages"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages (run once)\n",
        "%pip install -q mne PyWavelets scikit-learn seaborn imbalanced-learn\n",
        "%pip install -q azureml-core azure-ai-ml azure-identity\n",
        "\n",
        "print(\"✅ Packages installed (if no errors above).\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Note: you may need to restart the kernel to use updated packages.\nNote: you may need to restart the kernel to use updated packages.\n✅ Packages installed (if no errors above).\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1768731715479
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 2 — Load libraries + set seeds"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic utilities\n",
        "import os  # file ops\n",
        "import random  # RNG\n",
        "\n",
        "# Arrays\n",
        "import numpy as np  # numpy arrays\n",
        "\n",
        "# EEG processing\n",
        "import mne  # EEG processing\n",
        "import pywt  # wavelets\n",
        "\n",
        "# ML tools\n",
        "from sklearn.decomposition import FastICA  # ICA\n",
        "from sklearn.model_selection import StratifiedKFold  # CV\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score  # metrics\n",
        "\n",
        "# Balancing\n",
        "from imblearn.over_sampling import SMOTE, RandomOverSampler  # SMOTE and fallback\n",
        "\n",
        "# Helpers\n",
        "from collections import defaultdict  # grouping\n",
        "from typing import Optional, Union, Sequence, Dict, Tuple, List  # typing\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt  # plotting\n",
        "import seaborn as sns  # heatmaps\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf  # TF\n",
        "from tensorflow import keras  # keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger  # callbacks\n",
        "\n",
        "# Try enabling interactive logs (optional)\n",
        "try:\n",
        "    tf.keras.utils.enable_interactive_logging()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Set seeds\n",
        "random.seed(42)\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "print(\"✅ Imports done + seeds set.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2026-01-18 10:22:19.174495: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2026-01-18 10:22:19.474688: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768731739.575114    3146 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768731739.601478    3146 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768731739.844713    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768731739.844751    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768731739.844753    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768731739.844755    3146 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n2026-01-18 10:22:19.876033: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\nTo enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Imports done + seeds set.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1768731747742
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 3 — Azure download + load AD arrays + build labels"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure ML workspace tools\n",
        "from azureml.core import Workspace, Datastore, Dataset\n",
        "\n",
        "print(\"[STEP 1] Connecting to Azure ML workspace...\")\n",
        "\n",
        "# Workspace details (given)\n",
        "subscription_id = \"eccc04ba-d8b0-4f70-864a-b4a6753bfc72\"\n",
        "resource_group  = \"somnasnest\"\n",
        "workspace_name  = \"SomnasNest\"\n",
        "\n",
        "# Folder path in datastore (given)\n",
        "folder_path = \"UI/2026-01-17_162622_UTC/Data Array/\"\n",
        "\n",
        "# Connect to workspace\n",
        "ws = Workspace.get(\n",
        "    name=workspace_name,\n",
        "    subscription_id=subscription_id,\n",
        "    resource_group=resource_group\n",
        ")\n",
        "\n",
        "print(\"[STEP 1] Workspace connected ✅\")\n",
        "\n",
        "# Get default datastore (workspaceblobstore)\n",
        "datastore = ws.get_default_datastore()\n",
        "print(\"[STEP 1] Default datastore loaded ✅\")\n",
        "\n",
        "# Build FileDataset from folder\n",
        "ds = Dataset.File.from_files(path=(datastore, folder_path))\n",
        "print(\"[STEP 1] FileDataset created ✅\")\n",
        "\n",
        "# Download locally\n",
        "local_dir = \"./_ad_data_array\"\n",
        "os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "print(f\"[STEP 1] Downloading data to: {local_dir} ...\")\n",
        "ds.download(target_path=local_dir, overwrite=True)\n",
        "print(\"[STEP 1] Download complete ✅\")\n",
        "\n",
        "# Load arrays\n",
        "arrays = {}  # store loaded arrays\n",
        "\n",
        "print(\"[STEP 1] Loading .npy files...\")\n",
        "for root, _, files in os.walk(local_dir):\n",
        "    for f in files:\n",
        "        p = os.path.join(root, f)\n",
        "        if f.lower().endswith(\".npy\"):\n",
        "            arrays[f] = np.load(p, allow_pickle=False)\n",
        "\n",
        "# Safety check\n",
        "if \"ad_negative.npy\" not in arrays or \"ad_positive.npy\" not in arrays:\n",
        "    raise FileNotFoundError(\"❌ Could not find ad_negative.npy and ad_positive.npy in downloaded folder.\")\n",
        "\n",
        "# Extract arrays\n",
        "X_neg = arrays[\"ad_negative.npy\"].astype(np.float32)  # (31,127,150000)\n",
        "X_pos = arrays[\"ad_positive.npy\"].astype(np.float32)  # (46,127,150000)\n",
        "\n",
        "print(\"✅ Arrays loaded:\")\n",
        "print(\"  ad_negative.npy:\", X_neg.shape, X_neg.dtype)\n",
        "print(\"  ad_positive.npy:\", X_pos.shape, X_pos.dtype)\n",
        "\n",
        "# Build labels\n",
        "y_neg = np.zeros((X_neg.shape[0],), dtype=np.int32)  # label 0\n",
        "y_pos = np.ones((X_pos.shape[0],), dtype=np.int32)   # label 1\n",
        "\n",
        "# Combine into one dataset\n",
        "X_all_trials = np.concatenate([X_neg, X_pos], axis=0)  # (77,127,150000)\n",
        "y_all_trials = np.concatenate([y_neg, y_pos], axis=0)  # (77,)\n",
        "\n",
        "print(\"[STEP 1] Combined dataset:\")\n",
        "print(\"  X_all_trials:\", X_all_trials.shape)\n",
        "print(\"  y_all_trials:\", y_all_trials.shape)\n",
        "print(\"  Class counts:\", np.unique(y_all_trials, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 1] Connecting to Azure ML workspace...\n[STEP 1] Workspace connected ✅\n[STEP 1] Default datastore loaded ✅\n[STEP 1] FileDataset created ✅\n[STEP 1] Downloading data to: ./_ad_data_array ...\n{'infer_column_types': 'False', 'activity': 'download'}\n{'infer_column_types': 'False', 'activity': 'download', 'activityApp': 'FileDataset'}\n[STEP 1] Download complete ✅\n[STEP 1] Loading .npy files...\n✅ Arrays loaded:\n  ad_negative.npy: (31, 127, 150000) float32\n  ad_positive.npy: (46, 127, 150000) float32\n[STEP 1] Combined dataset:\n  X_all_trials: (77, 127, 150000)\n  y_all_trials: (77,)\n  Class counts: (array([0, 1], dtype=int32), array([31, 46]))\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\nOverriding of current TracerProvider is not allowed\nOverriding of current LoggerProvider is not allowed\nOverriding of current MeterProvider is not allowed\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\nAttempting to instrument while already instrumented\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1768731837545
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 4 — Helper + leakage-safe preprocessing classes"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper: map channel names\n",
        "def _names_from_index_mapping(n_channels, index_to_name):\n",
        "    if index_to_name is None:\n",
        "        return [f\"EEG{i+1}\" for i in range(n_channels)]\n",
        "    keys = list(index_to_name.keys())\n",
        "    is_zero_based = (0 in keys) and (1 not in keys)\n",
        "    names = []\n",
        "    for i in range(n_channels):\n",
        "        key = i if is_zero_based else (i + 1)\n",
        "        names.append(index_to_name.get(key, f\"EEG{i+1}\"))\n",
        "    return names\n",
        "\n",
        "# Helper: make MNE Raw\n",
        "def _make_raw(eeg, sfreq, ch_names, use_standard_1020=True):\n",
        "    ch_types = ['eog' if str(n).upper().startswith(\"EOG\") else 'eeg' for n in ch_names]\n",
        "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=ch_types)\n",
        "    raw = mne.io.RawArray(eeg.astype(np.float32, copy=False), info, verbose=False)\n",
        "\n",
        "    montage_applied = False\n",
        "    if use_standard_1020:\n",
        "        try:\n",
        "            mont = mne.channels.make_standard_montage(\"standard_1020\")\n",
        "            raw.set_montage(mont, match_case=False, on_missing=\"ignore\")\n",
        "            montage_applied = True\n",
        "        except Exception:\n",
        "            montage_applied = False\n",
        "\n",
        "    return raw, montage_applied\n",
        "\n",
        "# Wavelet ICA\n",
        "class WaveletICA:\n",
        "    def __init__(self, wavelet=\"db4\", level=3, n_components=10, random_state=42):\n",
        "        self.wavelet = wavelet\n",
        "        self.level = level\n",
        "        self.n_components = n_components\n",
        "        self.random_state = random_state\n",
        "        self.ica_ = None\n",
        "        self._n_ch = None\n",
        "\n",
        "    def fit(self, X):\n",
        "        C = X.shape[0]\n",
        "        self._n_ch = C\n",
        "        coeffs = pywt.wavedec(X, wavelet=self.wavelet, level=self.level, axis=1)\n",
        "        A = coeffs[0]\n",
        "        k = int(min(self.n_components, C))\n",
        "        self.ica_ = FastICA(n_components=k, random_state=self.random_state)\n",
        "        S = self.ica_.fit_transform(A.T)\n",
        "        A_denoised = self.ica_.inverse_transform(S).T\n",
        "        coeffs[0] = A_denoised\n",
        "        _ = pywt.waverec(coeffs, wavelet=self.wavelet, axis=1)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        assert self.ica_ is not None, \"WaveletICA not fitted yet.\"\n",
        "        coeffs = pywt.wavedec(X, wavelet=self.wavelet, level=self.level, axis=1)\n",
        "        A = coeffs[0]\n",
        "        S = self.ica_.transform(A.T)\n",
        "        A_denoised = self.ica_.inverse_transform(S).T\n",
        "        coeffs[0] = A_denoised\n",
        "        Y = pywt.waverec(coeffs, wavelet=self.wavelet, axis=1)\n",
        "\n",
        "        if Y.shape[1] < X.shape[1]:\n",
        "            Y = np.pad(Y, ((0, 0), (0, X.shape[1] - Y.shape[1])), mode=\"constant\")\n",
        "        elif Y.shape[1] > X.shape[1]:\n",
        "            Y = Y[:, :X.shape[1]]\n",
        "\n",
        "        return Y.astype(np.float32, copy=False)\n",
        "\n",
        "# Leakage-safe preprocessor (same as your sleep deprivation pipeline)\n",
        "class EEGPreprocessor:\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        index_to_name=None,\n",
        "        use_standard_1020=True,\n",
        "        resample_to=None,\n",
        "        notch_freqs=50.0,\n",
        "        highpass=0.05,\n",
        "        bad_point_z=6.0,\n",
        "        bad_channel_z=5.0,\n",
        "        interpolate_bad_channels=False,\n",
        "        car=True,\n",
        "        use_wica=True,\n",
        "        wica_components=10,\n",
        "        wica_wavelet=\"db4\",\n",
        "        wica_level=3,\n",
        "        wica_random_state=42\n",
        "    ):\n",
        "        self.index_to_name = index_to_name\n",
        "        self.use_standard_1020 = use_standard_1020\n",
        "        self.resample_to = resample_to\n",
        "        self.notch_freqs = notch_freqs\n",
        "        self.highpass = highpass\n",
        "        self.bad_point_z = bad_point_z\n",
        "        self.bad_channel_z = bad_channel_z\n",
        "        self.interpolate_bad_channels = interpolate_bad_channels\n",
        "        self.car = car\n",
        "        self.use_wica = use_wica\n",
        "\n",
        "        self._sfreq_out = None\n",
        "        self._train_mu = None\n",
        "        self._train_sd = None\n",
        "        self._robust_med = None\n",
        "        self._robust_mad = None\n",
        "        self._train_eeg_names = None\n",
        "\n",
        "        self._wica = WaveletICA(\n",
        "            wavelet=wica_wavelet,\n",
        "            level=wica_level,\n",
        "            n_components=wica_components,\n",
        "            random_state=wica_random_state\n",
        "        )\n",
        "\n",
        "    @property\n",
        "    def sfreq_out(self):\n",
        "        assert self._sfreq_out is not None, \"Preprocessor not run yet.\"\n",
        "        return float(self._sfreq_out)\n",
        "\n",
        "    def _filter_and_reference(self, raw):\n",
        "        if self.resample_to is not None and float(self.resample_to) != float(raw.info[\"sfreq\"]):\n",
        "            raw.resample(self.resample_to, npad=\"auto\")\n",
        "        self._sfreq_out = float(raw.info[\"sfreq\"])\n",
        "\n",
        "        if self.notch_freqs is not None:\n",
        "            raw.notch_filter(freqs=self.notch_freqs, verbose=False)\n",
        "\n",
        "        if self.highpass is not None:\n",
        "            raw.filter(l_freq=self.highpass, h_freq=None, verbose=False)\n",
        "\n",
        "        if self.car:\n",
        "            raw.set_eeg_reference(\"average\", projection=True)\n",
        "            raw.apply_proj()\n",
        "\n",
        "    def _repair_transients_with_train_stats(self, raw):\n",
        "        X = raw.get_data()\n",
        "        mu = self._train_mu\n",
        "        sd = self._train_sd\n",
        "        assert mu is not None and sd is not None, \"Training stats not set.\"\n",
        "\n",
        "        hi = mu + self.bad_point_z * sd\n",
        "        lo = mu - self.bad_point_z * sd\n",
        "        mask = (X > hi) | (X < lo)\n",
        "\n",
        "        if np.any(mask):\n",
        "            X_fixed = X.copy()\n",
        "            t = np.arange(X.shape[1], dtype=float)\n",
        "            for ch in range(X.shape[0]):\n",
        "                m = mask[ch]\n",
        "                if m.any():\n",
        "                    good = ~m\n",
        "                    if good.sum() >= 2:\n",
        "                        X_fixed[ch, m] = np.interp(t[m], t[good], X_fixed[ch, good])\n",
        "            raw._data = X_fixed\n",
        "\n",
        "    def fit(self, X_train, sfreq):\n",
        "        C = X_train.shape[0]\n",
        "        ch_names = _names_from_index_mapping(C, self.index_to_name)\n",
        "\n",
        "        raw_train, montage_applied = _make_raw(X_train, sfreq, ch_names, self.use_standard_1020)\n",
        "        self._filter_and_reference(raw_train)\n",
        "\n",
        "        Xt = raw_train.get_data()\n",
        "        self._train_mu = Xt.mean(axis=1, keepdims=True)\n",
        "        self._train_sd = Xt.std(axis=1, keepdims=True) + 1e-12\n",
        "\n",
        "        if self.use_wica:\n",
        "            self._wica.fit(Xt)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, sfreq):\n",
        "        C = X.shape[0]\n",
        "        ch_names = _names_from_index_mapping(C, self.index_to_name)\n",
        "\n",
        "        raw, _ = _make_raw(X, sfreq, ch_names, self.use_standard_1020)\n",
        "        self._filter_and_reference(raw)\n",
        "        self._repair_transients_with_train_stats(raw)\n",
        "\n",
        "        Xf = raw.get_data()\n",
        "        if self.use_wica:\n",
        "            Xf = self._wica.transform(Xf)\n",
        "\n",
        "        return Xf.astype(np.float32, copy=False), self.sfreq_out\n",
        "\n",
        "    def fit_transform(self, X_train, sfreq):\n",
        "        self.fit(X_train, sfreq)\n",
        "        X_clean, fs_out = self.transform(X_train, sfreq)\n",
        "        return X_clean, fs_out\n",
        "\n",
        "print(\"✅ Preprocessing classes loaded.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "✅ Preprocessing classes loaded.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1768731895096
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 5 — Set sampling frequency + Preprocess all trials"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 2] Starting preprocessing...\")\n",
        "\n",
        "# IMPORTANT:\n",
        "# Your data arrays do not include fs inside the .npy files.\n",
        "# If you already know the sampling rate, set it here.\n",
        "# If not, use the correct value from your dataset documentation.\n",
        "fs = 1000.0  # <-- CHANGE THIS if your dataset uses a different sampling rate\n",
        "\n",
        "print(f\"[STEP 2] Using fs={fs} Hz\")\n",
        "\n",
        "CHANNEL_MAP = None  # keep same as before\n",
        "\n",
        "# Create preprocessor (same settings)\n",
        "pre = EEGPreprocessor(\n",
        "    index_to_name=CHANNEL_MAP,\n",
        "    use_standard_1020=True,\n",
        "    resample_to=None,\n",
        "    notch_freqs=[50.0, 100.0, 150.0],\n",
        "    highpass=0.05,\n",
        "    bad_point_z=6.0,\n",
        "    bad_channel_z=5.0,\n",
        "    interpolate_bad_channels=False,\n",
        "    car=True,\n",
        "    use_wica=True,\n",
        "    wica_components=10,\n",
        "    wica_wavelet=\"db4\",\n",
        "    wica_level=3,\n",
        "    wica_random_state=42\n",
        ")\n",
        "\n",
        "# Fit preprocessor on a subset (like before)\n",
        "max_calib_trials = min(10, X_all_trials.shape[0])\n",
        "print(f\"[STEP 2] Fitting preprocessor on first {max_calib_trials} trials...\")\n",
        "\n",
        "calib_trials = X_all_trials[:max_calib_trials]  # take first few\n",
        "X_calib = np.concatenate(calib_trials, axis=1).astype(np.float32, copy=False)  # concat time\n",
        "\n",
        "X_calib_clean, fs_out = pre.fit_transform(X_calib, fs)\n",
        "print(f\"[STEP 2] Preprocessor fitted ✅ | fs_out={fs_out} Hz\")\n",
        "\n",
        "# Apply to all trials\n",
        "data_clean = []\n",
        "for i in range(X_all_trials.shape[0]):\n",
        "    X_clean, _ = pre.transform(X_all_trials[i], fs)\n",
        "    data_clean.append(X_clean.astype(np.float32, copy=False))\n",
        "    if (i + 1) % 5 == 0:\n",
        "        print(f\"[STEP 2] Preprocessed {i+1}/{X_all_trials.shape[0]} trials...\")\n",
        "\n",
        "data_clean = np.array(data_clean, dtype=np.float32)\n",
        "\n",
        "print(\"[STEP 2] Done preprocessing ✅\")\n",
        "print(\"  data_clean shape:\", data_clean.shape)\n",
        "print(\"  labels shape    :\", y_all_trials.shape)\n",
        "print(\"  class counts    :\", np.unique(y_all_trials, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 2] Starting preprocessing...\n[STEP 2] Using fs=1000.0 Hz\n[STEP 2] Fitting preprocessor on first 10 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessor fitted ✅ | fs_out=1000.0 Hz\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 5/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 10/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 15/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 20/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 25/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 30/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 35/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 40/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 45/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 50/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 55/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 60/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 65/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 70/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Preprocessed 75/77 trials...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\nEEG channel type selected for re-referencing\nAdding average EEG reference projection.\n1 projection items deactivated\nAverage reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\nCreated an SSP operator (subspace dimension = 1)\n1 projection items activated\nSSP projectors applied...\n[STEP 2] Done preprocessing ✅\n  data_clean shape: (77, 127, 150000)\n  labels shape    : (77,)\n  class counts    : (array([0, 1], dtype=int32), array([31, 46]))\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1768732296609
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 6 — Augmentation"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 3] Starting augmentation (segmentation)...\")\n",
        "\n",
        "def augment_data(trial_data, label, segment_size=100):\n",
        "    segments = []\n",
        "    labels = []\n",
        "    n_segments = trial_data.shape[1] // segment_size\n",
        "\n",
        "    for i in range(n_segments):\n",
        "        seg = trial_data[:, i*segment_size:(i+1)*segment_size]\n",
        "        segments.append(seg.astype(np.float32, copy=False))\n",
        "        labels.append(int(label))\n",
        "\n",
        "    return segments, labels\n",
        "\n",
        "augmented = []\n",
        "aug_targets = []\n",
        "\n",
        "for trial, y in zip(data_clean, y_all_trials):\n",
        "    segs, ys = augment_data(trial, y, segment_size=100)\n",
        "    augmented.extend(segs)\n",
        "    aug_targets.extend(ys)\n",
        "\n",
        "augmented = np.array(augmented, dtype=np.float32)  # (N,127,100)\n",
        "aug_targets = np.array(aug_targets, dtype=np.int32)\n",
        "\n",
        "print(\"[STEP 3] Augmentation done ✅\")\n",
        "print(\"  augmented shape:\", augmented.shape)\n",
        "print(\"  aug_targets shape:\", aug_targets.shape)\n",
        "print(\"  class counts:\", np.unique(aug_targets, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 3] Starting augmentation (segmentation)...\n[STEP 3] Augmentation done ✅\n  augmented shape: (115500, 127, 100)\n  aug_targets shape: (115500,)\n  class counts: (array([0, 1], dtype=int32), array([46500, 69000]))\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1768732337218
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 7 — “Fair selection”"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 4] Fair selection step...\")\n",
        "\n",
        "# Group by class (no subject IDs exist in this array dataset)\n",
        "class_data = {0: [], 1: []}\n",
        "\n",
        "for x, y in zip(augmented, aug_targets):\n",
        "    class_data[int(y)].append(x)\n",
        "\n",
        "max_per_class = 20000  # adjust if needed\n",
        "\n",
        "selected_data = []\n",
        "selected_targets = []\n",
        "\n",
        "for cls in [0, 1]:\n",
        "    picked = class_data[cls][:max_per_class]\n",
        "    selected_data.extend(picked)\n",
        "    selected_targets.extend([cls] * len(picked))\n",
        "\n",
        "selected_data = np.array(selected_data, dtype=np.float32)\n",
        "selected_targets = np.array(selected_targets, dtype=np.int32)\n",
        "\n",
        "print(\"[STEP 4] Selection done ✅\")\n",
        "print(\"  selected_data shape:\", selected_data.shape)\n",
        "print(\"  selected_targets shape:\", selected_targets.shape)\n",
        "print(\"  class counts:\", np.unique(selected_targets, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 4] Fair selection step...\n[STEP 4] Selection done ✅\n  selected_data shape: (40000, 127, 100)\n  selected_targets shape: (40000,)\n  class counts: (array([0, 1], dtype=int32), array([20000, 20000]))\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1768732368358
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 8 — Reshape for Conformer input"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 5] Reshaping data for Conformer...\")\n",
        "\n",
        "# (N, C, T) -> (N, C, T, 1)\n",
        "X_all = selected_data[..., np.newaxis].astype(np.float32, copy=False)\n",
        "y_all = selected_targets.astype(np.int32, copy=False)\n",
        "\n",
        "print(\"[STEP 5] Done ✅\")\n",
        "print(\"  X_all shape:\", X_all.shape)\n",
        "print(\"  y_all shape:\", y_all.shape)\n",
        "print(\"  class counts:\", np.unique(y_all, return_counts=True))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 5] Reshaping data for Conformer...\n[STEP 5] Done ✅\n  X_all shape: (40000, 127, 100, 1)\n  y_all shape: (40000,)\n  class counts: (array([0, 1], dtype=int32), array([20000, 20000]))\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1768732404672
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 9 — Conformer model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== Cell 9 — Conformer Model (UNCHANGED ARCHITECTURE) ====================\n",
        "# This is the SAME model architecture you provided.\n",
        "# Only use create_conformer_model(input_shape=(127, 100, 1)) later in training.\n",
        "\n",
        "import tensorflow as tf  # tensorflow ops\n",
        "from tensorflow import keras  # keras base\n",
        "from tensorflow.keras import layers  # keras layers\n",
        "import numpy as np  # numpy arrays\n",
        "\n",
        "print(\"[STEP 9] Loading Conformer model code (unchanged)...\")\n",
        "\n",
        "# ==================== GLU Activation ====================\n",
        "class GLU(layers.Layer):\n",
        "    \"\"\"Gated Linear Unit - splits input in half and applies gating\"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        a, b = tf.split(x, 2, axis=-1)  # split channels into 2 halves\n",
        "        return a * tf.nn.sigmoid(b)  # gate: a * sigmoid(b)\n",
        "\n",
        "# ==================== Depthwise Conv1D ====================\n",
        "class DepthwiseConv1D(layers.Layer):\n",
        "    \"\"\"\n",
        "    Custom Depthwise 1D Convolution using groups.\n",
        "    TF >= 2.4 required for Conv1D(groups=...).\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size, padding='same', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.kernel_size = kernel_size  # kernel size\n",
        "        self.padding = padding  # padding mode\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.channels = input_shape[-1]  # number of channels\n",
        "        self.conv = layers.Conv1D(\n",
        "            filters=self.channels,  # output channels = input channels\n",
        "            kernel_size=self.kernel_size,  # kernel size\n",
        "            padding=self.padding,  # same padding\n",
        "            groups=self.channels,  # depthwise conv\n",
        "            use_bias=False  # no bias\n",
        "        )\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.conv(x)  # apply depthwise conv\n",
        "\n",
        "# ==================== Transformer-XL Relative Multi-Head Attention ====================\n",
        "class TransformerXLMultiHeadAttention(layers.Layer):\n",
        "    \"\"\"\n",
        "    Transformer-XL relative multi-head attention with:\n",
        "    - relative embeddings\n",
        "    - relative shift trick\n",
        "    - content bias u and position bias v\n",
        "    \"\"\"\n",
        "    def __init__(self, d_model, num_heads, dropout_rate=0.1, max_len=5000, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.d_model = d_model  # embedding dim\n",
        "        self.num_heads = num_heads  # num heads\n",
        "        self.dropout_rate = dropout_rate  # dropout\n",
        "        self.max_len = max_len  # max sequence length\n",
        "\n",
        "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
        "        self.depth = d_model // num_heads  # per-head dim\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)  # pre-norm\n",
        "\n",
        "        # Q, K, V projections\n",
        "        self.wq = layers.Dense(self.d_model, use_bias=False)\n",
        "        self.wk = layers.Dense(self.d_model, use_bias=False)\n",
        "        self.wv = layers.Dense(self.d_model, use_bias=False)\n",
        "\n",
        "        # relative projection W_r\n",
        "        self.w_r = layers.Dense(self.d_model, use_bias=False)\n",
        "\n",
        "        # sinusoidal relative position embeddings (2*max_len+1, d_model)\n",
        "        pos = np.arange(-self.max_len, self.max_len + 1, dtype=np.float32)[:, None]\n",
        "        dim = np.arange(self.d_model, dtype=np.float32)[None, :]\n",
        "        angle = pos / (10000 ** (2 * (dim // 2) / self.d_model))\n",
        "        pe = np.where(dim % 2 == 0, np.sin(angle), np.cos(angle)).astype(np.float32)\n",
        "\n",
        "        self.rel_pos_emb = self.add_weight(\n",
        "            name='rel_pos_emb',\n",
        "            shape=(2 * self.max_len + 1, self.d_model),\n",
        "            initializer=keras.initializers.Constant(pe),\n",
        "            trainable=False\n",
        "        )\n",
        "\n",
        "        # biases u and v (per head)\n",
        "        self.u_bias = self.add_weight(\n",
        "            name='u_bias',\n",
        "            shape=(self.num_heads, self.depth),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "        self.v_bias = self.add_weight(\n",
        "            name='v_bias',\n",
        "            shape=(self.num_heads, self.depth),\n",
        "            initializer='zeros',\n",
        "            trainable=True\n",
        "        )\n",
        "\n",
        "        self.dense_out = layers.Dense(self.d_model)  # output projection\n",
        "        self.dropout_attn = layers.Dropout(self.dropout_rate)  # dropout on attn weights\n",
        "        self.dropout_out = layers.Dropout(self.dropout_rate)  # dropout on output\n",
        "\n",
        "    def rel_shift(self, x):\n",
        "        \"\"\"\n",
        "        Relative shift trick.\n",
        "        Input:  (B, H, L, 2L-1)\n",
        "        Output: (B, H, L, L)\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        heads = tf.shape(x)[1]\n",
        "        seq_len = tf.shape(x)[2]\n",
        "\n",
        "        x_padded = tf.pad(x, [[0, 0], [0, 0], [0, 0], [1, 0]])  # pad left\n",
        "        x_padded = tf.reshape(x_padded, [batch_size, heads, 2 * seq_len, seq_len])  # reshape\n",
        "        x_shifted = x_padded[:, :, 1:, :]  # drop first row\n",
        "        x_shifted = tf.reshape(x_shifted, [batch_size, heads, seq_len, 2 * seq_len - 1])  # reshape back\n",
        "        return x_shifted[:, :, :, :seq_len]  # keep first L columns\n",
        "\n",
        "    def call(self, x, mask=None, training=False):\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        # ensure seq_len <= max_len\n",
        "        tf.debugging.assert_less_equal(seq_len, self.max_len, message=\"seq_len too large for max_len\")\n",
        "\n",
        "        x_norm = self.layer_norm(x)  # pre-norm\n",
        "\n",
        "        q = self.wq(x_norm)  # (B, L, D)\n",
        "        k = self.wk(x_norm)  # (B, L, D)\n",
        "        v = self.wv(x_norm)  # (B, L, D)\n",
        "\n",
        "        # reshape to (B, L, H, d)\n",
        "        q = tf.reshape(q, [batch_size, seq_len, self.num_heads, self.depth])\n",
        "        k = tf.reshape(k, [batch_size, seq_len, self.num_heads, self.depth])\n",
        "        v = tf.reshape(v, [batch_size, seq_len, self.num_heads, self.depth])\n",
        "\n",
        "        # transpose to (B, H, L, d)\n",
        "        q = tf.transpose(q, [0, 2, 1, 3])\n",
        "        k = tf.transpose(k, [0, 2, 1, 3])\n",
        "        v = tf.transpose(v, [0, 2, 1, 3])\n",
        "\n",
        "        # relative indices for L -> (2L-1)\n",
        "        r_indices = tf.range(2 * seq_len - 1, dtype=tf.int32)\n",
        "        r_indices_centered = r_indices - (seq_len - 1) + self.max_len\n",
        "        r_emb = tf.gather(self.rel_pos_emb, r_indices_centered)  # (2L-1, D)\n",
        "\n",
        "        # project relative embedding\n",
        "        r = self.w_r(r_emb)  # (2L-1, D)\n",
        "        r = tf.reshape(r, [2 * seq_len - 1, self.num_heads, self.depth])  # (2L-1, H, d)\n",
        "        r = tf.transpose(r, [1, 0, 2])  # (H, 2L-1, d)\n",
        "\n",
        "        # AC = (Q+u)K^T\n",
        "        q_with_u = q + self.u_bias[None, :, None, :]\n",
        "        AC = tf.matmul(q_with_u, k, transpose_b=True)  # (B, H, L, L)\n",
        "\n",
        "        # BD = (Q+v)R^T then rel_shift\n",
        "        q_with_v = q + self.v_bias[None, :, None, :]\n",
        "        BD = tf.einsum('bhld,hrd->bhlr', q_with_v, r)  # (B, H, L, 2L-1)\n",
        "        BD_shifted = self.rel_shift(BD)  # (B, H, L, L)\n",
        "\n",
        "        attn_score = AC + BD_shifted  # combine\n",
        "        attn_score = attn_score / tf.math.sqrt(tf.cast(self.depth, tf.float32))  # scale\n",
        "\n",
        "        # optional mask\n",
        "        if mask is not None:\n",
        "            mask = tf.cast(mask, attn_score.dtype)\n",
        "            attn_score += (1.0 - mask) * -1e9\n",
        "\n",
        "        attn_weights = tf.nn.softmax(attn_score, axis=-1)  # softmax\n",
        "        attn_weights = self.dropout_attn(attn_weights, training=training)  # dropout\n",
        "\n",
        "        attn_output = tf.matmul(attn_weights, v)  # (B, H, L, d)\n",
        "\n",
        "        # concat heads: (B, L, D)\n",
        "        attn_output = tf.transpose(attn_output, [0, 2, 1, 3])\n",
        "        attn_output = tf.reshape(attn_output, [batch_size, seq_len, self.d_model])\n",
        "\n",
        "        output = self.dense_out(attn_output)  # output proj\n",
        "        output = self.dropout_out(output, training=training)  # dropout\n",
        "        return output\n",
        "\n",
        "# ==================== Feed Forward Module ====================\n",
        "class FeedForwardModule(layers.Layer):\n",
        "    \"\"\"FFN with 4x expansion and swish\"\"\"\n",
        "    def __init__(self, d_model, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.d_model = d_model\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)  # pre-norm\n",
        "        self.dense1 = layers.Dense(self.d_model * 4)  # expand 4x\n",
        "        self.swish = layers.Activation('swish')  # swish\n",
        "        self.dropout1 = layers.Dropout(self.dropout_rate)  # dropout\n",
        "        self.dense2 = layers.Dense(self.d_model)  # project back\n",
        "        self.dropout2 = layers.Dropout(self.dropout_rate)  # dropout\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x_norm = self.layer_norm(x)\n",
        "        x = self.dense1(x_norm)\n",
        "        x = self.swish(x)\n",
        "        x = self.dropout1(x, training=training)\n",
        "        x = self.dense2(x)\n",
        "        x = self.dropout2(x, training=training)\n",
        "        return x\n",
        "\n",
        "# ==================== Convolution Module ====================\n",
        "class ConvolutionModule(layers.Layer):\n",
        "    \"\"\"Conv module with GLU + depthwise conv\"\"\"\n",
        "    def __init__(self, d_model, kernel_size=32, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.d_model = d_model\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)  # pre-norm\n",
        "        self.pointwise_conv1 = layers.Conv1D(self.d_model * 2, kernel_size=1)  # expand\n",
        "        self.glu = GLU()  # GLU gate\n",
        "        self.depthwise_conv = DepthwiseConv1D(kernel_size=self.kernel_size, padding='same')  # depthwise\n",
        "        self.batch_norm = layers.BatchNormalization()  # batch norm\n",
        "        self.swish = layers.Activation('swish')  # swish\n",
        "        self.pointwise_conv2 = layers.Conv1D(self.d_model, kernel_size=1)  # project back\n",
        "        self.dropout = layers.Dropout(self.dropout_rate)  # dropout\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x_norm = self.layer_norm(x)\n",
        "        x = self.pointwise_conv1(x_norm)\n",
        "        x = self.glu(x)\n",
        "        x = self.depthwise_conv(x)\n",
        "        x = self.batch_norm(x, training=training)\n",
        "        x = self.swish(x)\n",
        "        x = self.pointwise_conv2(x)\n",
        "        x = self.dropout(x, training=training)\n",
        "        return x\n",
        "\n",
        "# ==================== Conformer Block ====================\n",
        "class ConformerBlock(layers.Layer):\n",
        "    \"\"\"FFN(0.5) -> MHSA -> Conv -> FFN(0.5) -> LN\"\"\"\n",
        "    def __init__(self, d_model, num_heads, kernel_size=32, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.ffn1 = FeedForwardModule(d_model, dropout_rate)\n",
        "        self.mhsa = TransformerXLMultiHeadAttention(d_model, num_heads, dropout_rate)\n",
        "        self.conv = ConvolutionModule(d_model, kernel_size, dropout_rate)\n",
        "        self.ffn2 = FeedForwardModule(d_model, dropout_rate)\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, x, mask=None, training=False):\n",
        "        x = x + 0.5 * self.ffn1(x, training=training)\n",
        "        x = x + self.mhsa(x, mask=mask, training=training)\n",
        "        x = x + self.conv(x, training=training)\n",
        "        x = x + 0.5 * self.ffn2(x, training=training)\n",
        "        return self.layer_norm(x)\n",
        "\n",
        "# ==================== Conformer Encoder (Vision Adaptation) ====================\n",
        "class ConformerEncoder(keras.Model):\n",
        "    \"\"\"Vision-style Conformer encoder for binary classification\"\"\"\n",
        "    def __init__(self, input_shape_tuple, num_blocks=4, d_model=128, num_heads=4, kernel_size=32, dropout_rate=0.1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.input_shape_tuple = input_shape_tuple\n",
        "        self.num_blocks = num_blocks\n",
        "        self.d_model = d_model\n",
        "\n",
        "        # Conv subsampling (same architecture)\n",
        "        self.conv_subsample = keras.Sequential([\n",
        "            layers.Conv2D(d_model // 2, kernel_size=3, strides=2, padding='same'),\n",
        "            layers.ReLU(),\n",
        "            layers.Conv2D(d_model, kernel_size=3, strides=2, padding='same'),\n",
        "            layers.ReLU(),\n",
        "        ])\n",
        "\n",
        "        self.conformer_blocks = [\n",
        "            ConformerBlock(d_model, num_heads, kernel_size, dropout_rate)\n",
        "            for _ in range(num_blocks)\n",
        "        ]\n",
        "\n",
        "        self.global_pool = layers.GlobalAveragePooling1D()\n",
        "        self.final_dropout = layers.Dropout(dropout_rate)\n",
        "        self.classifier = layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.conv_subsample(x, training=training)\n",
        "\n",
        "        batch_size = tf.shape(x)[0]\n",
        "        height = tf.shape(x)[1]\n",
        "        width = tf.shape(x)[2]\n",
        "\n",
        "        x = tf.reshape(x, [batch_size, height * width, self.d_model])\n",
        "\n",
        "        for block in self.conformer_blocks:\n",
        "            x = block(x, mask=None, training=training)\n",
        "\n",
        "        x = self.global_pool(x)\n",
        "        x = self.final_dropout(x, training=training)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# ==================== Model Creation ====================\n",
        "def create_conformer_model(input_shape=(127, 100, 1)):\n",
        "    \"\"\"Create and compile Conformer model (same architecture)\"\"\"\n",
        "    model = ConformerEncoder(\n",
        "        input_shape_tuple=input_shape,\n",
        "        num_blocks=4,\n",
        "        d_model=128,\n",
        "        num_heads=4,\n",
        "        kernel_size=32,\n",
        "        dropout_rate=0.1\n",
        "    )\n",
        "\n",
        "    dummy = tf.zeros((1,) + input_shape)  # dummy input\n",
        "    _ = model(dummy, training=False)  # build model\n",
        "\n",
        "    model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),  # optimizer\n",
        "    loss='binary_crossentropy',  # loss\n",
        "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy', threshold=0.5)]  # metric\n",
        ")\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "print(\"[STEP 9] ✅ Conformer model code ready.\")\n",
        "print(\"[STEP 9] Example: model = create_conformer_model(input_shape=(127, 100, 1))\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 9] Loading Conformer model code (unchanged)...\n[STEP 9] ✅ Conformer model code ready.\n[STEP 9] Example: model = create_conformer_model(input_shape=(127, 100, 1))\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1768734727108
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cell 10 — 5-Fold CV + train-only normalization + SMOTE + EarlyStopping + LR scheduling"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[STEP 6] Starting cross-validation...\")\n",
        "\n",
        "n_splits = 5\n",
        "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "fold_metrics = []\n",
        "fold_conf_mats = []\n",
        "\n",
        "# Input shape for Conformer (H,W,C) = (127, 100, 1)\n",
        "input_shape = (X_all.shape[1], X_all.shape[2], X_all.shape[3])\n",
        "print(\"[STEP 6] Model input shape:\", input_shape)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_all, y_all), start=1):\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(f\"[FOLD {fold}/{n_splits}] Splitting data...\")\n",
        "\n",
        "    # Split\n",
        "    X_train_raw = X_all[train_idx].astype(np.float32, copy=False)\n",
        "    y_train_raw = y_all[train_idx].astype(np.int32, copy=False)\n",
        "    X_val_raw = X_all[val_idx].astype(np.float32, copy=False)\n",
        "    y_val_raw = y_all[val_idx].astype(np.int32, copy=False)\n",
        "\n",
        "    print(f\"[FOLD {fold}] Train size: {X_train_raw.shape[0]} | Val size: {X_val_raw.shape[0]}\")\n",
        "    print(f\"[FOLD {fold}] Train class count:\", np.unique(y_train_raw, return_counts=True))\n",
        "    print(f\"[FOLD {fold}] Val class count  :\", np.unique(y_val_raw, return_counts=True))\n",
        "\n",
        "    # -------- Normalization (train only) --------\n",
        "    print(f\"[FOLD {fold}] Normalizing (train stats only)...\")\n",
        "\n",
        "    eps = 1e-6\n",
        "    train_mean = np.mean(X_train_raw, axis=(0, 2, 3), keepdims=True).astype(np.float32)\n",
        "    train_std = np.std(X_train_raw, axis=(0, 2, 3), keepdims=True).astype(np.float32)\n",
        "    train_std = np.maximum(train_std, eps)\n",
        "\n",
        "    X_train_norm = (X_train_raw - train_mean) / train_std\n",
        "    X_val_norm = (X_val_raw - train_mean) / train_std\n",
        "\n",
        "    print(f\"[FOLD {fold}] Normalization done ✅\")\n",
        "\n",
        "    # -------- SMOTE (train only) --------\n",
        "    print(f\"[FOLD {fold}] Applying SMOTE (train only)...\")\n",
        "\n",
        "    X_train_2d = X_train_norm.reshape(X_train_norm.shape[0], -1)\n",
        "    unique_before, counts_before = np.unique(y_train_raw, return_counts=True)\n",
        "    minority_n = int(np.min(counts_before))\n",
        "\n",
        "    if minority_n >= 2:\n",
        "        k_neighbors = max(1, min(5, minority_n - 1))\n",
        "        smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
        "        X_bal_2d, y_bal = smote.fit_resample(X_train_2d, y_train_raw)\n",
        "        print(f\"[FOLD {fold}] SMOTE applied ✅ (k={k_neighbors})\")\n",
        "    else:\n",
        "        ros = RandomOverSampler(random_state=42)\n",
        "        X_bal_2d, y_bal = ros.fit_resample(X_train_2d, y_train_raw)\n",
        "        print(f\"[FOLD {fold}] SMOTE not possible → used RandomOverSampler ⚠️\")\n",
        "\n",
        "    X_train_bal = X_bal_2d.reshape(-1, *input_shape).astype(np.float32)\n",
        "    y_train_bal = y_bal.astype(np.float32)\n",
        "\n",
        "    print(f\"[FOLD {fold}] Train balanced shape:\", X_train_bal.shape)\n",
        "    print(f\"[FOLD {fold}] Train balanced counts:\", np.unique(y_train_bal, return_counts=True))\n",
        "\n",
        "    # -------- Build model --------\n",
        "    print(f\"[FOLD {fold}] Building Conformer model...\")\n",
        "\n",
        "    model = create_conformer_model(input_shape=input_shape)  # SAME ARCH, only input shape changes\n",
        "\n",
        "    print(f\"[FOLD {fold}] Model built ✅\")\n",
        "\n",
        "    # Callbacks\n",
        "    early_stop = EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=15,\n",
        "        restore_best_weights=True,\n",
        "        verbose=1\n",
        "    )\n",
        "    lr_plateau = ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\",\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        min_lr=1e-6,\n",
        "        verbose=1\n",
        "    )\n",
        "    ckpt = ModelCheckpoint(\n",
        "        filepath=f\"ad_fold_{fold:02d}_best.keras\",\n",
        "        monitor=\"val_loss\",\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "    csv_logger = CSVLogger(f\"ad_fold_{fold:02d}_log.csv\", append=False)\n",
        "\n",
        "    callbacks = [early_stop, lr_plateau, ckpt, csv_logger]\n",
        "\n",
        "    # Train\n",
        "    print(f\"[FOLD {fold}] Training started...\")\n",
        "    history = model.fit(\n",
        "        X_train_bal, y_train_bal,\n",
        "        validation_data=(X_val_norm, y_val_raw.astype(np.float32)),\n",
        "        epochs=200,\n",
        "        batch_size=16,\n",
        "        shuffle=True,\n",
        "        verbose=1,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "    print(f\"[FOLD {fold}] Training finished ✅\")\n",
        "\n",
        "    # Evaluate\n",
        "    print(f\"[FOLD {fold}] Evaluating...\")\n",
        "    val_loss, val_acc, val_auc = model.evaluate(X_val_norm, y_val_raw.astype(np.float32), verbose=1)\n",
        "    print(f\"[FOLD {fold}] val_loss={val_loss:.4f} | val_acc={val_acc:.4f} | val_auc={val_auc:.4f}\")\n",
        "\n",
        "    # Predictions\n",
        "    y_prob = model.predict(X_val_norm, verbose=1).reshape(-1)\n",
        "    y_pred = (y_prob > 0.5).astype(int)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_val_raw, y_pred)\n",
        "    fold_conf_mats.append(cm)\n",
        "    print(f\"[FOLD {fold}] Confusion matrix:\\n{cm}\")\n",
        "\n",
        "    # Metrics from CM\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    accuracy = (TP + TN) / max((TP + TN + FP + FN), 1)\n",
        "    precision = TP / max((TP + FP), 1)\n",
        "    recall = TP / max((TP + FN), 1)\n",
        "    specificity = TN / max((TN + FP), 1)\n",
        "    f1 = (2 * precision * recall) / max((precision + recall), 1e-12)\n",
        "\n",
        "    try:\n",
        "        auc_val = float(roc_auc_score(y_val_raw, y_prob))\n",
        "    except Exception:\n",
        "        auc_val = float(\"nan\")\n",
        "\n",
        "    fold_metrics.append({\n",
        "        \"fold\": fold,\n",
        "        \"val_loss\": float(val_loss),\n",
        "        \"val_acc\": float(val_acc),\n",
        "        \"auc\": float(auc_val),\n",
        "        \"accuracy\": float(accuracy),\n",
        "        \"precision\": float(precision),\n",
        "        \"recall\": float(recall),\n",
        "        \"specificity\": float(specificity),\n",
        "        \"f1\": float(f1)\n",
        "    })\n",
        "\n",
        "    # Plot CM\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"Fold {fold} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"[STEP 6] Cross-validation finished ✅\")\n",
        "\n",
        "# Summaries\n",
        "def safe_mean(vals):\n",
        "    return float(np.nanmean(np.array(vals, dtype=float)))\n",
        "\n",
        "def safe_std(vals):\n",
        "    return float(np.nanstd(np.array(vals, dtype=float)))\n",
        "\n",
        "avg = {k: safe_mean([m[k] for m in fold_metrics]) for k in fold_metrics[0].keys() if k != \"fold\"}\n",
        "std = {k: safe_std([m[k] for m in fold_metrics]) for k in avg.keys()}\n",
        "\n",
        "print(\"\\n[FINAL] Average CV metrics (mean ± std):\")\n",
        "for k in avg:\n",
        "    print(f\"  {k:12s}: {avg[k]:.4f} ± {std[k]:.4f}\")\n",
        "\n",
        "cm_sum = np.sum(np.stack(fold_conf_mats, axis=0), axis=0)\n",
        "print(\"\\n[FINAL] Summed confusion matrix across folds:\")\n",
        "print(cm_sum)\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.heatmap(cm_sum, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"Summed Confusion Matrix (All Folds)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[STEP 6] Starting cross-validation...\n[STEP 6] Model input shape: (127, 100, 1)\n\n======================================================================\n[FOLD 1/5] Splitting data...\n[FOLD 1] Train size: 32000 | Val size: 8000\n[FOLD 1] Train class count: (array([0, 1], dtype=int32), array([16000, 16000]))\n[FOLD 1] Val class count  : (array([0, 1], dtype=int32), array([4000, 4000]))\n[FOLD 1] Normalizing (train stats only)...\n[FOLD 1] Normalization done ✅\n[FOLD 1] Applying SMOTE (train only)...\n[FOLD 1] SMOTE applied ✅ (k=5)\n[FOLD 1] Train balanced shape: (32000, 127, 100, 1)\n[FOLD 1] Train balanced counts: (array([0., 1.], dtype=float32), array([16000, 16000]))\n[FOLD 1] Building Conformer model...\nWARNING:tensorflow:5 out of the last 5 calls to <function conv.<locals>._conv_xla at 0x7e137df02290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\nWARNING:tensorflow:6 out of the last 6 calls to <function conv.<locals>._conv_xla at 0x7e137de5e290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n[FOLD 1] Model built ✅\n[FOLD 1] Training started...\nEpoch 1/200\n\u001b[1m   1/2000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20:14:58\u001b[0m 36s/step - accuracy: 0.4375 - loss: 0.7833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m   2/2000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18:02\u001b[0m 10s/step - accuracy: 0.5156 - loss: 0.8604 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m  25/2000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18:32\u001b[0m 10s/step - accuracy: 0.5267 - loss: 0.9153\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m  26/2000\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:18:15\u001b[0m 10s/step - accuracy: 0.5273 - loss: 0.9115"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 96\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[FOLD \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Training started...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 96\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_bal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_bal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_raw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[FOLD \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Training finished ✅\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1768735071331
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.10 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.16",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}