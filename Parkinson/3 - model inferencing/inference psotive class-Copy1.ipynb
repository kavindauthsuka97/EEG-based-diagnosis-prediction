{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4b572c-0225-422f-8d84-10fb8b49d2c2",
   "metadata": {},
   "source": [
    "CELL 1 — Imports + seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9555a00-9b76-4e4e-84be-aac3699cf002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imports loaded and seeds set.\n"
     ]
    }
   ],
   "source": [
    "# Operating system utilities\n",
    "import os\n",
    "\n",
    "# Array handling\n",
    "import numpy as np\n",
    "\n",
    "# Pickle for loading normalization stats\n",
    "import pickle\n",
    "\n",
    "# EEG preprocessing libraries\n",
    "import mne\n",
    "import pywt\n",
    "\n",
    "# Machine learning utilities\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# TensorFlow / Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Reproducibility\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"✅ Imports loaded and seeds set.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8898c39a-4931-4584-a1b4-465d83bd85c8",
   "metadata": {},
   "source": [
    "CELL 2 — Load trained model + normalization stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08364221-736a-4bb5-af25-c225104902fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Weights loaded into rebuilt model.\n",
      "✅ Training mean loaded.\n",
      "✅ Training std loaded.\n",
      "✅ Saved safe model to: C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Parkinson\\model inference\\p_eegformer-v1_SAFE.h5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import tempfile\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, SeparableConv2D, DepthwiseConv2D, BatchNormalization, Activation,\n",
    "    AveragePooling2D, Dropout, Dense, Add, Reshape,\n",
    "    LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# =========================\n",
    "# Paths (UPDATED for Parkinson)\n",
    "# =========================\n",
    "MODEL_PATH = r\"C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Parkinson\\model inference\\p_eegformer-v1.keras\"\n",
    "MEAN_PATH  = r\"C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Parkinson\\model inference\\p_train_mean.pkl\"\n",
    "STD_PATH   = r\"C:\\Users\\HP\\Desktop\\Jupyter Notebooks\\Dermerzel\\SomnasNest\\Parkinson\\model inference\\p_train_std.pkl\"\n",
    "\n",
    "# =========================\n",
    "# Safe replacement for Lambda(lambda y: y[:, :, :, :32])\n",
    "# =========================\n",
    "class ChannelSlice(keras.layers.Layer):\n",
    "    def __init__(self, n_channels, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "    def call(self, x):\n",
    "        return x[:, :, :, :self.n_channels]\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\"n_channels\": self.n_channels})\n",
    "        return cfg\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Model definition\n",
    "# =========================\n",
    "def SpatialAttention(x):\n",
    "    attention = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    attention = Dense(64, activation='relu')(attention)\n",
    "    attention = Dense(x.shape[1], activation='sigmoid')(attention)\n",
    "    attention = tf.keras.layers.Reshape((x.shape[1], 1, 1))(attention)\n",
    "    return tf.keras.layers.Multiply()([x, attention])\n",
    "\n",
    "def TransformerBlock(x, num_heads=4, key_dim=64, ff_dim=128, dropout_rate=0.1):\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(x, x)\n",
    "    attn_output = Dropout(dropout_rate)(attn_output)\n",
    "    attn_output = Add()([x, attn_output])\n",
    "    attn_output = LayerNormalization()(attn_output)\n",
    "\n",
    "    ff_output = Dense(ff_dim, activation='relu')(attn_output)\n",
    "    ff_output = Dropout(dropout_rate)(ff_output)\n",
    "    ff_output = Dense(x.shape[-1])(ff_output)\n",
    "    x = Add()([attn_output, ff_output])\n",
    "    x = LayerNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def EEGNet_SpatialTransformer(input_shape=(127, 100, 1), dropout_rate=0.5, num_heads=4, ff_dim=128):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = SeparableConv2D(32, (1, 5), padding='same', use_bias=False)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = SpatialAttention(x)\n",
    "\n",
    "    x = DepthwiseConv2D((input_shape[0], 1), use_bias=False, depth_multiplier=2, padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    residual = ChannelSlice(32, name=\"residual_slice\")(inputs)\n",
    "    residual = BatchNormalization()(residual)\n",
    "\n",
    "    x = Add()([x, residual])\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = AveragePooling2D((1, 4))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x = SeparableConv2D(64, (1, 3), padding='same', use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = AveragePooling2D((1, 4))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    x_shape = K.int_shape(x)\n",
    "    x = Reshape((x_shape[1], x_shape[2] * x_shape[3]))(x)\n",
    "    x = TransformerBlock(x, num_heads=num_heads, key_dim=64, ff_dim=ff_dim)\n",
    "\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    return Model(inputs, outputs, name=\"EEGNet_SpatialTransformer\")\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Extract weights from .keras\n",
    "# =========================\n",
    "def extract_weights_from_keras(keras_path: str) -> str:\n",
    "    tmp_dir = tempfile.mkdtemp(prefix=\"keras_weights_\")\n",
    "    with zipfile.ZipFile(keras_path, \"r\") as z:\n",
    "        names = z.namelist()\n",
    "        weight_candidates = [n for n in names if n.endswith(\".h5\") and \"weights\" in n.lower()]\n",
    "        if not weight_candidates:\n",
    "            raise FileNotFoundError(f\"No weights .h5 found inside {keras_path}\")\n",
    "\n",
    "        weights_name = weight_candidates[0]\n",
    "        z.extract(weights_name, tmp_dir)\n",
    "        return os.path.join(tmp_dir, weights_name)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Build & load model\n",
    "# =========================\n",
    "model = EEGNet_SpatialTransformer(input_shape=(62, 100, 1))\n",
    "\n",
    "weights_path = extract_weights_from_keras(MODEL_PATH)\n",
    "model.load_weights(weights_path)\n",
    "print(\"✅ Weights loaded into rebuilt model.\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name=\"accuracy\", threshold=0.5)]\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Load mean / std\n",
    "# =========================\n",
    "with open(MEAN_PATH, \"rb\") as f:\n",
    "    train_mean = pickle.load(f)\n",
    "print(\"✅ Training mean loaded.\")\n",
    "\n",
    "with open(STD_PATH, \"rb\") as f:\n",
    "    train_std = pickle.load(f)\n",
    "print(\"✅ Training std loaded.\")\n",
    "\n",
    "# =========================\n",
    "# Save SAFE model (CURRENT WORKING DIRECTORY)\n",
    "# =========================\n",
    "SAFE_MODEL_PATH = os.path.join(os.getcwd(), \"p_eegformer-v1_SAFE.h5\")\n",
    "model.save(SAFE_MODEL_PATH)\n",
    "print(f\"✅ Saved safe model to: {SAFE_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc44d222-4daf-466f-b55f-07ccac26ebb3",
   "metadata": {},
   "source": [
    "CELL 3 — Load ONLY excluded trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4552ccad-4bc8-4f23-aa72-b04edccd2c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ EEG arrays loaded.\n",
      "Negative shape: (31, 62, 120000)\n",
      "Positive shape: (21, 62, 60000)\n",
      "✅ Extracted excluded trials:\n",
      "Excluded negative: (5, 62, 120000)\n",
      "Excluded positive: (5, 62, 60000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Local EEG data paths (UPDATED for Parkinson)\n",
    "# =========================\n",
    "NEG_PATH = r\"D:\\Dermerzel\\SomnasNest\\Parkinson\\Data Array\\parkinson_negative.npy\"\n",
    "POS_PATH = r\"D:\\Dermerzel\\SomnasNest\\Parkinson\\Data Array\\parkinson_positive.npy\"\n",
    "\n",
    "# =========================\n",
    "# Load full arrays\n",
    "# =========================\n",
    "X_neg_full = np.load(NEG_PATH).astype(np.float32)\n",
    "X_pos_full = np.load(POS_PATH).astype(np.float32)\n",
    "\n",
    "print(\"✅ EEG arrays loaded.\")\n",
    "print(\"Negative shape:\", X_neg_full.shape)\n",
    "print(\"Positive shape:\", X_pos_full.shape)\n",
    "\n",
    "# =========================\n",
    "# Extract ONLY last 5 trials (excluded during training)\n",
    "# =========================\n",
    "X_neg_excluded = X_neg_full[-5:]\n",
    "X_pos_excluded = X_pos_full[-5:]\n",
    "\n",
    "print(\"✅ Extracted excluded trials:\")\n",
    "print(\"Excluded negative:\", X_neg_excluded.shape)\n",
    "print(\"Excluded positive:\", X_pos_excluded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14208a60-780a-419f-8239-5bdba714d398",
   "metadata": {},
   "source": [
    "CELL 4 — Select ONLY last ad_negative sample (target = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ee70b32e-df6b-4001-b9ec-e84ce66475a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Selected last excluded ad_positive trial.\n",
      "Trial shape: (62, 60000)\n",
      "Ground truth label: 1\n"
     ]
    }
   ],
   "source": [
    "# Select ONLY the last excluded positive trial\n",
    "X_test_trial = X_pos_excluded[-5]        # last unseen ad_positive sample\n",
    "y_test_trial = 1                         # ground truth label (positive)\n",
    "\n",
    "print(\"✅ Selected last excluded ad_positive trial.\")\n",
    "print(\"Trial shape:\", X_test_trial.shape)\n",
    "print(\"Ground truth label:\", y_test_trial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0295f-fe0e-489d-97df-27399a0c364a",
   "metadata": {},
   "source": [
    "* downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6e6702a-c1e9-4bd6-b1c8-88a49c9fd15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# --- Downsample from 1000 Hz -> 500 Hz (keep output name: X_test_trial) ---\\nsfreq_in = 1000\\nsfreq_out = 500\\n\\nX_test_trial = mne.filter.resample(\\n    X_test_trial.astype(np.float64, copy=False),\\n    down=sfreq_in // sfreq_out,   # 2\\n    npad=\"auto\",\\n    axis=-1,\\n    verbose=True\\n).astype(np.float32, copy=False)\\n\\nprint(\"✅ Downsampled X_test_trial to 500 Hz.\")\\nprint(\"Trial shape after downsampling:\", X_test_trial.shape, X_test_trial.dtype)\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# --- Downsample from 1000 Hz -> 500 Hz (keep output name: X_test_trial) ---\n",
    "sfreq_in = 1000\n",
    "sfreq_out = 500\n",
    "\n",
    "X_test_trial = mne.filter.resample(\n",
    "    X_test_trial.astype(np.float64, copy=False),\n",
    "    down=sfreq_in // sfreq_out,   # 2\n",
    "    npad=\"auto\",\n",
    "    axis=-1,\n",
    "    verbose=True\n",
    ").astype(np.float32, copy=False)\n",
    "\n",
    "print(\"✅ Downsampled X_test_trial to 500 Hz.\")\n",
    "print(\"Trial shape after downsampling:\", X_test_trial.shape, X_test_trial.dtype)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1148bf-53c8-4dc9-b4c7-7a619900d547",
   "metadata": {},
   "source": [
    "CELL 5 — Helper + preprocessing classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0a5bed4-e578-451a-b8c7-3b69c8269fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Preprocessing helpers defined.\n"
     ]
    }
   ],
   "source": [
    "# Helper to generate channel names\n",
    "def _names_from_index_mapping(n_channels, index_to_name):\n",
    "    return [f\"EEG{i+1}\" for i in range(n_channels)]\n",
    "\n",
    "# Helper to create MNE Raw object\n",
    "def _make_raw(eeg, sfreq, ch_names):\n",
    "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=\"eeg\")\n",
    "    return mne.io.RawArray(eeg, info, verbose=False)\n",
    "\n",
    "# Wavelet ICA class\n",
    "class WaveletICA:\n",
    "    def __init__(self, wavelet=\"db4\", level=3, n_components=10):\n",
    "        self.wavelet = wavelet\n",
    "        self.level = level\n",
    "        self.n_components = n_components\n",
    "        self.ica = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        coeffs = pywt.wavedec(X, self.wavelet, level=self.level, axis=1)\n",
    "        A = coeffs[0]\n",
    "        self.ica = FastICA(n_components=min(self.n_components, X.shape[0]), random_state=42)\n",
    "        S = self.ica.fit_transform(A.T)\n",
    "        coeffs[0] = self.ica.inverse_transform(S).T\n",
    "        pywt.waverec(coeffs, self.wavelet, axis=1)\n",
    "\n",
    "    def transform(self, X):\n",
    "        coeffs = pywt.wavedec(X, self.wavelet, level=self.level, axis=1)\n",
    "        A = coeffs[0]\n",
    "        S = self.ica.transform(A.T)\n",
    "        coeffs[0] = self.ica.inverse_transform(S).T\n",
    "        return pywt.waverec(coeffs, self.wavelet, axis=1)\n",
    "\n",
    "print(\"✅ Preprocessing helpers defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecabba65-f176-40ee-9616-ad5b75683307",
   "metadata": {},
   "source": [
    "CELL 6 — Apply preprocessing to unseen test trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e670665-042a-4004-a0c1-e5028b004408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n",
      "Created an SSP operator (subspace dimension = 1)\n",
      "1 projection items activated\n",
      "SSP projectors applied...\n",
      "✅ Preprocessing applied.\n",
      "Cleaned trial shape: (62, 60000)\n"
     ]
    }
   ],
   "source": [
    "# Sampling frequency (same as training)\n",
    "fs = 500.0\n",
    "\n",
    "# Create Raw object\n",
    "raw = _make_raw(X_test_trial, fs, _names_from_index_mapping(X_test_trial.shape[0], None))\n",
    "\n",
    "# Notch filtering\n",
    "raw.notch_filter([50, 100, 150], verbose=False)\n",
    "\n",
    "# High-pass filtering\n",
    "raw.filter(l_freq=0.05, h_freq=None, verbose=False)\n",
    "\n",
    "# Common average reference\n",
    "raw.set_eeg_reference(\"average\", projection=True)\n",
    "raw.apply_proj()\n",
    "\n",
    "# Extract cleaned signal\n",
    "X_clean = raw.get_data().astype(np.float32)\n",
    "\n",
    "print(\"✅ Preprocessing applied.\")\n",
    "print(\"Cleaned trial shape:\", X_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880869e-281e-48f6-adde-aeb7969bf9e4",
   "metadata": {},
   "source": [
    "CELL 7 — Segment test trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8840de4-a842-4379-ac3c-3b6385c9981f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Trial segmented.\n",
      "Segments shape: (600, 62, 100)\n"
     ]
    }
   ],
   "source": [
    "# Segment size\n",
    "SEGMENT_SIZE = 100\n",
    "\n",
    "# Segment the trial\n",
    "segments = []\n",
    "for i in range(X_clean.shape[1] // SEGMENT_SIZE):\n",
    "    seg = X_clean[:, i*SEGMENT_SIZE:(i+1)*SEGMENT_SIZE]\n",
    "    segments.append(seg)\n",
    "\n",
    "# Convert to array\n",
    "X_test_segments = np.array(segments, dtype=np.float32)\n",
    "\n",
    "print(\"✅ Trial segmented.\")\n",
    "print(\"Segments shape:\", X_test_segments.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73a256-a43b-42ea-b6de-1ef798c1e7b7",
   "metadata": {},
   "source": [
    "CELL 8 — Reshape + normalize using TRAINING stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94c63994-1590-45d6-90cb-29ab2674e7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normalization applied using training statistics.\n",
      "Final test shape: (600, 62, 100, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add channel dimension\n",
    "X_test = X_test_segments[..., np.newaxis]\n",
    "\n",
    "# Normalize using training mean/std\n",
    "X_test_norm = (X_test - train_mean) / train_std\n",
    "\n",
    "print(\"✅ Normalization applied using training statistics.\")\n",
    "print(\"Final test shape:\", X_test_norm.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2331cf-a7bc-4b88-84a8-a99960ade91e",
   "metadata": {},
   "source": [
    "CELL 9 — Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "67b0ffea-89a3-483a-8b2e-d4f1669879f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inference completed for ad_positive trial.\n",
      "First 10 predicted labels: [1 1 1 1 1 1 1 1 1 1]\n",
      "Total segments: 600\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for each segment\n",
    "y_probs = model.predict(X_test_norm, verbose=0)\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "y_preds = (y_probs >= 0.5).astype(int).flatten()\n",
    "\n",
    "# Ground truth labels (ALL ones because ad_positive)\n",
    "y_true = np.ones_like(y_preds)\n",
    "\n",
    "print(\"✅ Inference completed for ad_positive trial.\")\n",
    "print(\"First 10 predicted labels:\", y_preds[:10])\n",
    "print(\"Total segments:\", len(y_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c815e60-49db-4e87-9b17-38152116265f",
   "metadata": {},
   "source": [
    "CELL 10 — Confusion matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "000085f8-31ca-407c-acbb-62678e563ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives : 0\n",
      "False Positives: 0\n",
      "False Negatives: 4\n",
      "True Positives : 596\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Force both labels (0 = Negative, 1 = Positive)\n",
    "# -------------------------------------------------\n",
    "cm = confusion_matrix(\n",
    "    y_true,\n",
    "    y_preds,\n",
    "    labels=[0, 1]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Plot confusion matrix\n",
    "# -------------------------------------------------\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"Negative\", \"Positive\"],\n",
    "    yticklabels=[\"Negative\", \"Positive\"],\n",
    "    cbar=False\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix — Last Excluded ad_positive Sample\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# Optional: print readable breakdown\n",
    "# -------------------------------------------------\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"True Negatives : {tn}\")\n",
    "print(f\"False Positives: {fp}\")\n",
    "print(f\"False Negatives: {fn}\")\n",
    "print(f\"True Positives : {tp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6490f5e3-268a-42af-91a1-501235308314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Electrode list length = 127 but X_test_norm has 62 channels.\n",
      "✅ Trimmed electrode list to 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Saliency (segments):  20%|██        | 122/600 [00:12<00:48,  9.77it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14772\\2866596788.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Compute saliency for each segment in your unseen trial\u001b[39;00m\n\u001b[32m     59\u001b[39m all_saliencies = []\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m tqdm(range(X_test_norm.shape[\u001b[32m0\u001b[39m]), desc=\u001b[33m\"Computing Saliency (segments)\"\u001b[39m):\n\u001b[32m     61\u001b[39m     sample = X_test_norm[i:i+\u001b[32m1\u001b[39m]                          \u001b[38;5;66;03m# (1, C, T, 1)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     sal = compute_electrode_saliency(model, sample, class_index=\u001b[32m1\u001b[39m)\n\u001b[32m     63\u001b[39m     all_saliencies.append(sal)\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m all_saliencies = np.array(all_saliencies, dtype=np.float32)   \u001b[38;5;66;03m# (n_segments, C)\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_14772\\2866596788.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(model, input_sample, class_index)\u001b[39m\n\u001b[32m     38\u001b[39m     input_sample = tf.convert_to_tensor(input_sample, dtype=tf.float32)\n\u001b[32m     39\u001b[39m \n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tf.GradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[32m     41\u001b[39m         tape.watch(input_sample)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m         pred = model(input_sample, training=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m         \u001b[38;5;66;03m# Make a scalar target to differentiate\u001b[39;00m\n\u001b[32m     45\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pred.shape[-\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    976\u001b[39m                 )\n\u001b[32m    977\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    978\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    980\u001b[39m \n\u001b[32m    981\u001b[39m         \u001b[38;5;66;03m################################################\u001b[39;00m\n\u001b[32m    982\u001b[39m         \u001b[38;5;66;03m# 8. Add a node in the graph for symbolic calls.\u001b[39;00m\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m                 call_fn,\n\u001b[32m     57\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     58\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\models\\functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training, mask, **kwargs)\u001b[39m\n\u001b[32m    179\u001b[39m             masks = tree.flatten(mask)\n\u001b[32m    180\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m x, mask \u001b[38;5;28;01min\u001b[39;00m zip(inputs, masks):\n\u001b[32m    181\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    182\u001b[39m                     backend.set_keras_mask(x, mask)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m         outputs = self._run_through_graph(\n\u001b[32m    184\u001b[39m             inputs,\n\u001b[32m    185\u001b[39m             operation_fn=lambda op: operation_fn(\n\u001b[32m    186\u001b[39m                 op, training=training, **kwargs\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\function.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, operation_fn, call_fn)\u001b[39m\n\u001b[32m    202\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    203\u001b[39m                     \u001b[38;5;66;03m# Use NNX operation mapping\u001b[39;00m\n\u001b[32m    204\u001b[39m                     operation = self._get_operation_for_node(node)\n\u001b[32m    205\u001b[39m                     op = operation_fn(operation)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m                     outputs = op(*args, **kwargs)\n\u001b[32m    207\u001b[39m \n\u001b[32m    208\u001b[39m                 \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[32m    209\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;28;01min\u001b[39;00m zip(node.outputs, tree.flatten(outputs)):\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\models\\functional.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    640\u001b[39m                 \u001b[38;5;28;01mand\u001b[39;00m value \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    641\u001b[39m             ):\n\u001b[32m    642\u001b[39m                 kwargs[name] = value\n\u001b[32m    643\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m operation(*args, **kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\layers\\layer.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m                     \u001b[33m\"layers will not see the mask.\"\u001b[39m\n\u001b[32m    976\u001b[39m                 )\n\u001b[32m    977\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    978\u001b[39m             \u001b[38;5;66;03m# Destroy call context if we created it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m             self._maybe_reset_call_context()\n\u001b[32m    980\u001b[39m \n\u001b[32m    981\u001b[39m         \u001b[38;5;66;03m################################################\u001b[39;00m\n\u001b[32m    982\u001b[39m         \u001b[38;5;66;03m# 8. Add a node in the graph for symbolic calls.\u001b[39;00m\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m             \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m             \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m    122\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\operation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m             call_fn = traceback_utils.inject_argument_info_in_traceback(\n\u001b[32m     56\u001b[39m                 call_fn,\n\u001b[32m     57\u001b[39m                 object_name=(f\"{self.__class__.__name__}.call()\"),\n\u001b[32m     58\u001b[39m             )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m call_fn(*args, **kwargs)\n\u001b[32m     60\u001b[39m \n\u001b[32m     61\u001b[39m         \u001b[38;5;66;03m# Plain flow.\u001b[39;00m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors(args, kwargs):\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m                 new_e = e\n\u001b[32m    214\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m new_e.with_traceback(e.__traceback__) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    215\u001b[39m         \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    216\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m signature\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m             \u001b[38;5;28;01mdel\u001b[39;00m bound_signature\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, inputs, training)\u001b[39m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m call(self, inputs, training=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m         x = ops.matmul(inputs, self.kernel)\n\u001b[32m    152\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.bias \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    153\u001b[39m             x = ops.add(x, self.bias)\n\u001b[32m    154\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m self.activation \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\ops\\numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m   4207\u001b[39m         Output tensor, matrix product of the inputs.\n\u001b[32m   4208\u001b[39m     \"\"\"\n\u001b[32m   4209\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((x1, x2)):\n\u001b[32m   4210\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Matmul().symbolic_call(x1, x2)\n\u001b[32m-> \u001b[39m\u001b[32m4211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.numpy.matmul(x1, x2)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\numpy.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x1, x2)\u001b[39m\n\u001b[32m    622\u001b[39m             output = tf.tensordot(x1, x2, axes=\u001b[32m1\u001b[39m)\n\u001b[32m    623\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m x1_shape.rank == \u001b[32m1\u001b[39m:\n\u001b[32m    624\u001b[39m             output = tf.tensordot(x1, x2, axes=[[\u001b[32m0\u001b[39m], [-\u001b[32m2\u001b[39m]])\n\u001b[32m    625\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m             output = tf.matmul(x1, x2, output_type=output_type)\n\u001b[32m    627\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tf.cast(output, result_dtype)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    140\u001b[39m   \u001b[38;5;28;01mdef\u001b[39;00m wrapper(*args, **kwargs):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ops.is_auto_dtype_conversion_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m op(*args, **kwargs)\n\u001b[32m    143\u001b[39m     bound_arguments = signature.bind(*args, **kwargs)\n\u001b[32m    144\u001b[39m     bound_arguments.apply_defaults()\n\u001b[32m    145\u001b[39m     bound_kwargs = bound_arguments.arguments\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m Exception \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m       filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    153\u001b[39m       \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m       \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1261\u001b[39m \n\u001b[32m   1262\u001b[39m       \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[32m   1263\u001b[39m       \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1264\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(*args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1265\u001b[39m       \u001b[38;5;28;01mexcept\u001b[39;00m (TypeError, ValueError):\n\u001b[32m   1266\u001b[39m         \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[32m   1267\u001b[39m         \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[32m   1268\u001b[39m         result = dispatch(op_dispatch_handler, args, kwargs)\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, grad_a, grad_b, name)\u001b[39m\n\u001b[32m   3634\u001b[39m             grad_y=grad_b,\n\u001b[32m   3635\u001b[39m             name=name,\n\u001b[32m   3636\u001b[39m         )\n\u001b[32m   3637\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3638\u001b[39m         return gen_math_ops.batch_mat_mul_v2(\n\u001b[32m   3639\u001b[39m             a,\n\u001b[32m   3640\u001b[39m             b,\n\u001b[32m   3641\u001b[39m             adj_x=adjoint_a,\n",
      "\u001b[32m~\\anaconda3\\envs\\DL\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(x, y, adj_x, adj_y, grad_x, grad_y, name)\u001b[39m\n\u001b[32m   1641\u001b[39m         \u001b[33m\"grad_x\"\u001b[39m, grad_x, \u001b[33m\"grad_y\"\u001b[39m, grad_y)\n\u001b[32m   1642\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   1643\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1644\u001b[39m       _ops.raise_from_not_ok_status(e, name)\n\u001b[32m-> \u001b[39m\u001b[32m1645\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m _core._FallbackException:\n\u001b[32m   1646\u001b[39m       \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1648\u001b[39m       return batch_mat_mul_v2_eager_fallback(\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# %% Step 11 - Gradient-based saliency scores (for your unseen trial segments)\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Your electrode list (must match channel order in X_test_norm)\n",
    "electrode_names = [\n",
    "    'Fp1', 'Fz', 'F3', 'F7', 'FT9', 'FC5', 'FC1', 'C3', 'T7', 'TP9', 'CP5', 'CP1', 'Pz', 'P3', 'P7', 'O1', 'Oz', 'O2',\n",
    "    'P4', 'P8', 'TP10', 'CP6', 'CP2', 'Cz', 'C4', 'T8', 'FT10', 'FC6', 'FC2', 'F4', 'F8', 'Fp2', 'AF7', 'AF3', 'AFz',\n",
    "    'F1', 'F5', 'FT7', 'FC3', 'C1', 'C5', 'TP7', 'CP3', 'P1', 'P5', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'P6', 'P2',\n",
    "    'CPz', 'CP4', 'TP8', 'C6', 'C2', 'FC4', 'FT8', 'F6', 'AF8', 'AF4', 'F2', 'F9', 'AFF1h', 'FFC1h', 'FFC5h', 'FTT7h',\n",
    "    'FCC3h', 'CCP1h', 'CCP5h', 'TPP7h', 'P9', 'PPO9h', 'PO9', 'O9', 'OI1h', 'PPO1h', 'CPP3h', 'CPP4h', 'PPO2h', 'OI2h',\n",
    "    'O10', 'PO10', 'PPO10h', 'P10', 'TPP8h', 'CCP6h', 'CCP2h', 'FCC4h', 'FTT8h', 'FFC6h', 'FFC2h', 'AFF2h', 'F10',\n",
    "    'AFp1', 'AFF5h', 'FFT9h', 'FFT7h', 'FFC3h', 'FCC1h', 'FCC5h', 'FTT9h', 'TTP7h', 'CCP3h', 'CPP1h', 'CPP5h', 'TPP9h',\n",
    "    'POO9h', 'PPO5h', 'POO1', 'POO2', 'PPO6h', 'POO10h', 'TPP10h', 'CPP6h', 'CPP2h', 'CCP4h', 'TTP8h', 'FTT10h',\n",
    "    'FCC6h', 'FCC2h', 'FFC4h', 'FFT8h', 'FFT10h', 'AFF6h', 'AFp2'\n",
    "]\n",
    "\n",
    "# --- Safety check: electrode count must match your data channel count ---\n",
    "n_channels_data = X_test_norm.shape[1]\n",
    "if len(electrode_names) != n_channels_data:\n",
    "    print(f\"⚠️ Electrode list length = {len(electrode_names)} but X_test_norm has {n_channels_data} channels.\")\n",
    "    # Fallback: auto-generate names to avoid crashing (or trim if electrode list is longer)\n",
    "    if len(electrode_names) > n_channels_data:\n",
    "        electrode_names = electrode_names[:n_channels_data]\n",
    "        print(f\"✅ Trimmed electrode list to {n_channels_data}.\")\n",
    "    else:\n",
    "        electrode_names = [f\"EEG{i+1}\" for i in range(n_channels_data)]\n",
    "        print(f\"✅ Using auto-generated names EEG1..EEG{n_channels_data}.\")\n",
    "\n",
    "def compute_electrode_saliency(model, input_sample, class_index=1):\n",
    "    \"\"\"\n",
    "    Compute per-electrode saliency for ONE sample shaped like (1, C, T, 1).\n",
    "    Works for sigmoid (1 output) or softmax (>=2 outputs).\n",
    "    \"\"\"\n",
    "    input_sample = tf.convert_to_tensor(input_sample, dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_sample)\n",
    "        pred = model(input_sample, training=False)\n",
    "\n",
    "        # Make a scalar target to differentiate\n",
    "        if pred.shape[-1] == 1:\n",
    "            target = pred[:, 0]                          # sigmoid probability\n",
    "        else:\n",
    "            target = pred[:, class_index]                # softmax probability for class_index\n",
    "\n",
    "    grads = tape.gradient(target, input_sample)          # same shape as input_sample\n",
    "    grads = tf.abs(grads)\n",
    "\n",
    "    # Average over time and \"channel dimension\" (the last dim=1) -> keep electrodes\n",
    "    # input shape: (1, C, T, 1) => reduce over T and last dim\n",
    "    saliency = tf.reduce_mean(grads, axis=(2, 3))        # -> (1, C)\n",
    "    return saliency.numpy().flatten()\n",
    "\n",
    "# Compute saliency for each segment in your unseen trial\n",
    "all_saliencies = []\n",
    "for i in tqdm(range(X_test_norm.shape[0]), desc=\"Computing Saliency (segments)\"):\n",
    "    sample = X_test_norm[i:i+1]                          # (1, C, T, 1)\n",
    "    sal = compute_electrode_saliency(model, sample, class_index=1)\n",
    "    all_saliencies.append(sal)\n",
    "\n",
    "all_saliencies = np.array(all_saliencies, dtype=np.float32)   # (n_segments, C)\n",
    "\n",
    "# Aggregate across segments\n",
    "mean_saliency = np.mean(all_saliencies, axis=0)               # (C,)\n",
    "normalized_saliency = mean_saliency / (np.max(mean_saliency) + 1e-8)\n",
    "\n",
    "# Save CSV\n",
    "saliency_df = pd.DataFrame({\n",
    "    \"Electrode\": electrode_names,\n",
    "    \"Saliency Score\": normalized_saliency\n",
    "})\n",
    "\n",
    "out_csv = \"gradient_saliency_scores_last_excluded_ad_positive_trial.csv\"\n",
    "saliency_df.to_csv(out_csv, index=False)\n",
    "print(f\"✅ Saved gradient-based saliency scores to '{out_csv}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081642ef-8230-4e7e-9944-7ab06b9a7ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [NEW CELL] Clear topomap: BIG dots + labels with leader lines (robust for your channel set)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mne\n",
    "\n",
    "# -------- 1) Load values --------\n",
    "if \"normalized_saliency\" in globals() and \"electrode_names\" in globals():\n",
    "    ch_names_orig = list(electrode_names)\n",
    "    values_orig = np.asarray(normalized_saliency, dtype=float)\n",
    "else:\n",
    "    # Change filename if needed\n",
    "    df = pd.read_csv(\"70th_gradient_saliency_scores.csv\")\n",
    "    ch_names_orig = df[\"Electrode\"].astype(str).tolist()\n",
    "    values_orig = df[\"Saliency Score\"].to_numpy(dtype=float)\n",
    "\n",
    "# -------- 2) Build mapping to montage channel names --------\n",
    "# Many high-density names end with \"h\" (e.g., AFF1h). Standard montages often store them without \"h\".\n",
    "def montage_lookup_name(name: str) -> str:\n",
    "    n = name.strip()\n",
    "    if n.endswith(\"h\") and len(n) > 1:\n",
    "        return n[:-1]  # AFF1h -> AFF1\n",
    "    return n\n",
    "\n",
    "ch_names_lookup = [montage_lookup_name(n) for n in ch_names_orig]\n",
    "\n",
    "# -------- 3) Create info & set a montage with custom positions --------\n",
    "# Use standard_1005 for broader coverage than standard_1020\n",
    "base_montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "base_pos = base_montage.get_positions()[\"ch_pos\"]  # dict: {name: xyz}\n",
    "\n",
    "# Create a custom position dict for *your original* channel names\n",
    "# by borrowing xyz from the lookup name if available.\n",
    "ch_pos_custom = {}\n",
    "keep_idx = []\n",
    "for i, (orig, look) in enumerate(zip(ch_names_orig, ch_names_lookup)):\n",
    "    if look in base_pos:\n",
    "        ch_pos_custom[orig] = base_pos[look]\n",
    "        keep_idx.append(i)\n",
    "\n",
    "if len(keep_idx) == 0:\n",
    "    raise RuntimeError(\n",
    "        \"No channels matched the montage. Try a different montage (e.g., 'biosemi160') \"\n",
    "        \"or provide a custom electrode position file.\"\n",
    "    )\n",
    "\n",
    "# Keep only channels we can place\n",
    "ch_names = [ch_names_orig[i] for i in keep_idx]\n",
    "values = values_orig[keep_idx]\n",
    "\n",
    "# Create info and apply custom dig montage\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=1000.0, ch_types=\"eeg\")\n",
    "custom_montage = mne.channels.make_dig_montage(ch_pos=ch_pos_custom, coord_frame=\"head\")\n",
    "info.set_montage(custom_montage, on_missing=\"ignore\")\n",
    "\n",
    "# -------- 4) Compute 2D topomap coordinates (only valid channels exist here) --------\n",
    "coords2d = mne.channels.layout._find_topomap_coords(info, picks=np.arange(len(ch_names)))\n",
    "\n",
    "# -------- 5) Plot BIG + crisp --------\n",
    "fig, ax = plt.subplots(figsize=(14, 9), dpi=250)\n",
    "\n",
    "vmin, vmax = float(values.min()), float(values.max())  # or set fixed range manually\n",
    "\n",
    "im, cn = mne.viz.plot_topomap(\n",
    "    values,\n",
    "    info,\n",
    "    axes=ax,\n",
    "    show=False,\n",
    "    contours=6,\n",
    "    sensors=False,      # draw our own dots\n",
    "    outlines=\"head\",\n",
    "    vlim=(vmin, vmax),\n",
    "    cmap=\"jet\",\n",
    ")\n",
    "\n",
    "# -------- 6) Draw big dots + labels with outward leader lines --------\n",
    "dot_size = 18\n",
    "font_size = 13\n",
    "arrow_lw = 0.9\n",
    "\n",
    "for (x, y), name in zip(coords2d, ch_names):\n",
    "    # big dot\n",
    "    ax.plot(x, y, \"k.\", markersize=dot_size, zorder=10)\n",
    "\n",
    "    # radial outward label placement\n",
    "    r = np.sqrt(x * x + y * y) + 1e-9\n",
    "    ux, uy = x / r, y / r  # outward unit vector\n",
    "\n",
    "    # base offset outward + a tiny vertical lift to reduce overlap\n",
    "    offset_out = 0.085\n",
    "    offset_lift = 0.015\n",
    "\n",
    "    x_text = x + ux * offset_out\n",
    "    y_text = y + uy * offset_out + (offset_lift if y >= 0 else -offset_lift)\n",
    "\n",
    "    ax.annotate(\n",
    "        name,\n",
    "        xy=(x, y),\n",
    "        xytext=(x_text, y_text),\n",
    "        textcoords=\"data\",\n",
    "        fontsize=font_size,\n",
    "        fontweight=\"bold\",\n",
    "        ha=\"left\" if x_text >= x else \"right\",\n",
    "        va=\"center\",\n",
    "        bbox=dict(facecolor=\"white\", edgecolor=\"black\", alpha=0.88, pad=0.25),\n",
    "        arrowprops=dict(arrowstyle=\"-\", color=\"black\", lw=arrow_lw),\n",
    "        zorder=11,\n",
    "    )\n",
    "\n",
    "# -------- 7) Colorbar + title --------\n",
    "cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "cbar.set_label(\"Electrode importance\", fontsize=14)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "missing = len(ch_names_orig) - len(ch_names)\n",
    "ax.set_title(\n",
    "    f\"Topographic map of electrode importance (clear labels)\\n\"\n",
    "    f\"Plotted {len(ch_names)} channels (skipped {missing} without montage positions)\",\n",
    "    fontsize=18,\n",
    ")\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a464ca7-fd1a-4302-a313-134d4d7fcef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% CELL 9B — Calculate Average Probability (Production-Style)\n",
    "\n",
    "\"\"\"\n",
    "This matches the production code calculation:\n",
    "1. Get sigmoid probabilities per segment\n",
    "2. Average across all segments\n",
    "3. Determine class and confidence\n",
    "\"\"\"\n",
    "\n",
    "# Get raw probabilities (already computed in Cell 9)\n",
    "# y_probs is shape (n_segments, 1) - sigmoid output per segment\n",
    "\n",
    "# Calculate average probability across all segments\n",
    "avg_probability = float(np.mean(y_probs))\n",
    "\n",
    "# Determine predicted class using 0.5 threshold\n",
    "predicted_class = \"positive\" if avg_probability >= 0.5 else \"negative\"\n",
    "\n",
    "# Calculate confidence (production logic)\n",
    "if avg_probability >= 0.5:\n",
    "    confidence = avg_probability\n",
    "else:\n",
    "    confidence = 1.0 - avg_probability\n",
    "\n",
    "# Display results\n",
    "print(\"=\"*60)\n",
    "print(\"PRODUCTION-STYLE PROBABILITY CALCULATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total segments analyzed: {len(y_probs)}\")\n",
    "print(f\"Average sigmoid probability: {avg_probability:.6f}\")\n",
    "print(f\"Predicted class: {predicted_class}\")\n",
    "print(f\"Confidence: {confidence:.3f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Breakdown statistics\n",
    "print(\"\\nSegment Probability Statistics:\")\n",
    "print(f\"  Min probability: {y_probs.min():.6f}\")\n",
    "print(f\"  Max probability: {y_probs.max():.6f}\")\n",
    "print(f\"  Median probability: {np.median(y_probs):.6f}\")\n",
    "print(f\"  Std dev: {y_probs.std():.6f}\")\n",
    "\n",
    "# Distribution of predictions\n",
    "num_positive_segments = (y_probs >= 0.5).sum()\n",
    "num_negative_segments = (y_probs < 0.5).sum()\n",
    "print(f\"\\nSegment-level predictions:\")\n",
    "print(f\"  Positive segments: {num_positive_segments} ({100*num_positive_segments/len(y_probs):.1f}%)\")\n",
    "print(f\"  Negative segments: {num_negative_segments} ({100*num_negative_segments/len(y_probs):.1f}%)\")\n",
    "\n",
    "# Expected output format (matches production)\n",
    "output_json = {\n",
    "    \"status\": predicted_class,\n",
    "    \"confidence\": round(confidence, 3),\n",
    "    \"probability\": round(avg_probability, 3),\n",
    "    \"metadata\": {\n",
    "        \"total_segments\": len(y_probs),\n",
    "        \"positive_segments\": int(num_positive_segments),\n",
    "        \"negative_segments\": int(num_negative_segments),\n",
    "        \"ground_truth\": \"positive\" if y_test_trial == 1 else \"negative\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PRODUCTION OUTPUT FORMAT:\")\n",
    "print(\"=\"*60)\n",
    "import json\n",
    "print(json.dumps(output_json, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03be33e-0842-4f11-9342-e61778523f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
